<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="author" content="ljingb" />
    <meta name="robots" content="index, follow"/>

    <meta property="og:title" content="logstash的kafka插件使用"/>
    <meta property="og:url" content="http://bigbo.github.io/pages/2015/01/23/logstash_kafka/"/>
    <meta property="og:site_name" content="BigBo's blog"/>
    <meta property="og:type" content="article"/>

    <link rel="canonical" href="http://bigbo.github.io/pages/2015/01/23/logstash_kafka/" />

    <title>logstash的kafka插件使用 | BigBo's blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" type="text/css" href="//libs.baidu.com/fontawesome/4.0.3/css/font-awesome.css" />
    <link rel="stylesheet" type="text/css" href="//libs.baidu.com/bootstrap/2.3.2/css/bootstrap.min.css" />

    <link rel="stylesheet" type="text/css" href="http://bigbo.github.io/theme/css/main.css" />
    <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="BigBo's blog Atom Feed" />

    <script type="text/javascript">var switchTo5x=true;</script>
    <script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script>
    <script type="text/javascript">
        stLight.options({
            publisher: "",
            doNotHash: false,
            doNotCopy: false,
            hashAddressBar: false
        });
    </script>
</head>

<body id="index">
<a class="hidden-phone" href="https://github.com/bigbo">
<img style="position: absolute; top: 0; right: 0; border: 0;"
src="http://s3.amazonaws.com/github/ribbons/forkme_right_gray_6d6d6d.png" alt="Follow me on GitHub" />
</a>
    <div class="row-fluid">
        <div class="span10 offset1">
            <header id="banner" >
                <h1>
                    <a href="http://bigbo.github.io/">BigBo's blog </a>
                </h1>
                <nav class="navbar">
                    <div class="navbar-inner">
                        <ul class="nav">
                            <li ><a href="http://bigbo.github.io/pages/about/">About</a></li>
                            <li ><a href="http://bigbo.github.io/category/gui-dang.html">归档</a></li>
                            <li class="active"><a href="http://bigbo.github.io/category/technology.html">Technology</a></li>
                        </ul>

                    </div>
                </nav>
            </header><!-- /#banner -->
        </div>
    </div>

    <div class="row-fluid">
        <div class="span10 offset1">
            <div class="row-fluid">
<div class="span10 offset1">
  <section>
    <article>
      <header>
        <h1 class="entry-title">
          <a href="http://bigbo.github.io/pages/2015/01/23/logstash_kafka/" rel="bookmark"
             title="Permalink to logstash的kafka插件使用">logstash的kafka插件使用</a></h1>
      </header>
      <div class="entry-content">
<footer class="post-info">
    <address class="vcard author">
        by <a class="url fn" href="http://bigbo.github.io/author/ljingb.html">ljingb</a>
    </address>

    in <a href="http://bigbo.github.io/category/technology.html">Technology</a>

    on 2015-01-23

        |
        tags:         <a href="http://bigbo.github.io/tag/kafka.html">kafka</a>
        <a href="http://bigbo.github.io/tag/xiao-xi-dui-lie.html">消息队列</a>
        <a href="http://bigbo.github.io/tag/logstash.html">logstash</a>
        <a href="http://bigbo.github.io/tag/ri-zhi-chu-li.html">日志处理</a>


        |
        <a href="http://bigbo.github.io/pages/2015/01/23/logstash_kafka/#disqus_thread">comments</a>

    
</footer><!-- /.post-info -->

        <h2>前言</h2>
<p>关于logstash可以产看其 <a href="http://logstash.net/">官网</a> ,对于英文有障碍的人士,或是想知道更多插件使用技巧的用户请移步 <a href="http://chenlinux.com/">@三斗室</a> 所著作 <a href="https://github.com/bigbo/logstash-best-practice-cn">logstash最佳实战</a> ,本片内容已经并入其中相关章节.</p>
<hr />
<h2>Logstash-kafka简介</h2>
<p><a href="https://github.com/joekiller/logstash-kafka">https://github.com/joekiller/logstash-kafka</a></p>
<p>插件已经正式合并进官方仓库，以下使用介绍基于<strong>logstash 1.4相关版本</strong>，1.5及以后版本的使用后续依照官方文档持续更新。</p>
<p>插件本身内容非常简单，其主要依赖同一作者写的 <a href="https://github.com/joekiller/jruby-kafka">jruby-kafka</a> 模块。需要注意的是：<strong>该模块仅支持 Kafka－0.8 版本。如果是使用 0.7 版本 kafka 的，将无法直接使 jruby-kafka 该模块和 logstash-kafka 插件。</strong></p>
<h2>安装</h2>
<ul>
<li>安装按照官方文档完全自动化的安装.或是可以通过以下方式手动自己安装插件，不过重点注意的是 <strong>kafka 的版本</strong>，上面已经指出了。</li>
</ul>
<blockquote>
<ol>
<li>
<p>下载 logstash 并解压重命名为 <code>./logstash-1.4.0</code> 文件目录。</p>
</li>
<li>
<p>下载 kafka 相关组件，以下示例选的为 <a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.1.1/kafka-0.8.1.1-src.tgz">kafka_2.8.0-0.8.1.1-src</a>，并解压重命名为 <code>./kafka_2.8.0-0.8.1.1</code>。</p>
</li>
<li>
<p>下载 logstash-kafka v0.4.2 从 <a href="https://github.com/joekiller/logstash-kafka/releases">releases</a>，并解压重命名为 <code>./logstash-kafka-0.4.2</code>。</p>
</li>
<li>
<p>从 <code>./kafka_2.8.0-0.8.1.1/libs</code> 目录下复制所有的 jar 文件拷贝到 <code>./logstash-1.4.0/vendor/jar/kafka_2.8.0-0.8.1.1/libs</code> 下，其中你需要创建 <code>kafka_2.8.0-0.8.1.1/libs</code> 相关文件夹及目录。</p>
</li>
<li>
<p>分别复制 <code>./logstash-kafka-0.4.2/logstash</code> 里的 <code>inputs</code> 和 <code>outputs</code> 下的 <code>kafka.rb</code>，拷贝到对应的 <code>./logstash-1.4.0/lib/logstash</code> 里的 <code>inputs</code> 和 <code>outputs</code> 对应目录下。</p>
</li>
<li>
<p>切换到 <code>./logstash-1.4.0</code> 目录下，现在需要运行 logstash-kafka 的 gembag.rb 脚本去安装 jruby-kafka 库，执行以下命令： <code>GEM_HOME=vendor/bundle/jruby/1.9 GEM_PATH= java -jar vendor/jar/jruby-complete-1.7.11.jar --1.9 ../logstash-kafka-0.4.2/gembag.rb ../logstash-kafka-0.4.2/logstash-kafka.gemspec</code>。</p>
</li>
<li>
<p>现在可以使用 logstash-kafka 插件运行 logstash 了。例如：<code>bin/logstash agent -f logstash.conf</code>。</p>
</li>
</ol>
</blockquote>
<h2>Input 配置示例</h2>
<p>以下配置可以实现对 kafka 读取端(consumer)的基本使用。</p>
<p>消费端更多详细的配置请查看 <a href="http://kafka.apache.org/documentation.html#consumerconfigs">http://kafka.apache.org/documentation.html#consumerconfigs</a> kafka 官方文档的消费者部分配置文档。</p>
<div class="highlight"><pre>input {
    kafka {
        zk_connect =&gt; &quot;localhost:2181&quot;
        group_id =&gt; &quot;logstash&quot;
        topic_id =&gt; &quot;test&quot;
        reset_beginning =&gt; false # boolean (optional)， default: false
        consumer_threads =&gt; 5  # number (optional)， default: 1
        decorate_events =&gt; true # boolean (optional)， default: false
        }
    }
</pre></div>


<h2>Input 解释</h2>
<p>消费端的一些比较有用的配置项：</p>
<ul>
<li>group_id</li>
</ul>
<p>消费者分组，可以通过组 ID 去指定，不同的组之间消费是相互不受影响的，相互隔离。</p>
<ul>
<li>topic_id</li>
</ul>
<p>指定消费话题，也是必填项目，指定消费某个 <code>topic</code> ，这个其实就是订阅某个主题，然后去消费。</p>
<ul>
<li>reset_beginning</li>
</ul>
<p>logstash 启动后从什么位置开始读取数据，默认是结束位置，也就是说 logstash 进程会以从上次读取结束时的偏移量开始继续读取，如果之前没有消费过，那么就开始从头读取.如果你是要导入原有数据，把这个设定改成 "true"， logstash 进程就从头开始读取.有点类似 <code>cat</code> ，但是读到最后一行不会终止，而是变成 <code>tail -F</code> ，继续监听相应数据。</p>
<ul>
<li>decorate_events</li>
</ul>
<p>在输出消息的时候会输出自身的信息包括:消费消息的大小， topic 来源以及 consumer 的 group 信息。</p>
<ul>
<li>rebalance_max_retries</li>
</ul>
<p>当有新的 consumer(logstash) 加入到同一 group 时，将会 <code>reblance</code> ，此后将会有 <code>partitions</code> 的消费端迁移到新的 <code>consumer</code> 上，如果一个 <code>consumer</code> 获得了某个 <code>partition</code> 的消费权限，那么它将会向 <code>zookeeper</code> 注册， <code>Partition Owner registry</code> 节点信息，但是有可能此时旧的 <code>consumer</code> 尚没有释放此节点，此值用于控制，注册节点的重试次数。</p>
<ul>
<li>consumer_timeout_ms</li>
</ul>
<p>指定时间内没有消息到达就抛出异常，一般不需要改。</p>
<p>以上是相对重要参数的使用示例，更多参数可以选项可以跟据 <a href="https://github.com/joekiller/logstash-kafka/blob/master/README.md">https://github.com/joekiller/logstash-kafka/blob/master/README.md</a> 查看 input 默认参数。</p>
<h2>注意</h2>
<p>1.想要使用多个 logstash 端协同消费同一个 <code>topic</code> 的话，那么需要把两个或是多个 logstash 消费端配置成相同的 <code>group_id</code> 和 <code>topic_id</code>， 但是前提是要把<strong>相应的 topic 分多个 partitions (区)</strong>，多个消费者消费是无法保证消息的消费顺序性的。</p>
<blockquote>
<p>这里解释下，为什么要分多个 <strong>partitions(区)</strong>， kafka 的消息模型是对 topic 分区以达到分布式效果。每个 <code>topic</code> 下的不同的 <strong>partitions (区)</strong>只能有一个 <strong>Owner</strong> 去消费。所以只有多个分区后才能启动多个消费者，对应不同的区去消费。其中协调消费部分是由 server 端协调而成。不必使用者考虑太多。只是<strong>消息的消费则是无序的</strong>。</p>
</blockquote>
<p>总结:保证消息的顺序，那就用一个 <strong>partition</strong>。 <strong>kafka 的每个 partition 只能同时被同一个 group 中的一个 consumer 消费</strong>。</p>
<h2>Output 配置</h2>
<p>以下配置可以实现对 kafka 写入端 (producer) 的基本使用。</p>
<p>生产端更多详细的配置请查看 <a href="http://kafka.apache.org/documentation.html#producerconfigs">http://kafka.apache.org/documentation.html#producerconfigs</a> kafka 官方文档的生产者部分配置文档。</p>
<div class="highlight"><pre> output {
    kafka {
        broker_list =&gt; &quot;localhost:9092&quot;
        topic_id =&gt; &quot;test&quot;
        compression_codec =&gt; &quot;snappy&quot; # string (optional)， one of [&quot;none&quot;， &quot;gzip&quot;， &quot;snappy&quot;]， default: &quot;none&quot;
    }
}
</pre></div>


<h2>Output 解释</h2>
<p>生产的可设置性还是很多的，设置其实更多，以下是更多的设置：</p>
<ul>
<li>compression_codec</li>
</ul>
<p>消息的压缩模式，默认是 none，可以有 gzip 和 snappy (暂时还未测试开启压缩与不开启的性能，数据传输大小等对比)。</p>
<ul>
<li>compressed_topics</li>
</ul>
<p>可以针对特定的 topic 进行压缩，设置这个参数为 <code>topic</code> ，表示此 <code>topic</code> 进行压缩。</p>
<ul>
<li>request_required_acks</li>
</ul>
<p>消息的确认模式:</p>
<blockquote>
<p>可以设置为 0: 生产者不等待 broker 的回应，只管发送.会有最低能的延迟和最差的保证性(在服务器失败后会导致信息丢失)</p>
<p>可以设置为 1: 生产者会收到 leader 的回应在 leader 写入之后.(在当前 leader 服务器为复制前失败可能会导致信息丢失)</p>
<p>可以设置为 -1: 生产者会收到 leader 的回应在全部拷贝完成之后。</p>
</blockquote>
<ul>
<li>partitioner_class</li>
</ul>
<p>分区的策略，默认是 hash 取模</p>
<ul>
<li>send_buffer_bytes</li>
</ul>
<p>socket 的缓存大小设置，其实就是缓冲区的大小</p>
<h4>消息模式相关</h4>
<ul>
<li>serializer_class</li>
</ul>
<p>消息体的系列化处理类，转化为字节流进行传输，<strong>请注意 encoder 必须和下面的 <code>key_serializer_class</code> 使用相同的类型</strong>。</p>
<ul>
<li>key_serializer_class</li>
</ul>
<p>默认的是与 <code>serializer_class</code> 相同</p>
<ul>
<li>producer_type</li>
</ul>
<p>生产者的类型 <code>async</code> 异步执行消息的发送 <code>sync</code> 同步执行消息的发送</p>
<ul>
<li>queue_buffering_max_ms</li>
</ul>
<p><strong>异步模式下</strong>，那么就会在设置的时间缓存消息，并一次性发送</p>
<ul>
<li>queue_buffering_max_messages</li>
</ul>
<p><strong>异步的模式下</strong>，最长等待的消息数</p>
<ul>
<li>queue_enqueue_timeout_ms</li>
</ul>
<p><strong>异步模式下</strong>，进入队列的等待时间，若是设置为0，那么要么进入队列，要么直接抛弃</p>
<ul>
<li>batch_num_messages</li>
</ul>
<p><strong>异步模式下</strong>，每次发送的最大消息数，前提是触发了 <code>queue_buffering_max_messages</code> 或是 <code>queue_enqueue_timeout_ms</code> 的限制</p>
<p>以上是相对重要参数的使用示例，更多参数可以选项可以跟据 <a href="https://github.com/joekiller/logstash-kafka/blob/master/README.md">https://github.com/joekiller/logstash-kafka/blob/master/README.md</a> 查看 output 默认参数。</p>
<h3>小贴士</h3>
<p>默认情况下，插件是使用 json 编码来输入和输出相应的消息，消息传递过程中 logstash 默认会为消息编码内加入相应的时间戳和 hostname 等信息。如果不想要以上信息(一般做消息转发的情况下)，可以使用以下配置，例如:</p>
<div class="highlight"><pre> output {
    kafka {
        codec =&gt; plain {
            format =&gt; &quot;%{message}&quot;
        }
    }
}
</pre></div>

      </div><!-- /.entry-content -->

        <div class="comments">
                <h2>Comments !</h2>
                    <!-- Duoshuo Comment BEGIN -->
                        <div class="ds-thread"></div>
                            <script type="text/javascript">
        var duoshuoQuery = {short_name:"bigbo"};
  (function() {
      var ds = document.createElement('script');
         ds.type = 'text/javascript';ds.async = true;
            ds.src = 'http://static.duoshuo.com/embed.js';
               ds.charset = 'UTF-8';
                  (document.getElementsByTagName('head')[0]
                       || document.getElementsByTagName('body')[0]).appendChild(ds);

                     })();
  </script>
    <noscript>Please enable JavaScript to view the comments.</noscript>
    <!-- Duoshuo Comment END -->


    </article>
  </section>
</div>
            </div>
        </div>
    </div>

    <footer id="site-footer">
        <div class="row-fluid">
            <div class="span10 offset1">
                <address>
                    <p>
                    Copyright 2014-2015 by <a href="http://bigbo.github.io/">ljingb</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                    </p>
                    <p>
                    Powered by <a href="http://getpelican.com/">Pelican</a>,<a href="http://github.com/jsliang/pelican-fresh/">Fresh</a> is a responsive theme designed by <a href="http://jsliang.com/">jsliang</a> and <a href="https://github.com/jsliang/pelican-fresh/graphs/contributors">contributors</a>.
                    </p>
                </address>
            </div>
        </div>
    </footer>

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-58118410-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
    <script src="//libs.baidu.com/jquery/2.0.0/jquery.min.js"></script>
    <script src="//libs.baidu.com/bootstrap/2.3.2/css/bootstrap.min.css"></script>
</body>
</html>