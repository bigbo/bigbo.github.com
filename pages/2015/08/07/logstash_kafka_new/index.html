<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="author" content="ljingb" />
    <meta name="robots" content="index, follow"/>

    <meta property="og:title" content="logstash的kafka插件使用(更新)"/>
    <meta property="og:url" content="http://bigbo.github.io/pages/2015/08/07/logstash_kafka_new/"/>
    <meta property="og:site_name" content="BigBo's blog"/>
    <meta property="og:type" content="article"/>

    <link rel="canonical" href="http://bigbo.github.io/pages/2015/08/07/logstash_kafka_new/" />

    <title>logstash的kafka插件使用(更新) | BigBo's blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" type="text/css" href="//libs.baidu.com/fontawesome/4.0.3/css/font-awesome.css" />
    <link rel="stylesheet" type="text/css" href="//libs.baidu.com/bootstrap/2.3.2/css/bootstrap.min.css" />

    <link rel="stylesheet" type="text/css" href="http://bigbo.github.io/theme/css/main.css" />
    <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="BigBo's blog Atom Feed" />

    <script type="text/javascript">var switchTo5x=true;</script>
    <script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script>
    <script type="text/javascript">
        stLight.options({
            publisher: "",
            doNotHash: false,
            doNotCopy: false,
            hashAddressBar: false
        });
    </script>
</head>

<body id="index">
<a class="hidden-phone" href="https://github.com/bigbo">
<img style="position: absolute; top: 0; right: 0; border: 0;"
src="http://s3.amazonaws.com/github/ribbons/forkme_right_gray_6d6d6d.png" alt="Follow me on GitHub" />
</a>
    <div class="row-fluid">
        <div class="span10 offset1">
            <header id="banner" >
                <h1>
                    <a href="http://bigbo.github.io/">BigBo's blog </a>
                </h1>
                <nav class="navbar">
                    <div class="navbar-inner">
                        <ul class="nav">
                            <li ><a href="http://bigbo.github.io/pages/about/">About</a></li>
                            <li ><a href="http://bigbo.github.io/category/gui-dang.html">归档</a></li>
                            <li class="active"><a href="http://bigbo.github.io/category/technology.html">Technology</a></li>
                        </ul>

                    </div>
                </nav>
            </header><!-- /#banner -->
        </div>
    </div>

    <div class="row-fluid">
        <div class="span10 offset1">
            <div class="row-fluid">
<div class="span10 offset1">
  <section>
    <article>
      <header>
        <h1 class="entry-title">
          <a href="http://bigbo.github.io/pages/2015/08/07/logstash_kafka_new/" rel="bookmark"
             title="Permalink to logstash的kafka插件使用(更新)">logstash的kafka插件使用(更新)</a></h1>
      </header>
      <div class="entry-content">
<footer class="post-info">
    <address class="vcard author">
        by <a class="url fn" href="http://bigbo.github.io/author/ljingb.html">ljingb</a>
    </address>

    in <a href="http://bigbo.github.io/category/technology.html">Technology</a>

    on 2015-08-07

        |
        tags:         <a href="http://bigbo.github.io/tag/kafka.html">kafka</a>
        <a href="http://bigbo.github.io/tag/xiao-xi-dui-lie.html">消息队列</a>
        <a href="http://bigbo.github.io/tag/logstash-cha-jian.html">logstash 插件</a>
        <a href="http://bigbo.github.io/tag/ri-zhi-chu-li.html">日志处理</a>


        |
        <a href="http://bigbo.github.io/pages/2015/08/07/logstash_kafka_new/#disqus_thread">comments</a>

    
</footer><!-- /.post-info -->

        <ul>
<li>以下内容同步更新到 <ELKstack-技术指南> <a href="http://kibana.logstash.es/">http://kibana.logstash.es/</a></li>
</ul>
<h1>通过kafka传输</h1>
<p>Kafka 是一个高吞吐量的分布式发布订阅日志服务，具有高可用、高性能、分布式、高扩展、持久性等特性。目前已经在各大公司中广泛使用。和之前采用 Redis 做轻量级消息队列不同，Kafka 利用磁盘作队列，所以也就无所谓消息缓冲时的磁盘问题。此外，如果公司内部已有 Kafka 服务在运行，logstash 也可以快速接入，免去重复建设的麻烦。</p>
<p>如果打算新建 Kafka 系统的，请参考 Kafka 官方入门文档：<a href="http://kafka.apache.org/documentation.html#quickstart">http://kafka.apache.org/documentation.html#quickstart</a></p>
<h2>kafka 基本概念</h2>
<p>以下仅对相关基本概念说明，更多概念见官方文档：</p>
<ul>
<li>Topic
 主题，声明一个主题，producer指定该主题发布消息，订阅该主题的consumer对该主题进行消费</li>
<li>Partition
每个主题可以分为多个分区，每个分区对应磁盘上一个目录，分区可以分布在不同broker上，producer在发布消息时，可以通过指定partition key映射到对应分区，然后向该分区发布消息，在无partition key情况下，随机选取分区，一段时间内触发一次(比如10分钟)，这样就保证了同一个producer向同一partition发布的消息是顺序的。
消费者消费时，可以指定partition进行消费，也可以使用high-level-consumer api,自动进行负载均衡，并将partition分给consumer，一个partition只能被一个consumer进行消费。</li>
<li>Consumer
消费者，可以多实例部署，可以批量拉取，有两类API可供选择：一个simpleConsumer，暴露所有的操作给用户，可以提交offset、fetch offset、指定partition fetch message；另外一个high-level-consumer(ZookeeperConsumerConnector)，帮助用户做基于partition自动分配的负载均衡，定期提交offset，建立消费队列等。simpleConsumer相当于手动挡，high-level-consumer相当于自动挡。</li>
</ul>
<p>simpleConsumer：无需像high-level-consumer那样向zk注册brokerid、owner，甚至不需要提交offset到zk，可以将offset提交到任意地方比如(mysql,本地文件等)。</p>
<p>high-level-consumer：一个进程中可以启多个消费线程，一个消费线程即是一个consumer，假设A进程里有2个线程(consumerid分别为1，2)，B进程有2个线程(consumerid分别为1，2)，topic1的partition有5个，那么partition分配是这样的：</p>
<div class="highlight"><pre>    partition1 ---&gt; A进程consumerid1
    partition2 ---&gt; A进程consumerid1
    partition3 ---&gt; A进程consumerid2
    partition4 ---&gt; B进程consumer1
    partition5 ---&gt; B进程consumer2
</pre></div>


<ul>
<li>Group
 High-level-consumer可以声明group，每个group可以有多个consumer，每group各自管理各自的消费offset，各个不同group之间互不关联影响。</li>
</ul>
<p>由于目前版本消费的offset、owner、group都是consumer自己通过zk管理，所以group对于broker和producer并不关心，一些监控工具需要通过group来监控，simpleComsumer无需声明group。</p>
<h3>小提示</h3>
<p>以上概念是 logstash 的 kafka 插件的必要参数，请理解阅读，对后续使用 kafka 插件有重要作用。logstash-kafka-input 插件使用的是 <code>High-level-consumer API</code>。</p>
<h2>插件安装</h2>
<h3>logstash-1.4 安装</h3>
<p>如果你使用的还是 1.4 版本，需要自己单独安装 logstash-kafka 插件。插件地址见：<a href="https://github.com/joekiller/logstash-kafka">https://github.com/joekiller/logstash-kafka</a>。</p>
<p>插件本身内容非常简单，其主要依赖同一作者写的 <a href="https://github.com/joekiller/jruby-kafka">jruby-kafka</a> 模块。需要注意的是：<strong>该模块仅支持 Kafka-0.8 版本。如果是使用 0.7 版本 kafka 的，将无法直接使 jruby-kafka 该模块和 logstash-kafka 插件。</strong></p>
<p>安装按照官方文档完全自动化的安装。或是可以通过以下方式手动自己安装插件，不过重点注意的是 <strong>kafka 的版本</strong>，上面已经指出了。</p>
<ol>
<li>下载 logstash 并解压重命名为 <code>./logstash-1.4.0</code> 文件目录。</li>
<li>下载 kafka 相关组件，以下示例选的为 <a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.1.1/kafka-0.8.1.1-src.tgz">kafka_2.8.0-0.8.1.1-src</a>，并解压重命名为 <code>./kafka_2.8.0-0.8.1.1</code>。</li>
<li>从 <a href="https://github.com/joekiller/logstash-kafka/releases">releases</a> 页下载 logstash-kafka v0.4.2 版，并解压重命名为 <code>./logstash-kafka-0.4.2</code>。</li>
<li>从 <code>./kafka_2.8.0-0.8.1.1/libs</code> 目录下复制所有的 jar 文件拷贝到 <code>./logstash-1.4.0/vendor/jar/kafka_2.8.0-0.8.1.1/libs</code> 下，其中你需要创建 <code>kafka_2.8.0-0.8.1.1/libs</code> 相关文件夹及目录。</li>
<li>分别复制 <code>./logstash-kafka-0.4.2/logstash</code> 里的 <code>inputs</code> 和 <code>outputs</code> 下的 <code>kafka.rb</code>，拷贝到对应的 <code>./logstash-1.4.0/lib/logstash</code> 里的 <code>inputs</code> 和 <code>outputs</code> 对应目录下。</li>
<li>切换到 <code>./logstash-1.4.0</code> 目录下，现在需要运行 logstash-kafka 的 gembag.rb 脚本去安装 jruby-kafka 库，执行以下命令： <code>GEM_HOME=vendor/bundle/jruby/1.9 GEM_PATH= java -jar vendor/jar/jruby-complete-1.7.11.jar --1.9 ../logstash-kafka-0.4.2/gembag.rb ../logstash-kafka-0.4.2/logstash-kafka.gemspec</code>。</li>
<li>现在可以使用 logstash-kafka 插件运行 logstash 了。</li>
</ol>
<h3>logstash-1.5 安装</h3>
<p>logstash 从 1.5 版本开始才集成了 Kafka 支持。1.5 版本开始所有插件的目录和命名都发生了改变，插件发布地址见：<a href="https://github.com/logstash-plugins">https://github.com/logstash-plugins</a>。
安装和更新插件都可以使用官方提供的方式：</p>
<div class="highlight"><pre><span class="p">$</span><span class="nv">bin</span><span class="x">/plugin install OR </span><span class="p">$</span><span class="nv">bin</span><span class="x">/plugin update</span>
</pre></div>


<h3>小贴士</h3>
<p>对于插件的安装和更新，默认走的Gem源为 <a href="https://rubygems.org">https://rubygems.org</a>,对于咱们国内网络来说是出奇的慢或是根本无法访问（爬梯子除外），在安装或是更新插件是，可以尝试修改目录下 <code>Gemfile</code> 文件中的 <code>source</code> 为淘宝源<a href="https://ruby.taobao.org">https://ruby.taobao.org</a>，这样会使你的安装或是更新顺畅很多。</p>
<h2>插件配置</h2>
<h3>Input 配置示例</h3>
<p>以下配置可以实现对 kafka 读取端(consumer)的基本使用。</p>
<p>消费端更多详细的配置请查看 <a href="http://kafka.apache.org/documentation.html#consumerconfigs">http://kafka.apache.org/documentation.html#consumerconfigs</a> kafka 官方文档的消费者部分配置文档。</p>
<div class="highlight"><pre>input {
    kafka {
        zk_connect =&gt; &quot;localhost:2181&quot;
        group_id =&gt; &quot;logstash&quot;
        topic_id =&gt; &quot;test&quot;
        reset_beginning =&gt; false # boolean (optional)， default: false
        consumer_threads =&gt; 5  # number (optional)， default: 1
        decorate_events =&gt; true # boolean (optional)， default: false
    }
}
</pre></div>


<h3>Input 解释</h3>
<p>作为 Consumer 端,插件使用的是 <code>High-level-consumer API</code>，<strong>请结合上述 kafka 基本概念进行设置</strong>：</p>
<ul>
<li>group_id</li>
</ul>
<p>消费者分组，可以通过组 ID 去指定，不同的组之间消费是相互不受影响的，相互隔离。</p>
<ul>
<li>topic_id</li>
</ul>
<p>指定消费话题，也是必填项目，指定消费某个 <code>topic</code> ，这个其实就是订阅某个主题，然后去消费。</p>
<ul>
<li>reset_beginning</li>
</ul>
<p>logstash 启动后从什么位置开始读取数据，默认是结束位置，也就是说 logstash 进程会以从上次读取结束时的偏移量开始继续读取，如果之前没有消费过，那么就开始从头读取.如果你是要导入原有数据，把这个设定改成 "true"， logstash 进程就从头开始读取.有点类似 <code>cat</code> ，但是读到最后一行不会终止，而是变成 <code>tail -F</code> ，继续监听相应数据。</p>
<ul>
<li>decorate_events</li>
</ul>
<p>在输出消息的时候会输出自身的信息包括:消费消息的大小， topic 来源以及 consumer 的 group 信息。</p>
<ul>
<li>rebalance_max_retries</li>
</ul>
<p>当有新的 consumer(logstash) 加入到同一 group 时，将会 <code>reblance</code> ，此后将会有 <code>partitions</code> 的消费端迁移到新的 <code>consumer</code> 上，如果一个 <code>consumer</code> 获得了某个 <code>partition</code> 的消费权限，那么它将会向 <code>zookeeper</code> 注册， <code>Partition Owner registry</code> 节点信息，但是有可能此时旧的 <code>consumer</code> 尚没有释放此节点，此值用于控制，注册节点的重试次数。</p>
<ul>
<li>consumer_timeout_ms</li>
</ul>
<p>指定时间内没有消息到达就抛出异常，一般不需要改。</p>
<p>以上是相对重要参数的使用示例，更多参数可以选项可以跟据 <a href="https://github.com/joekiller/logstash-kafka/blob/master/README.md">https://github.com/joekiller/logstash-kafka/blob/master/README.md</a> 查看 input 默认参数。</p>
<h4>注意</h4>
<p>1.想要使用多个 logstash 端协同消费同一个 <code>topic</code> 的话，那么需要把两个或是多个 logstash 消费端配置成相同的 <code>group_id</code> 和 <code>topic_id</code>， 但是前提是要把<strong>相应的 topic 分多个 partitions (区)</strong>，多个消费者消费是无法保证消息的消费顺序性的。</p>
<ul>
<li>这里解释下，为什么要分多个 <strong>partitions(区)</strong>， kafka 的消息模型是对 topic 分区以达到分布式效果。每个 <code>topic</code> 下的不同的 <strong>partitions (区)</strong>只能有一个 <strong>Owner</strong> 去消费。所以只有多个分区后才能启动多个消费者，对应不同的区去消费。其中协调消费部分是由 server 端协调而成。不必使用者考虑太多。只是<strong>消息的消费则是无序的</strong>。</li>
</ul>
<p>总结:保证消息的顺序，那就用一个 <strong>partition</strong>。 <strong>kafka 的每个 partition 只能同时被同一个 group 中的一个 consumer 消费</strong>。</p>
<h3>Output 配置</h3>
<p>以下配置可以实现对 kafka 写入端 (producer) 的基本使用。</p>
<p>生产端更多详细的配置请查看 <a href="http://kafka.apache.org/documentation.html#producerconfigs">http://kafka.apache.org/documentation.html#producerconfigs</a> kafka 官方文档的生产者部分配置文档。</p>
<div class="highlight"><pre> output {
    kafka {
        broker_list =&gt; &quot;localhost:9092&quot;
        topic_id =&gt; &quot;test&quot;
        compression_codec =&gt; &quot;snappy&quot; # string (optional)， one of [&quot;none&quot;， &quot;gzip&quot;， &quot;snappy&quot;]， default: &quot;none&quot;
    }
}
</pre></div>


<h3>Output 解释</h3>
<p>作为 Producer 端使用，以下仅为重要概念解释，<strong>请结合上述 kafka 基本概念进行设置</strong>：</p>
<ul>
<li>compression_codec</li>
</ul>
<p>消息的压缩模式，默认是 none，可以有 gzip 和 snappy (暂时还未测试开启压缩与不开启的性能，数据传输大小等对比)。</p>
<ul>
<li>compressed_topics</li>
</ul>
<p>可以针对特定的 topic 进行压缩，设置这个参数为 <code>topic</code> ，表示此 <code>topic</code> 进行压缩。</p>
<ul>
<li>request_required_acks</li>
</ul>
<p>消息的确认模式:</p>
<blockquote>
<p>可以设置为 0: 生产者不等待 broker 的回应，只管发送.会有最低能的延迟和最差的保证性(在服务器失败后会导致信息丢失)
可以设置为 1: 生产者会收到 leader 的回应在 leader 写入之后.(在当前 leader 服务器为复制前失败可能会导致信息丢失)
可以设置为 -1: 生产者会收到 leader 的回应在全部拷贝完成之后。</p>
</blockquote>
<ul>
<li>partitioner_class</li>
</ul>
<p>分区的策略，默认是 hash 取模</p>
<ul>
<li>send_buffer_bytes</li>
</ul>
<p>socket 的缓存大小设置，其实就是缓冲区的大小</p>
<h4>消息模式相关</h4>
<ul>
<li>serializer_class</li>
</ul>
<p>消息体的系列化处理类，转化为字节流进行传输，<strong>请注意 encoder 必须和下面的 <code>key_serializer_class</code> 使用相同的类型</strong>。</p>
<ul>
<li>key_serializer_class</li>
</ul>
<p>默认的是与 <code>serializer_class</code> 相同</p>
<ul>
<li>producer_type</li>
</ul>
<p>生产者的类型 <code>async</code> 异步执行消息的发送 <code>sync</code> 同步执行消息的发送</p>
<ul>
<li>queue_buffering_max_ms</li>
</ul>
<p><strong>异步模式下</strong>，那么就会在设置的时间缓存消息，并一次性发送</p>
<ul>
<li>queue_buffering_max_messages</li>
</ul>
<p><strong>异步的模式下</strong>，最长等待的消息数</p>
<ul>
<li>queue_enqueue_timeout_ms</li>
</ul>
<p><strong>异步模式下</strong>，进入队列的等待时间，若是设置为0，那么要么进入队列，要么直接抛弃</p>
<ul>
<li>batch_num_messages</li>
</ul>
<p><strong>异步模式下</strong>，每次发送的最大消息数，前提是触发了 <code>queue_buffering_max_messages</code> 或是 <code>queue_enqueue_timeout_ms</code> 的限制</p>
<p>以上是相对重要参数的使用示例，更多参数可以选项可以跟据 <a href="https://github.com/joekiller/logstash-kafka/blob/master/README.md">https://github.com/joekiller/logstash-kafka/blob/master/README.md</a> 查看 output 默认参数。</p>
<h3>小贴士</h3>
<p>logstash-kafka 插件输入和输出默认 <code>codec</code>  为 json 格式。在输入和输出的时候注意下编码格式。消息传递过程中 logstash 默认会为消息编码内加入相应的时间戳和 hostname 等信息。如果不想要以上信息(一般做消息转发的情况下)，可以使用以下配置，例如:</p>
<div class="highlight"><pre> output {
    kafka {
        codec =&gt; plain {
            format =&gt; &quot;%{message}&quot;
        }
    }
}
</pre></div>


<p>作为 Consumer 从kafka中读数据，如果为非 json 格式的话需要进行相关解码，例如：</p>
<div class="highlight"><pre>input {
    kafka {
        zk_connect =&gt; &quot;xxx：xxx&quot;
        group_id =&gt; &quot;test&quot;
        topic_id =&gt; &quot;test-topic&quot;
        codec =&gt; &quot;line&quot;
        ...........
    }
}
</pre></div>


<p>关于性能：</p>
<p>其实 logstash 的 kafka 插件性能并不是很突出，可以通过使用以下命令查看队列积压消费情况：</p>
<div class="highlight"><pre>$/bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --group test
</pre></div>


<p>队列积压严重，性能跟不上的情况下，结合实际服务器资源，可以适当增加 topic 的 partition 多实例化 Consumer 进行消费处理消息。</p>
<p>更多高性能方案可以选择 <a href="https://github.com/reachkrishnaraj/kafka-elasticsearch-standalone-consumer">https://github.com/reachkrishnaraj/kafka-elasticsearch-standalone-consumer</a></p>
<h1>致谢</h1>
<ul>
<li>
<p>感谢 候鸟树 的kafka相关技术总结</p>
</li>
<li>
<p>感谢 金桥 的建议和提醒</p>
</li>
</ul>

      </div><!-- /.entry-content -->

        <div class="comments">
                <h2>Comments !</h2>
                    <!-- Duoshuo Comment BEGIN -->
                        <div class="ds-thread"></div>
                            <script type="text/javascript">
        var duoshuoQuery = {short_name:"bigbo"};
  (function() {
      var ds = document.createElement('script');
         ds.type = 'text/javascript';ds.async = true;
            ds.src = 'http://static.duoshuo.com/embed.js';
               ds.charset = 'UTF-8';
                  (document.getElementsByTagName('head')[0]
                       || document.getElementsByTagName('body')[0]).appendChild(ds);

                     })();
  </script>
    <noscript>Please enable JavaScript to view the comments.</noscript>
    <!-- Duoshuo Comment END -->


    </article>
  </section>
</div>
            </div>
        </div>
    </div>

    <footer id="site-footer">
        <div class="row-fluid">
            <div class="span10 offset1">
                <address>
                    <p>
                    Copyright 2014-2015 by <a href="http://bigbo.github.io/">ljingb</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                    </p>
                    <p>
                    Powered by <a href="http://getpelican.com/">Pelican</a>,<a href="http://github.com/jsliang/pelican-fresh/">Fresh</a> is a responsive theme designed by <a href="http://jsliang.com/">jsliang</a> and <a href="https://github.com/jsliang/pelican-fresh/graphs/contributors">contributors</a>.
                    </p>
                </address>
            </div>
        </div>
    </footer>

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-58118410-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
    <script src="//libs.baidu.com/jquery/2.0.0/jquery.min.js"></script>
    <script src="//libs.baidu.com/bootstrap/2.3.2/css/bootstrap.min.css"></script>
</body>
</html>