<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>BigBo's blog</title><link href="http://bigbo.github.io/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>http://bigbo.github.io/</id><updated>2015-03-27T19:30:00+08:00</updated><entry><title>logstash-input-file以及logstash-output-kafka插件性能测试</title><link href="http://bigbo.github.io/pages/2015/03/26/logstash_performance/" rel="alternate"></link><updated>2015-03-27T19:30:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-03-26:pages/2015/03/26/logstash_performance/</id><summary type="html">&lt;p&gt;最近项目需求,要了解下logstash的一些性能,根据现有的技术方案,主要是针对 &lt;code&gt;logstash-input-file&lt;/code&gt; 插件以及 &lt;code&gt;logstash-output-kafka&lt;/code&gt; 插件进行测试,不过最近关注 logstash 的人应该清楚,目前处于新老版本迭代期,老版本&lt;a href="https://download.elasticsearch.org/logstash/logstash/logstash-1.4.2.tar.gz"&gt;1.4.2版本&lt;/a&gt; 和新版本 &lt;a href="http://download.elasticsearch.org/logstash/logstash/logstash-1.5.0.rc2.tar.gz"&gt;1.5.0RC2版本&lt;/a&gt; ,&lt;a href="http://chenlinux.com/2015/02/10/logstash-outputs-elasticsearch-http-memory-leak/"&gt;1.4.2版本内存泄露&lt;/a&gt; 问题在1.5版本后得到改进,但是1.5还没出正式版本.以下是根据1.5RC2版本来进行测试对比.&lt;/p&gt;
&lt;p&gt;硬件环境:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CPU&lt;/th&gt;
&lt;th&gt;硬盘&lt;/th&gt;
&lt;th&gt;内存&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Intel CorporationXeonE5 v2/Core i7&lt;/td&gt;
&lt;td&gt;2TX1&lt;/td&gt;
&lt;td&gt;128G&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;软件环境:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;系统&lt;/th&gt;
&lt;th align="center"&gt;java_jdk&lt;/th&gt;
&lt;th align="center"&gt;JVM&lt;/th&gt;
&lt;th align="center"&gt;Kafka Configuration&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;centos6.5&lt;/td&gt;
&lt;td align="center"&gt;1.7.0_65&lt;/td&gt;
&lt;td align="center"&gt;-Xmx2000m -Xss2048k(其他默认)&lt;/td&gt;
&lt;td align="center"&gt;Replica X1 Partition X1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;h2&gt;各版本之间性能对比&lt;/h2&gt;
&lt;h3&gt;裸跑性能&lt;/h3&gt;
&lt;p&gt;先测试下两个版本裸跑性能(不加任何filter),官方在之前也出过关于为什么用JRuby而不是用MRI的 &lt;a href="https://gist.github.com/jordansissel/4171039"&gt;性能测试报告&lt;/a&gt;,以下测试也选择官方的测试方法:使用 &lt;code&gt;generator&lt;/code&gt; 插件产生数据,然后使用 &lt;code&gt;pv&lt;/code&gt; 命令做性能监控.out.conf文件如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
 generator { count =&amp;gt; 5000000 }
}

output {
    stdout {
        codec =&amp;gt; dots
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./bin/logstash agent -f out.conf &lt;span class="p"&gt;|&lt;/span&gt; pv -Wbart &amp;gt; /dev/null
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;注意:centos下yum安装的 &lt;code&gt;pv&lt;/code&gt; 版本相对较低,没有 &lt;code&gt;-a&lt;/code&gt; 这个参数,使用起来不太好观察,可以选择更新下 &lt;a href="http://pkgs.repoforge.org/pv/"&gt;新版本&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;logstash1.4.2裸跑性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;1.53MiB 0:00:34 [47.2kiB/s] [46.2kiB/s]
1.97MiB 0:00:44 [37.9kiB/s] [45.9kiB/s]
2.81MiB 0:01:03 [38.3kiB/s] [45.7kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.5.0RC2裸跑性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;1.41MiB 0:00:52 [25.6kiB/s] [27.8kiB/s]
1.65MiB 0:01:00 [  26kiB/s] [28.1kiB/s]
2.19MiB 0:01:19 [  31kiB/s] [28.4kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;裸跑性能见分晓了.不解的是不知道为什么1.5RC2的版本与1.4.2版本的差距那么大.好奇心的驱使,去翻了下github的 &lt;a href="https://github.com/elastic/logstash/issues/2870#issuecomment-86515699"&gt;issues&lt;/a&gt;.看来确实新版本有些性能倒退,根据上面说的使用其修改版本 &lt;code&gt;fix/perf_regression&lt;/code&gt; 测试性能如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 941kiB 0:00:26 [31.9kiB/s] [36.2kiB/s]
2.86MiB 0:01:20 [36.2kiB/s] [36.2kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;对比修改前1.5.0RC2版本确实有提升(其实提升性能更大的是在filter的时候).但实际测试提升没有issues中作者写的那么大.&lt;/p&gt;
&lt;h3&gt;logstash-input-file性能对比&lt;/h3&gt;
&lt;p&gt;有了上面的结果现在对后续结果也有些预估,下面的测试只需把上面的配置文件稍作修改,修改成监听文件模式:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
    file {
        path =&amp;gt; &amp;quot;/data0/lijingbo/0.log&amp;quot;
     }
}

output {
    stdout {
             codec =&amp;gt; dots
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;命令同上:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./bin/logstash agent -f out.conf &lt;span class="p"&gt;|&lt;/span&gt; pv -Wbart &amp;gt; /dev/null
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.4.2性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;2.31MiB 0:01:18 [34.9kiB/s] [30.3kiB/s]
2.39MiB 0:01:21 [27.3kiB/s] [30.3kiB/s]
2.48MiB 0:01:24 [34.7kiB/s] [30.3kiB/s]
2.65MiB 0:01:29 [42.3kiB/s] [30.5kiB/s]
2.81MiB 0:01:34 [  36kiB/s] [30.6kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.5.0RC2性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 376kiB 0:00:20 [23.9kiB/s] [18.8kiB/s]
 498kiB 0:00:25 [27.1kiB/s] [19.9kiB/s]
 777kiB 0:00:39 [22.4kiB/s] [19.9kiB/s]
 2.08MiB 0:01:44 [20.1kiB/s] [20.4kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.5.0fix版本性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 673kiB 0:00:27 [  31kiB/s] [24.9kiB/s]
 896kiB 0:00:36 [26.5kiB/s] [24.9kiB/s]
1.09MiB 0:00:45 [25.3kiB/s] [24.8kiB/s]
1.86MiB 0:01:17 [19.1kiB/s] [24.7kiB/s]
1.91MiB 0:01:19 [29.7kiB/s] [24.8kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过上面的结果,高下立判了.对于文件读取直接输出转发的话还是1.4.2性能比较好.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;logstash-output-kafka性能对比&lt;/h3&gt;
&lt;p&gt;对于kafka的输出,由于 &lt;code&gt;1.4.2版本&lt;/code&gt; 当时没有把kafka的插件并入到logstash的默认设置里.所以在此选择手工安装 &lt;a href="http://bigbo.github.io/pages/2015/01/23/logstash_kafka/"&gt;此前介绍过&lt;/a&gt;,所选各个插件版本如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;logstash1.4.2 + kafka_2.10-0.8.1.1 + logstash-kafka-0.6.2 + jruby-kafka-0.2.1-java&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;logstash 1.5.0RC2 + logstash-output-kafka 0.1.8&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/elastic/logstash/tree/fix/perf_regression"&gt;logstash 1.5.0 (fix/perf_regression branch)&lt;/a&gt; + logstash-output-kafka 0.1.8&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对此其实可以根据github上的issues追溯到还是之前的作者对此方面有 &lt;a href="https://github.com/elastic/logstash/issues/2899"&gt;相关测试&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;同步模式&lt;/h4&gt;
&lt;p&gt;配置文件如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
 generator { count =&amp;gt; 30000000 }
}

output {
    stdout {
             codec =&amp;gt; dots
    }
  kafka {
    broker_list =&amp;gt; &amp;quot;localhost:9092&amp;quot;
    topic_id =&amp;gt; &amp;quot;test&amp;quot;
    compression_codec =&amp;gt; &amp;quot;snappy&amp;quot;
  }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;以上配置其实就是默认配置,默认配置一些选项未列出,其实默认配置走的是 &lt;code&gt;sync&lt;/code&gt; 模式.&lt;/p&gt;
&lt;p&gt;执行命令:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./bin/logstash agent -f out.conf &lt;span class="p"&gt;|&lt;/span&gt; pv -Wbart &amp;gt; /dev/null
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.4.2 + kafka_2.10-0.8.1.1 + logstash-kafka-0.6.2 + jruby-kafka-0.2.1-java 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 191kiB 0:01:04 [3.54kiB/s] [   3kiB/s]
 233kiB 0:01:17 [2.92kiB/s] [3.04kiB/s]
 275kiB 0:01:29 [3.71kiB/s] [ 3.1kiB/s]
 329kiB 0:01:45 [3.08kiB/s] [3.14kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash 1.5.0RC2 + logstash-output-kafka 0.1.8 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 456kiB 0:01:32 [5.41kiB/s] [4.96kiB/s]
 505kiB 0:01:41 [5.88kiB/s] [   5kiB/s]
 557kiB 0:01:51 [4.85kiB/s] [5.02kiB/s]
 598kiB 0:01:59 [5.69kiB/s] [5.03kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash 1.5.0 (fix/perf_regression branch) + logstash-output-kafka 0.1.8 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 440kiB 0:01:15 [7.09kiB/s] [5.88kiB/s]
 569kiB 0:01:34 [7.03kiB/s] [6.05kiB/s]
 616kiB 0:01:41 [7.21kiB/s] [ 6.1kiB/s]
 630kiB 0:01:43 [7.44kiB/s] [6.12kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h4&gt;异步模式&lt;/h4&gt;
&lt;p&gt;配置文件如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
 generator { count =&amp;gt; 30000000 }
}

output {
    stdout {
             codec =&amp;gt; dots
    }

  kafka {
    topic_id =&amp;gt; &amp;quot;test&amp;quot;
    compression_codec =&amp;gt; &amp;quot;snappy&amp;quot;
    request_required_acks =&amp;gt; 1
    serializer_class =&amp;gt; &amp;quot;kafka.serializer.StringEncoder&amp;quot;
    request_timeout_ms =&amp;gt; 10000
    producer_type =&amp;gt; &amp;#39;async&amp;#39;
    message_send_max_retries =&amp;gt; 5
    retry_backoff_ms =&amp;gt; 100
    queue_buffering_max_ms =&amp;gt; 5000
    queue_buffering_max_messages =&amp;gt; 10000
    queue_enqueue_timeout_ms =&amp;gt; -1
    batch_num_messages =&amp;gt; 1000
  }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;此配置其实同issues上的配置相同,主要是我上面测试出来的跟已有的结果差距甚大,顾选择此配置再次测试.&lt;/p&gt;
&lt;p&gt;logstash1.4.2 + kafka_2.10-0.8.1.1 + logstash-kafka-0.6.2 + jruby-kafka-0.2.1-java 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 796kiB 0:01:07 [12.6kiB/s] [11.9kiB/s]
 834kiB 0:01:10 [  12kiB/s] [11.9kiB/s]
 967kiB 0:01:20 [13.7kiB/s] [12.1kiB/s]
1.08MiB 0:01:31 [12.5kiB/s] [12.1kiB/s]
1.11MiB 0:01:33 [15.7kiB/s] [12.2kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash 1.5.0RC2 + logstash-output-kafka 0.1.8 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 649kiB 0:01:14 [7.79kiB/s] [8.77kiB/s]
 711kiB 0:01:20 [11.6kiB/s] [8.89kiB/s]
 769kiB 0:01:26 [10.4kiB/s] [8.95kiB/s]
 901kiB 0:01:39 [9.31kiB/s] [ 9.1kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash 1.5.0 (fix/perf_regression branch) + logstash-output-kafka 0.1.8 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 712kiB 0:01:16 [9.66kiB/s] [9.38kiB/s]
 765kiB 0:01:21 [11.4kiB/s] [9.45kiB/s]
 843kiB 0:01:29 [10.5kiB/s] [9.48kiB/s]
 884kiB 0:01:33 [  11kiB/s] [9.51kiB/s]
 945kiB 0:01:39 [9.38kiB/s] [9.55kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;结果显而易见了.不知道1.5版本性能问题会不会到正式解决或是提高.到时再来测试一翻.&lt;/p&gt;
&lt;h3&gt;logstash-input-file + logstash-out-kafka 性能对比&lt;/h3&gt;
&lt;p&gt;既然单独的插件测试过了, 综合的测试下两个一起使用的效果.所有条件均同上,差别仅是配置文件(异步模式).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
  file {
    path =&amp;gt; &amp;quot;/data0/lijingbo/0.log&amp;quot;
  }
}

output {
  stdout {
    codec =&amp;gt; dots
  }
  kafka {
    topic_id =&amp;gt; &amp;quot;test&amp;quot;
    compression_codec =&amp;gt; &amp;quot;snappy&amp;quot;
    request_required_acks =&amp;gt; 1
    serializer_class =&amp;gt; &amp;quot;kafka.serializer.StringEncoder&amp;quot;
    request_timeout_ms =&amp;gt; 10000
    producer_type =&amp;gt; &amp;#39;async&amp;#39;
    message_send_max_retries =&amp;gt; 5
    retry_backoff_ms =&amp;gt; 100
    queue_buffering_max_ms =&amp;gt; 5000
    queue_buffering_max_messages =&amp;gt; 10000
    queue_enqueue_timeout_ms =&amp;gt; -1
    batch_num_messages =&amp;gt; 1000
  }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;命令执行同之前.&lt;/p&gt;
&lt;p&gt;logstash1.4.2性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 735kiB 0:01:28 [12.9kiB/s] [8.36kiB/s]
 832kiB 0:01:36 [10.2kiB/s] [8.67kiB/s]
 898kiB 0:01:41 [14.1kiB/s] [ 8.9kiB/s]
 946kiB 0:01:45 [13.6kiB/s] [9.01kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.5RC2性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 720kiB 0:01:21 [11.6kiB/s] [8.89kiB/s]
 792kiB 0:01:29 [8.74kiB/s] [8.91kiB/s]
 851kiB 0:01:35 [10.1kiB/s] [8.96kiB/s]
 891kiB 0:01:39 [9.92kiB/s] [   9kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.5fix性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 986kiB 0:01:42 [10.8kiB/s] [9.67kiB/s]
 998kiB 0:01:43 [12.4kiB/s] [ 9.7kiB/s]
1.04MiB 0:01:50 [10.7kiB/s] [9.69kiB/s]
1.12MiB 0:01:58 [11.3kiB/s] [9.69kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;测试后感觉与想象中有些差距,对1.5正式版性能稳定性提升抱有希望.后续会跟进,做一些其他更多相关测试.&lt;/p&gt;</summary><category term="kafka"></category><category term="消息队列"></category><category term="logstash插件"></category><category term="日志处理"></category></entry><entry><title>elasticsearch之hadoop插件使用</title><link href="http://bigbo.github.io/pages/2015/02/28/elasticsearch_hadoop/" rel="alternate"></link><updated>2015-03-19T23:30:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-02-28:pages/2015/02/28/elasticsearch_hadoop/</id><summary type="html">&lt;h2&gt;elastic与Hadoop的连接&lt;/h2&gt;
&lt;p&gt;几个月前,由于资源有限,而需求无限,不得已想到es与hadoop的连接,本来想的很好,尝试把HDFS作为es的存储后端,把index存入HDFS中,这样就能节省存储空间了.当然官网也有相关使用配置(这里就不介绍了),经过几天的奋斗还是没能实现当初的想法,也幸亏没实现,实现了性能也是一大坑(猜测性能非常差以至于官方的 &lt;a href="https://github.com/elastic/elasticsearch-hdfs"&gt;elasticsearch-hdfs&lt;/a&gt; 插件都几年没更新了!).&lt;/p&gt;
&lt;p&gt;不过倒是尝试了把HDFS作为后端存储,可以实现备份elasticsearch数据快照到HDFS或者是从HDFS中恢复数据.选择插件 &lt;a href="https://github.com/elastic/elasticsearch-hadoop/tree/master/repository-hdfs"&gt;repository-hdfs&lt;/a&gt;,其实就是使用了ES的 &lt;code&gt;snapshot/restore&lt;/code&gt; 功能.&lt;/p&gt;
&lt;h2&gt;安装插件&lt;/h2&gt;
&lt;p&gt;我的es版本为 &lt;code&gt;1.3.9-1&lt;/code&gt;,注意: &lt;code&gt;1.3.0-1.3.7 and 1.4.0-1.4.2&lt;/code&gt; 存在&lt;a href="https://www.elastic.co/blog/elasticsearch-1-4-3-and-1-3-8-released/"&gt;Grooy漏洞&lt;/a&gt;,所以选择版本的时候注意下,插件选择版本对应为2.0.2,后端Hadoop为2.5.0,安装方式如下: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;./bin/plugin -i elasticsearch/elasticsearch-repository-hdfs/2.0.2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当然像我这样没外网的可以选择 &lt;a href="https://oss.sonatype.org/content/repositories/snapshots/org/elasticsearch/elasticsearch-repository-hdfs/"&gt;插件下载&lt;/a&gt;,选择对应的版本,解压拷贝到es的plugin目录.&lt;/p&gt;
&lt;h2&gt;配置使用&lt;/h2&gt;
&lt;h4&gt;直接用curl法:&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;curl -XPUT &amp;#39;http://localhost:9200/_snapshot/backup&amp;#39; -d &amp;#39;{
  &amp;quot;type&amp;quot;: &amp;quot;hdfs&amp;quot;,
    &amp;quot;settings&amp;quot;: {
            &amp;quot;uri&amp;quot;: &amp;quot;hdfs://hadoop:8020&amp;quot;,
            &amp;quot;path&amp;quot;: &amp;quot;/test/es&amp;quot;,
            &amp;quot;conf_location&amp;quot;: &amp;quot;hdfs-site.xml&amp;quot;
    }
}&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;返回 &lt;code&gt;{"acknowledged":true}&lt;/code&gt; 表示创建成功.&lt;/p&gt;
&lt;h5&gt;查看创建的配置:&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;curl http://localhost:9200/_snapshot/_all
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以看到返回刚才配置信息.&lt;/p&gt;
&lt;h5&gt;测试备份数据&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;curl -XPUT &amp;quot;localhost:9200/_snapshot/backup/snapshot_1?wait_for_completion=true&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;尝试去看下HDFS上是否有刚才备份的文件,访问 &lt;code&gt;http://hadoop:50070/explorer.html#/test/es&lt;/code&gt; 便可以看到相关的快照文件.&lt;/p&gt;
&lt;h5&gt;测试还原数据&lt;/h5&gt;
&lt;p&gt;通过快照还原数据,测试前可以把之前测试做过备份的索引进行删除,然后通过如下命令进行数据恢复:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;curl -XPOST &amp;quot;localhost:9200/_snapshot/backup/snapshot_1/_restore?wait_for_completion=true&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;通过kopf插件进行设置&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/lmenezes/elasticsearch-kopf"&gt;elasticsearch-kopf&lt;/a&gt;,是一个对es集群管理综合插件,无需安装&lt;a href="http://lmenezes.com/elasticsearch-kopf/?location=http://localhost:9200"&gt;体验地址&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;备份恢复快照设置如图:&lt;/p&gt;
&lt;p&gt;&lt;img alt="rsyslog" src="/pictures/es_hdfs.png" title="u&amp;quot;kopf设置&amp;quot;" /&gt;&lt;/p&gt;</summary><category term="elasticsearch 快照"></category><category term="elasticsearch plugin"></category><category term="HDFS"></category></entry><entry><title>logstash的kafka插件使用</title><link href="http://bigbo.github.io/pages/2015/01/23/logstash_kafka/" rel="alternate"></link><updated>2015-01-23T19:30:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-23:pages/2015/01/23/logstash_kafka/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;关于logstash可以产看其 &lt;a href="http://logstash.net/"&gt;官网&lt;/a&gt; ,对于英文有障碍的人士,或是想知道更多插件使用技巧的用户请移步 &lt;a href="http://chenlinux.com/"&gt;@三斗室&lt;/a&gt; 所著作 &lt;a href="https://github.com/bigbo/logstash-best-practice-cn"&gt;logstash最佳实战&lt;/a&gt; ,本片内容已经并入其中相关章节.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Logstash-kafka简介&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/joekiller/logstash-kafka"&gt;https://github.com/joekiller/logstash-kafka&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;插件已经正式合并进官方仓库，以下使用介绍基于&lt;strong&gt;logstash 1.4相关版本&lt;/strong&gt;，1.5及以后版本的使用后续依照官方文档持续更新。&lt;/p&gt;
&lt;p&gt;插件本身内容非常简单，其主要依赖同一作者写的 &lt;a href="https://github.com/joekiller/jruby-kafka"&gt;jruby-kafka&lt;/a&gt; 模块。需要注意的是：&lt;strong&gt;该模块仅支持 Kafka－0.8 版本。如果是使用 0.7 版本 kafka 的，将无法直接使 jruby-kafka 该模块和 logstash-kafka 插件。&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;安装&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;安装按照官方文档完全自动化的安装.或是可以通过以下方式手动自己安装插件，不过重点注意的是 &lt;strong&gt;kafka 的版本&lt;/strong&gt;，上面已经指出了。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;下载 logstash 并解压重命名为 &lt;code&gt;./logstash-1.4.0&lt;/code&gt; 文件目录。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;下载 kafka 相关组件，以下示例选的为 &lt;a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.1.1/kafka-0.8.1.1-src.tgz"&gt;kafka_2.8.0-0.8.1.1-src&lt;/a&gt;，并解压重命名为 &lt;code&gt;./kafka_2.8.0-0.8.1.1&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;下载 logstash-kafka v0.4.2 从 &lt;a href="https://github.com/joekiller/logstash-kafka/releases"&gt;releases&lt;/a&gt;，并解压重命名为 &lt;code&gt;./logstash-kafka-0.4.2&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从 &lt;code&gt;./kafka_2.8.0-0.8.1.1/libs&lt;/code&gt; 目录下复制所有的 jar 文件拷贝到 &lt;code&gt;./logstash-1.4.0/vendor/jar/kafka_2.8.0-0.8.1.1/libs&lt;/code&gt; 下，其中你需要创建 &lt;code&gt;kafka_2.8.0-0.8.1.1/libs&lt;/code&gt; 相关文件夹及目录。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分别复制 &lt;code&gt;./logstash-kafka-0.4.2/logstash&lt;/code&gt; 里的 &lt;code&gt;inputs&lt;/code&gt; 和 &lt;code&gt;outputs&lt;/code&gt; 下的 &lt;code&gt;kafka.rb&lt;/code&gt;，拷贝到对应的 &lt;code&gt;./logstash-1.4.0/lib/logstash&lt;/code&gt; 里的 &lt;code&gt;inputs&lt;/code&gt; 和 &lt;code&gt;outputs&lt;/code&gt; 对应目录下。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;切换到 &lt;code&gt;./logstash-1.4.0&lt;/code&gt; 目录下，现在需要运行 logstash-kafka 的 gembag.rb 脚本去安装 jruby-kafka 库，执行以下命令： &lt;code&gt;GEM_HOME=vendor/bundle/jruby/1.9 GEM_PATH= java -jar vendor/jar/jruby-complete-1.7.11.jar --1.9 ../logstash-kafka-0.4.2/gembag.rb ../logstash-kafka-0.4.2/logstash-kafka.gemspec&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;现在可以使用 logstash-kafka 插件运行 logstash 了。例如：&lt;code&gt;bin/logstash agent -f logstash.conf&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Input 配置示例&lt;/h2&gt;
&lt;p&gt;以下配置可以实现对 kafka 读取端(consumer)的基本使用。&lt;/p&gt;
&lt;p&gt;消费端更多详细的配置请查看 &lt;a href="http://kafka.apache.org/documentation.html#consumerconfigs"&gt;http://kafka.apache.org/documentation.html#consumerconfigs&lt;/a&gt; kafka 官方文档的消费者部分配置文档。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
    kafka {
        zk_connect =&amp;gt; &amp;quot;localhost:2181&amp;quot;
        group_id =&amp;gt; &amp;quot;logstash&amp;quot;
        topic_id =&amp;gt; &amp;quot;test&amp;quot;
        reset_beginning =&amp;gt; false # boolean (optional)， default: false
        consumer_threads =&amp;gt; 5  # number (optional)， default: 1
        decorate_events =&amp;gt; true # boolean (optional)， default: false
        }
    }
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Input 解释&lt;/h2&gt;
&lt;p&gt;消费端的一些比较有用的配置项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;group_id&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;消费者分组，可以通过组 ID 去指定，不同的组之间消费是相互不受影响的，相互隔离。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;topic_id&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;指定消费话题，也是必填项目，指定消费某个 &lt;code&gt;topic&lt;/code&gt; ，这个其实就是订阅某个主题，然后去消费。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;reset_beginning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;logstash 启动后从什么位置开始读取数据，默认是结束位置，也就是说 logstash 进程会以从上次读取结束时的偏移量开始继续读取，如果之前没有消费过，那么就开始从头读取.如果你是要导入原有数据，把这个设定改成 "true"， logstash 进程就从头开始读取.有点类似 &lt;code&gt;cat&lt;/code&gt; ，但是读到最后一行不会终止，而是变成 &lt;code&gt;tail -F&lt;/code&gt; ，继续监听相应数据。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;decorate_events&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在输出消息的时候会输出自身的信息包括:消费消息的大小， topic 来源以及 consumer 的 group 信息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rebalance_max_retries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当有新的 consumer(logstash) 加入到同一 group 时，将会 &lt;code&gt;reblance&lt;/code&gt; ，此后将会有 &lt;code&gt;partitions&lt;/code&gt; 的消费端迁移到新的 &lt;code&gt;consumer&lt;/code&gt; 上，如果一个 &lt;code&gt;consumer&lt;/code&gt; 获得了某个 &lt;code&gt;partition&lt;/code&gt; 的消费权限，那么它将会向 &lt;code&gt;zookeeper&lt;/code&gt; 注册， &lt;code&gt;Partition Owner registry&lt;/code&gt; 节点信息，但是有可能此时旧的 &lt;code&gt;consumer&lt;/code&gt; 尚没有释放此节点，此值用于控制，注册节点的重试次数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;consumer_timeout_ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;指定时间内没有消息到达就抛出异常，一般不需要改。&lt;/p&gt;
&lt;p&gt;以上是相对重要参数的使用示例，更多参数可以选项可以跟据 &lt;a href="https://github.com/joekiller/logstash-kafka/blob/master/README.md"&gt;https://github.com/joekiller/logstash-kafka/blob/master/README.md&lt;/a&gt; 查看 input 默认参数。&lt;/p&gt;
&lt;h2&gt;注意&lt;/h2&gt;
&lt;p&gt;1.想要使用多个 logstash 端协同消费同一个 &lt;code&gt;topic&lt;/code&gt; 的话，那么需要把两个或是多个 logstash 消费端配置成相同的 &lt;code&gt;group_id&lt;/code&gt; 和 &lt;code&gt;topic_id&lt;/code&gt;， 但是前提是要把&lt;strong&gt;相应的 topic 分多个 partitions (区)&lt;/strong&gt;，多个消费者消费是无法保证消息的消费顺序性的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里解释下，为什么要分多个 &lt;strong&gt;partitions(区)&lt;/strong&gt;， kafka 的消息模型是对 topic 分区以达到分布式效果。每个 &lt;code&gt;topic&lt;/code&gt; 下的不同的 &lt;strong&gt;partitions (区)&lt;/strong&gt;只能有一个 &lt;strong&gt;Owner&lt;/strong&gt; 去消费。所以只有多个分区后才能启动多个消费者，对应不同的区去消费。其中协调消费部分是由 server 端协调而成。不必使用者考虑太多。只是&lt;strong&gt;消息的消费则是无序的&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;总结:保证消息的顺序，那就用一个 &lt;strong&gt;partition&lt;/strong&gt;。 &lt;strong&gt;kafka 的每个 partition 只能同时被同一个 group 中的一个 consumer 消费&lt;/strong&gt;。&lt;/p&gt;
&lt;h2&gt;Output 配置&lt;/h2&gt;
&lt;p&gt;以下配置可以实现对 kafka 写入端 (producer) 的基本使用。&lt;/p&gt;
&lt;p&gt;生产端更多详细的配置请查看 &lt;a href="http://kafka.apache.org/documentation.html#producerconfigs"&gt;http://kafka.apache.org/documentation.html#producerconfigs&lt;/a&gt; kafka 官方文档的生产者部分配置文档。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; output {
    kafka {
        broker_list =&amp;gt; &amp;quot;localhost:9092&amp;quot;
        topic_id =&amp;gt; &amp;quot;test&amp;quot;
        compression_codec =&amp;gt; &amp;quot;snappy&amp;quot; # string (optional)， one of [&amp;quot;none&amp;quot;， &amp;quot;gzip&amp;quot;， &amp;quot;snappy&amp;quot;]， default: &amp;quot;none&amp;quot;
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Output 解释&lt;/h2&gt;
&lt;p&gt;生产的可设置性还是很多的，设置其实更多，以下是更多的设置：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;compression_codec&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;消息的压缩模式，默认是 none，可以有 gzip 和 snappy (暂时还未测试开启压缩与不开启的性能，数据传输大小等对比)。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;compressed_topics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以针对特定的 topic 进行压缩，设置这个参数为 &lt;code&gt;topic&lt;/code&gt; ，表示此 &lt;code&gt;topic&lt;/code&gt; 进行压缩。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;request_required_acks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;消息的确认模式:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;可以设置为 0: 生产者不等待 broker 的回应，只管发送.会有最低能的延迟和最差的保证性(在服务器失败后会导致信息丢失)&lt;/p&gt;
&lt;p&gt;可以设置为 1: 生产者会收到 leader 的回应在 leader 写入之后.(在当前 leader 服务器为复制前失败可能会导致信息丢失)&lt;/p&gt;
&lt;p&gt;可以设置为 -1: 生产者会收到 leader 的回应在全部拷贝完成之后。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;partitioner_class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分区的策略，默认是 hash 取模&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;send_buffer_bytes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;socket 的缓存大小设置，其实就是缓冲区的大小&lt;/p&gt;
&lt;h4&gt;消息模式相关&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;serializer_class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;消息体的系列化处理类，转化为字节流进行传输，&lt;strong&gt;请注意 encoder 必须和下面的 &lt;code&gt;key_serializer_class&lt;/code&gt; 使用相同的类型&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;key_serializer_class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;默认的是与 &lt;code&gt;serializer_class&lt;/code&gt; 相同&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;producer_type&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生产者的类型 &lt;code&gt;async&lt;/code&gt; 异步执行消息的发送 &lt;code&gt;sync&lt;/code&gt; 同步执行消息的发送&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;queue_buffering_max_ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;异步模式下&lt;/strong&gt;，那么就会在设置的时间缓存消息，并一次性发送&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;queue_buffering_max_messages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;异步的模式下&lt;/strong&gt;，最长等待的消息数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;queue_enqueue_timeout_ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;异步模式下&lt;/strong&gt;，进入队列的等待时间，若是设置为0，那么要么进入队列，要么直接抛弃&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;batch_num_messages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;异步模式下&lt;/strong&gt;，每次发送的最大消息数，前提是触发了 &lt;code&gt;queue_buffering_max_messages&lt;/code&gt; 或是 &lt;code&gt;queue_enqueue_timeout_ms&lt;/code&gt; 的限制&lt;/p&gt;
&lt;p&gt;以上是相对重要参数的使用示例，更多参数可以选项可以跟据 &lt;a href="https://github.com/joekiller/logstash-kafka/blob/master/README.md"&gt;https://github.com/joekiller/logstash-kafka/blob/master/README.md&lt;/a&gt; 查看 output 默认参数。&lt;/p&gt;
&lt;h3&gt;小贴士&lt;/h3&gt;
&lt;p&gt;默认情况下，插件是使用 json 编码来输入和输出相应的消息，消息传递过程中 logstash 默认会为消息编码内加入相应的时间戳和 hostname 等信息。如果不想要以上信息(一般做消息转发的情况下)，可以使用以下配置，例如:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; output {
    kafka {
        codec =&amp;gt; plain {
            format =&amp;gt; &amp;quot;%{message}&amp;quot;
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;</summary><category term="kafka"></category><category term="消息队列"></category><category term="logstash"></category><category term="日志处理"></category></entry><entry><title>rsyslog与Kafka结合使用</title><link href="http://bigbo.github.io/pages/2015/01/21/syslog_kafka/" rel="alternate"></link><updated>2015-01-21T15:40:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-21:pages/2015/01/21/syslog_kafka/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;最近在折腾 &lt;a href="http://www.rsyslog.com/"&gt;Rsyslog&lt;/a&gt; ,传输日志,对他怎么说呢,谁用谁知道,我仅仅是了解使用的程度,对于里面的坑以及使用策略还没有那么深入,不过日后会逐步的细化了解,其实现在对于日志传输来过网上一大堆技术方案任你选.但是感觉用rsyslog传输还是最方便,最快捷的.他以不变应万变,看图说话:&lt;/p&gt;
&lt;p&gt;&lt;img alt="rsyslog" src="/pictures/rsyslog_1.png" title="u&amp;quot;rsyslog支持图&amp;quot;" /&gt;&lt;/p&gt;
&lt;p&gt;可见rsyslog的覆盖面是相当的广泛.奈何近几日,打算把redis替换为 &lt;a href="http://kafka.apache.org/"&gt;kafka&lt;/a&gt; ,本篇主要记录 &lt;code&gt;rsyslog&lt;/code&gt; 与 &lt;code&gt;kafka&lt;/code&gt; 的对接使用. 上了.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Rsyslog对kafka的支持&lt;/h2&gt;
&lt;p&gt;通过对 &lt;a href="http://www.rsyslog.com/doc/master/configuration/modules/omkafka.html#example"&gt;rsyslog官方文档&lt;/a&gt; 查看,得知 &lt;code&gt;rsyslog&lt;/code&gt; 对 &lt;code&gt;kafka&lt;/code&gt; 的支持是 &lt;code&gt;v8.7.0&lt;/code&gt; 版本后才提供的支持.通过 &lt;a href="https://github.com/rsyslog/rsyslog/blob/v8-stable/ChangeLog"&gt;ChangeLog&lt;/a&gt; 也可以看出 &lt;code&gt;V8.X&lt;/code&gt; 的版本变化.&lt;/p&gt;
&lt;p&gt;查看本机的rsyslog版本:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;rsyslog.x86_64                                      7.6.3-1.el6
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;先是升级.升级方式有多种,推荐使用 &lt;a href="http://www.rsyslog.com/rhelcentos-rpms/"&gt;官方源用&lt;/a&gt; &lt;code&gt;yum&lt;/code&gt; 方式升级.使用源升级后的稳定版目前最新的是 &lt;code&gt;8.7.0-1.el6&lt;/code&gt; ,来查看下rpm包中是否包含 &lt;code&gt;omkafka&lt;/code&gt; 这个插件.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;# rpm -ql rsyslog
.......
/lib64/rsyslog/lmzlibw.so
/lib64/rsyslog/mmpstrucdata.so
.......
#主要看/lib64/rsyslog/目录下的.so文件
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;经过查看其实rpm包编译的版本中是不包含 &lt;code&gt;kafka&lt;/code&gt; 的插件的.经过下载源码包查看,源码包中包含此模块,估计是rpm包编译的时候没有加入进去吧.所以选择自己编译这个模块,编译好了拷贝到相应目录.&lt;/p&gt;
&lt;p&gt;下载源码包,使用 &lt;code&gt;./configure -h&lt;/code&gt; 查看帮助信息.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;  --enable-omkafka        Compiles omkafka module [default=no]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以清楚的查看到其实这个模块默认是不开启的.所以自己编译加入这个模块,编译好会在相应目录产生 &lt;code&gt;omkafka.so&lt;/code&gt; 这个文件,然后拷贝到 &lt;code&gt;/lib64/rsyslog/&lt;/code&gt; 目录下即可.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;体验+设置&lt;/h2&gt;
&lt;p&gt;使用需要在 &lt;code&gt;rsyslog.conf&lt;/code&gt; 配置文件下或是相应的配置文件中加入 &lt;code&gt;module(load="omkafka")&lt;/code&gt; 表示引入该模块.测试使用可以参照 &lt;a href="http://www.rsyslog.com/doc/master/configuration/modules/omkafka.html#example"&gt;文档中的示例&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;其实文档是相当的简陋,使用示例感觉就是配置上仅仅能使用,更多更详细的根本没有介绍,索性 &lt;a href="http://kafka.apache.org/documentation.html#producerconfigs"&gt;kafka官方的文档&lt;/a&gt; 是相当的详细.在使用的角度看,rsyslog目前是作为一个 &lt;strong&gt;Producer&lt;/strong&gt; 的角色,所以可以依照kafka的文档的 &lt;strong&gt;3.3Producer Configs&lt;/strong&gt; 章节设置,设置相应的参数可以放到 &lt;code&gt;confParam&lt;/code&gt; 或是 &lt;code&gt;topicConfParam&lt;/code&gt; 中就可以了.当然这个参数列表不是无限任何参数都可以往里面仍,根据rsyslog官方文档对这个参数的表述是:其实 &lt;strong&gt;omkafka&lt;/strong&gt; 是使用 &lt;code&gt;librdkafka&lt;/code&gt; 连接卡夫卡的,所以参数实际上那些 &lt;code&gt;librdkafka&lt;/code&gt; 支持的参数.&lt;/p&gt;
&lt;p&gt;仅仅测试的话,根据rsyslog官方文档中配置即可生效.更多的设置和方法还是参照kafka相关设置,以及经过自己充分测试再另行体验,由于我也是才接触配置,更多的使用也不太了解.没有文档真的很瞎啊,但是至少知道了大致怎么使用了.目前的体验来看 &lt;code&gt;partitions.number&lt;/code&gt; 等参数是很好用的.&lt;/p&gt;
&lt;p&gt;rsyslog的kafka模块使用 &lt;a href="http://lists.adiscon.net/pipermail/rsyslog/2014-December/039291.html"&gt;问答列表&lt;/a&gt;&lt;/p&gt;</summary><category term="kafka"></category><category term="消息队列"></category><category term="rsyslog"></category></entry><entry><title>kafka监控web端(添砖)</title><link href="http://bigbo.github.io/pages/2015/01/17/kafka_web_console/" rel="alternate"></link><updated>2015-01-17T15:40:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-17:pages/2015/01/17/kafka_web_console/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;最近在了解消息队列,主要是之前用的是redis,redis固然非常好用,但是也有相应的使用场景.随着数据量的增长,redis已经不能满足现在的需求了.所以需要找个更好的替代品.问了一圈大牛,也google一番,锁定在&lt;a href="http://kafka.apache.org/"&gt;kafka&lt;/a&gt;上了.关于&lt;strong&gt;kafka&lt;/strong&gt;怎么"玩",我也不知道,算是在摸索当中,想要知道安装使用等方法,请移步Google吧.虽然kafka我不会玩,但是我会玩怎么监控它.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;简介&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com/claudemamo/kafka-web-console"&gt;kafka-web-console&lt;/a&gt;,是kafka自己的一个Web管理界面.开源的东西好是好,但是不知道是不是开源的大牛B们都不愿意写文档!!出来个东西,居然没有安装步骤,只是有一些简单的使用说明,甚至说明都不详细,对于此点表示很坑!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;安装&lt;/h2&gt;
&lt;blockquote&gt;
&lt;h5&gt;1.先下载安装scala构建工具&lt;a href="http://www.scala-sbt.org/0.13/tutorial/Installing-sbt-on-Linux.html"&gt;sbt&lt;/a&gt;&lt;/h5&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; #本安装环境为centos6.5
 curl https://bintray.com/sbt/rpm/rpm &amp;gt; bintray-sbt-rpm.repo
 sudo mv bintray-sbt-rpm.repo /etc/yum.repos.d/
 sudo yum install sbt
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;h5&gt;2.下载&lt;strong&gt;kafka-web-console&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;git clone https://github.com/claudemamo/kafka-web-console&lt;/code&gt;&lt;/p&gt;
&lt;h5&gt;3.构建包&lt;/h5&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cd kafka-web-console/  
sbt dist
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;此处是构建出一个可用的standalone包来,以后用的话直接部署使用即可.另外,网上有写教程有说需要设置下数据库等设置,看着有些麻烦,默认的数据库是H2,我没有设置其他的数据库,以我的成功案例来看,此处保持默认设置即可.&lt;/p&gt;
&lt;p&gt;补充:其实早就相对GFW说生祝福了,用sbt构建包的时候问题多多,主要都是下载相关依赖的问题.好多依赖已经被墙了,以至于下载巨慢无比,甚至下载失败.有此问题的请挂代理.sbt怎么设置代理?你问我,我也不会,但是总有人会,请异步---&amp;gt;&lt;a href="http://stackoverflow.com/questions/13803459/how-to-use-sbt-from-behind-proxy"&gt;sbt构建代理设置&lt;/a&gt;&lt;/p&gt;
&lt;h5&gt;4.部署运行&lt;/h5&gt;
&lt;p&gt;当你顺利的构建完成之后,在&lt;code&gt;kafka-web-console/target/universal&lt;/code&gt;下出先一个压缩包.此压缩包正是刚才编译出的应用端.解压zip即可.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;unzip kafka-web-console-2.1.0-SNAPSHOT.zip  
cd kafka-web-console-2.1.0-SNAPSHOT/bin
#第一次启动加个参数不然报错
./kafka-web-console -DapplyEvolutions.default=true
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;至此你可以访问相应的机器的9000端口就可以体验了.&lt;/p&gt;
&lt;h5&gt;查看帮助以及后台运行&lt;/h5&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;./kafka-web-console -h  
nohup ./kafka-web-console &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;其实关于kafka相关的知识相当匮乏,林林总总的通过各种博客看了一些简介,摸着石头过河.后续有对kafka的研究再进行记录了解.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 提示: &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;关于kafka-web-console的使用要注意,实际使用发现,&lt;strong&gt; 会产生过多的TCP连接,导致抢占过多系统资源不说还占用过多的系统端口 &lt;/strong&gt;.由于对java一窍不通,所以也没搞明白什么原因导致.另外其监控效果也不好,图形非常不准.&lt;/p&gt;
&lt;p&gt;推荐另外一个监控系统 &lt;code&gt;KafkaOffsetMonitor&lt;/code&gt; ,用来实时监控Kafka集群的consumers以及它们在partition中的offset(偏移量).体验非常不错.唯一缺点是其中前端js部分可能用到了Google的前端公开库,导致身在天朝的人打开较慢或是直接打不开,需要注意下.&lt;/p&gt;</summary><category term="kafka"></category><category term="消息队列"></category><category term="监控"></category></entry><entry><title>MooseFS浅析(三)--chunk存储选择算法(搬砖)</title><link href="http://bigbo.github.io/pages/2015/01/16/Moosefs_three/" rel="alternate"></link><updated>2015-01-17T19:40:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-16:pages/2015/01/16/Moosefs_three/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;如果自己设计一套chunkserver选择算法,我们要达到哪些目标呢?&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;文件打散后尽量平均分布到各台chunkserver上&lt;/li&gt;
&lt;li&gt;各台chunkserver上的chunk数量尽可能的平均&lt;/li&gt;
&lt;li&gt;数据分发过程衡量系统负载，尽量把数据放在负载低的chunkserver上&lt;/li&gt;
&lt;li&gt;数据分发过程是否应该衡量各台chunkserver的可用空间?&lt;/li&gt;
&lt;li&gt;机架感应?&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;回到MFS使用过程中会有一个疑问.chunkserver的选择是怎么选择的.怎么才能保证数据保存占用空间平衡甚至平均?这就是数据分布算法.也正是分布式文件系统的核心容.所以在此,转来一篇关于MFS的chunk存储选择算法的文章.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;核心算法&lt;/h2&gt;
&lt;p&gt;还记得matocsserventry结构中的carry字段么,这个字段就是分布算法的核心.每台chunkserver会有自己的carry值,在选择chunkserver会将每台chunkserver按照carry从大到小做快速排序,优先选择carry值大的chunkserver来使用.&lt;/p&gt;
&lt;p&gt;在描述具体算法前,先介绍三个概念:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;allcnt:mfs中可用的chunkserver的个数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;availcnt:mfs中当前可以直接存储数据的chunkserver的个数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;demand:当前文件的副本数目&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;先说allcnt,可用的chunkserver要满足下面几个条件:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;chunkserver是活着的&lt;/li&gt;
&lt;li&gt;chunkserver的总空间大于0&lt;/li&gt;
&lt;li&gt;chunkserver的可用空间(总空间-使用空间)大于1G&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;availcnt指的是carry值大于1的可用chunkserver的个数.也就是在allcnt的约束条件上加一条carry值大于1.文件1.txt需要存储2个副本,但是mfs中仅仅有1台chunkserver可用,也就是&lt;code&gt;demand&amp;gt;allcnt&lt;/code&gt;的时候,mfs会自动减少文件的副本个数到allcnt,保证文件可以成功写入系统.&lt;/p&gt;
&lt;p&gt;关于carry有下面几个规则:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;仅carry值大于1的chunkserver可以存储新数据&lt;/li&gt;
&lt;li&gt;每台chunkserver存储新数据后其carry会减1&lt;/li&gt;
&lt;li&gt;demand&amp;gt;availcnt的时候，会递归的增加每台chunkserver的carry值，直到&lt;code&gt;demand&amp;lt;=availcnt&lt;/code&gt;为止&lt;/li&gt;
&lt;li&gt;每台chunkserver每次carry值的增加量等于当前chunkserver总空间除以最大的chunkserver总空间&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;上面的规则比较复杂.举个例子就更加清晰了.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：totalspace:3.94G carry:0.463254
chunkserver 2：totalspace:7.87G carry:0.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;文件1.txt大小1k,mfs默认一个chunk大小为64M,所以仅仅需要一个chunk就够了.此时 availcnt=0,demand=1,所以需要增加carry值&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：carry=0.463254 + (3.94/7.87) = 0.463254 + 0.500005 = 0.963259
chunkserver 2：carry=0.885674 + (7.87/7.87) = 0.885674 + 1.000000 = 1.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;此时 availcnt=1,demand=1,所以不需要增加carry值,对chunkserver按照carry从大到小排序结果为:&lt;code&gt;chunkserver 2 &amp;gt; chunkserver 1&lt;/code&gt;,文件1.txt的chunk会存储到chunkserver 2上,同时chunkserver 2的carry会减1&lt;/p&gt;
&lt;p&gt;如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：carry=0.963259
chunkserver 2：carry=1.885674 – 1 = 0.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;文件2.txt大小1k,mfs默认一个chunk大小为64M,所以仅仅需要一个chunk就够了.此时 availcnt=0,demand=1.所以需要增加carry值&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：carry=0.963259 + (3.94/7.87) = 0.963259 + 0.500005 = 1.463264
chunkserver 2：carry=0.885674 + (7.87/7.87) = 0.885674 + 1.000000 = 1.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;此时 availcnt=2,demand=1,所以不需要增加carry值,对chunkserver按照carry从大到小排序结果为:&lt;code&gt;chunkserver 2 &amp;gt; chunkserver 1&lt;/code&gt;,文件2.txt的chunk会存储到chunkserver 2上,同时chunkserver 2的carry会减1&lt;/p&gt;
&lt;p&gt;如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：carry=1.463264
chunkserver 2：carry=1.885674 – 1 = 0.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;文件3.txt大小1k,mfs默认一个chunk大小为64M,所以仅仅需要一个chunk就够了.此时availcnt=1,demand=1,所以不需要增加carry值.对chunkserver按照carry从大到小排序结果为:&lt;code&gt;chunkserver 1 &amp;gt; chunkserver 2&lt;/code&gt;,文件3.txt的chunk会存储到chunkserver 1上,同时chunkserver 1的carry会减1&lt;/p&gt;
&lt;p&gt;如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：carry=1.463264 – 1 = 0.463264
chunkserver 2：carry=0.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;因为两台chunkserver的总空间大小不一致,根据算法总空间大的那台chunkserver会存储更多的新数据.&lt;/p&gt;
&lt;p&gt;记住:&lt;strong&gt;仅仅和chunkserver的总空间有关系和可用空间没有任何关系&lt;/strong&gt;,也就是说,当各台chunkserver总空间大小差不多的情况下,chunk能更好的平均分布,否则mfs会更倾向于选择总空间大的机器来使用.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;最后一个问题,当mfs刚刚启动的时候,carry值是如果获得的?&lt;/p&gt;
&lt;p&gt;答案:随机产生,通过rndu32()这个函数,随机产生一个小于1,大于等于0的数.&lt;/p&gt;
&lt;p&gt;测试结果如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Nov 23 01:01:25 sunwg mfsmaster[13175]: 192.168.0.159,0.594834
Nov 23 01:01:25 sunwg mfsmaster[13175]: 192.168.0.160,0.000000
Nov 23 01:03:58 sunwg mfsmaster[13187]: 192.168.0.159,0.516242
Nov 23 01:03:58 sunwg mfsmaster[13187]: 192.168.0.160,0.826559
Nov 23 01:04:17 sunwg mfsmaster[13192]: 192.168.0.159,0.123765
Nov 23 01:04:17 sunwg mfsmaster[13192]: 192.168.0.160,0.389592
&lt;/pre&gt;&lt;/div&gt;</summary><category term="分布式文件系统"></category><category term="Moosefs"></category><category term="分布式存储"></category></entry><entry><title>Pelican设置及插件使用</title><link href="http://bigbo.github.io/pages/2015/01/13/blog_plugin/" rel="alternate"></link><updated>2015-01-14T13:50:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-13:pages/2015/01/13/blog_plugin/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;博客算是正式用起来了,觉得还不错,但是经过查看或是浏览其他人的博客,感觉自己的还是那么的low.为什么呢?因为没有选择一个高大上的主题,没有使用优秀的插件,没有做相关优化.查了查,还有好多后续工作要做.以下就对博客的插件等设置使用总结下.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;主题设置&lt;/h2&gt;
&lt;p&gt;简单粗暴的设置可以看&lt;a href="http://bigbo.github.io/pages/2014/12/28/create-blog/"&gt;这里&lt;/a&gt;主题设置相关简介.但是我还想说,上面的那些设置还远远不够.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里推荐一些优秀的主题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/talha131/pelican-elegant"&gt;Elegant&lt;/a&gt;,清俗淡雅.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/DandyDev/pelican-bootstrap3"&gt;pelican-bootstrap3&lt;/a&gt;,我早期用的一个主题,其中自己改了一些东西.此主题有些问题在于宽屏展示的会出现字体有宽边.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/jsliang/pelican-fresh"&gt;pelican-fresh&lt;/a&gt;.我现在使用的主题.各方面还都不错.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然其实还有好多的优秀主题没有加入到&lt;a href="https://github.com/getpelican/pelican-themes"&gt;官方主题库&lt;/a&gt;,要善用github的搜索功能.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;插件设置&lt;/h2&gt;
&lt;p&gt;插件的使用会使你的博客增添一些好的功能.例如评论功能.这里我推荐一些不错值得装的插件.另外官方也有提供&lt;a href="https://github.com/getpelican/pelican-plugins"&gt;插件库&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;sitemap&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/sitemap"&gt;sitemap&lt;/a&gt;可以生成xml和txt格式的网站地图,配置见插件的readme.&lt;/p&gt;
&lt;h4&gt;gzip_cache&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/gzip_cache"&gt;gzip_cache&lt;/a&gt;,可以将所有的页面压缩为gz格式,相对来说能加快页面的加载速度.&lt;/p&gt;
&lt;h4&gt;neighbors&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/davidlesieur/multi_neighbors"&gt;neighbors&lt;/a&gt;,邻居导航,也就是我们常说的上一篇下一篇文章&lt;/p&gt;
&lt;h4&gt;related_posts&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/LawrenceWoodman/related_posts-jekyll_plugin"&gt;related_posts&lt;/a&gt;,相关文章,根据tags判断的&lt;/p&gt;
&lt;p&gt;想使用当然还需要在配置文件&lt;strong&gt;pelicanconf.py&lt;/strong&gt;中进行设置.例如:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;## 插件目录
PLUGIN_PATHS = [u&amp;quot;pelican-plugins&amp;quot;]

PLUGINS = [u&amp;quot;sitemap&amp;quot;,u&amp;quot;gzip_cache&amp;quot;,u&amp;quot;neighbors&amp;quot;,u&amp;quot;related_posts&amp;quot;]

## 配置sitemap 插件
SITEMAP = {
    &amp;quot;format&amp;quot;: &amp;quot;xml&amp;quot;,
    &amp;quot;priorities&amp;quot;: {
        &amp;quot;articles&amp;quot;: 0.7,
        &amp;quot;indexes&amp;quot;: 0.5,
        &amp;quot;pages&amp;quot;: 0.3,
    },
    &amp;quot;changefreqs&amp;quot;: {
        &amp;quot;articles&amp;quot;: &amp;quot;monthly&amp;quot;,
        &amp;quot;indexes&amp;quot;: &amp;quot;daily&amp;quot;,
        &amp;quot;pages&amp;quot;: &amp;quot;monthly&amp;quot;,
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h2&gt;加载慢的解决&lt;/h2&gt;
&lt;p&gt;当博客上传到github能正常访问后,你就会发现一个问题,加载太TMD慢了!还能不能让然正常的访问了!经过调试,发现是前端&lt;strong&gt;css&lt;/strong&gt;资源需要加载&lt;a href="fonts.googleapi.com"&gt;Google的字体服务&lt;/a&gt;时间过长导致.可以认定是GFW给封了.罪过罪过.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;解决方法&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1.下载字体文件,到网站的静态文件夹内,具体可以参考&lt;a href="http://sudodev.cn/articles/354.html"&gt;让wordpress主题绕开对google的依赖&lt;/a&gt;.不过此种方法也有些问题.把静态资源放到Github上加载时间也没别之前好多少.&lt;/li&gt;
&lt;li&gt;2.把Google的静态公共库替换为国内的公共库.例如我的给替换成&lt;a href="fonts.useso.com"&gt;360的镜像地址&lt;/a&gt;.其实这种方法也有些弊端,例如国外用户访问就会出现加载过慢的问题.但是毕竟我们在'朝内',所以就换成360的资源库吧.操作如下:&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#static/css/目录下css文件中,例如main.css&lt;/span&gt;
&lt;span class="nd"&gt;@import&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;fonts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;googleapi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="n"&gt;family&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Overlock&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;700&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;900&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nd"&gt;@import&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;fonts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;googleapi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="n"&gt;family&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PT&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;Mono&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="c"&gt;#替换为&lt;/span&gt;
&lt;span class="nd"&gt;@import&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;fonts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;useso&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="n"&gt;family&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Overlock&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;700&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;900&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nd"&gt;@import&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;fonts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;useso&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="n"&gt;family&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PT&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;Mono&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;可以上传后测试下,基本上能在10s内刷新出来.效果明显.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;*国内其他开公共库&lt;/strong&gt;:
 &lt;a href="http://developer.baidu.com/wiki/index.php?title=docs/cplat/libs"&gt;百度CDN公共库&lt;/a&gt;; 
 &lt;a href="http://lib.sinaapp.com/"&gt;新浪云计算CDN公共库&lt;/a&gt;; 
 &lt;a href="http://jscdn.upai.com/"&gt;又拍云JS库CDN服务&lt;/a&gt;; 
 &lt;a href="http://www.staticfile.org/"&gt;七牛云静态文件CDN&lt;/a&gt;; &lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Google(百度) Analytics和Webmasters设置&lt;/h2&gt;
&lt;p&gt;注册&lt;a href="http://www.google.com/analytics/"&gt;Google Analytics&lt;/a&gt;和&lt;a href="http://www.google.com/webmasters/"&gt;Webmasters&lt;/a&gt;可以更好的管理自己的站点,&lt;a href="http://zhanzhang.baidu.com/"&gt;百度站长工具&lt;/a&gt;更好的让搜索引擎收录.认证有多种形式,可以根据注册使用向导来完成进一步设置.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;添加多说评论&lt;/h2&gt;
&lt;p&gt;首先在&lt;a href="http://duoshuo.com/"&gt;多说&lt;/a&gt;的网站中注册一个账号.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;修改模板文件&lt;/h4&gt;
&lt;p&gt;修改&lt;code&gt;templates/article.html&lt;/code&gt;内容,在最后一个endif之后添加如下内容&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;{%&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;DUOSHUO_SITENAME&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;SITEURL&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;article.status&lt;/span&gt; &lt;span class="p"&gt;!&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;draft&amp;quot;&lt;/span&gt; &lt;span class="cp"&gt;%}&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;comments&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;h2&amp;gt;&lt;/span&gt;Comments !&lt;span class="nt"&gt;&amp;lt;/h2&amp;gt;&lt;/span&gt;
    &lt;span class="c"&gt;&amp;lt;!-- Duoshuo Comment BEGIN --&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ds-thread&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;script&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;text/javascript&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        var duoshuoQuery = {short_name:&amp;quot;&lt;span class="cp"&gt;{{&lt;/span&gt; &lt;span class="nv"&gt;DUOSHUO_SITENAME&lt;/span&gt; &lt;span class="cp"&gt;}}&lt;/span&gt;&amp;quot;};
  (function() {
   var ds = document.createElement(&amp;#39;script&amp;#39;);
   ds.type = &amp;#39;text/javascript&amp;#39;;ds.async = true;
   ds.src = &amp;#39;http://static.duoshuo.com/embed.js&amp;#39;;
   ds.charset = &amp;#39;UTF-8&amp;#39;;
   (document.getElementsByTagName(&amp;#39;head&amp;#39;)[0]
    || document.getElementsByTagName(&amp;#39;body&amp;#39;)[0]).appendChild(ds);

   })();
  &lt;span class="nt"&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;noscript&amp;gt;&lt;/span&gt;Please enable JavaScript to view the comments.&lt;span class="nt"&gt;&amp;lt;/noscript&amp;gt;&lt;/span&gt;
&lt;span class="c"&gt;&amp;lt;!-- Duoshuo Comment END --&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/endif&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;这段代码会自动引入多说的评论插件,显示评论内容.&lt;/p&gt;
&lt;h4&gt;修改配置文件&lt;/h4&gt;
&lt;p&gt;在Pelicanconf.py中添加&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;DUOSHUO_SITENAME = &amp;quot;你的blog名称&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;然后重新生成网站就会看到相关的评论界面了.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;配置文件其他配置&lt;/h2&gt;
&lt;p&gt;还有一些其他配置就不一一详解了,以下列出仅供参考.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;## 设置URL按照日期显示
ARTICLE_URL = &amp;#39;pages/{date:%Y}/{date:%m}/{date:%d}/{slug}/&amp;#39;
ARTICLE_SAVE_AS = &amp;#39;pages/{date:%Y}/{date:%m}/{date:%d}/{slug}/index.html&amp;#39;
PAGE_URL = &amp;#39;pages/{slug}/&amp;#39;
PAGE_SAVE_AS = &amp;#39;pages/{slug}/index.html&amp;#39;

## 分页
DEFAULT_PAGINATION = 2

## 静态目录设置
STATIC_PATHS = [&amp;quot;pictures&amp;quot;, ]

## 顶部菜单项
MENUITEMS = [
            (&amp;#39;archives&amp;#39;,SITEURL+&amp;#39;/archives.html&amp;#39;),
            ]
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;以上算是对之前&lt;strong&gt;创建静态博客&lt;/strong&gt;的补充.其实都算是基本的设置,其实还有好多的设置应该做些总结,例如:增加站内搜索框等.时间关系吧,随着对自己博客的改造逐渐进行补充.&lt;/p&gt;</summary><category term="github pages"></category><category term="pelican_plugin"></category></entry><entry><title>MooseFS浅析(二)</title><link href="http://bigbo.github.io/pages/2015/01/08/Moosefs_two/" rel="alternate"></link><updated>2015-01-09T16:00:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-08:pages/2015/01/08/Moosefs_two/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;继上篇,感觉说了好多废话,多半是配置文件相关参数,作为一个基础运维人员,更关注的是怎么让服务更加稳定(高可用),出现问题如何恢复(容错)等,更接地气的东西打算在下面介绍下.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;启动和关闭顺序&lt;/h2&gt;
&lt;p&gt;master启动后,metalogger\chunker\client三个元素都能自动与master建立连接.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;正常启动顺序:matser---chunker---metalogger---client.&lt;/p&gt;
&lt;p&gt;关闭顺序:client---chunker---metalogger---master&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;Client操作与修复&lt;/h2&gt;
&lt;p&gt;客户端强制 &lt;code&gt;kill -9&lt;/code&gt; 杀掉 &lt;code&gt;mfsmount&lt;/code&gt; 进程,需要先 &lt;code&gt;umount&lt;/code&gt; ,然后再 &lt;code&gt;mount&lt;/code&gt; ,否则会提示:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;fuse&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;bad&lt;/span&gt; &lt;span class="n"&gt;mount&lt;/span&gt; &lt;span class="n"&gt;point&lt;/span&gt; &lt;span class="err"&gt;`&lt;/span&gt;&lt;span class="sr"&gt;/mnt/test/&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Transport&lt;/span&gt; &lt;span class="n"&gt;endpoint&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;connected&lt;/span&gt;
&lt;span class="n"&gt;see&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="sr"&gt;/data/jingbo.li/mfs/bin/&lt;/span&gt;&lt;span class="n"&gt;mfsmount&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;help&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;关于修复&lt;/h3&gt;
&lt;p&gt;使用过程中遭遇master断电导致服务停止,可以使用 &lt;code&gt;mfsmetarestore -a&lt;/code&gt; 修复才能启动,如果无法修复,使用 &lt;code&gt;metalogger&lt;/code&gt; 上的备份日志进行恢复: &lt;code&gt;mfsmetarestore -m metadata.mfs.back -o metadata.mfs changelog_ml.*.mfs&lt;/code&gt; ,但是此方法也不是万能的,但凡此过程chunks块出现问题,可以使用 &lt;code&gt;mfsfilerepair&lt;/code&gt; 进行修复.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mfsfilerepair&lt;/code&gt; 主要是处理坏文件的(如写操作引起的I/O错误)使文件能够部分可读.作用如下:在丢失块的情况下使用0对丢失文件进行填充;在块的版本号不匹配时设置快的版本号为master上已知的能在chunkerservers找到的最高版本号;&lt;/p&gt;
&lt;p&gt;注意:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;因为在第二种情况的内容不匹配,可能发生在块具有相同的版本,建议进行文件的拷贝(而不是进行不快照!),并删除原始文件再进行文件的修复.恢复后会有文件丢失或损坏.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;Chunker的空间&lt;/h2&gt;
&lt;p&gt;查看MooseFS文件的使用情况,请使用 &lt;code&gt;mfsdirinfo&lt;/code&gt; 命令,相当于 &lt;code&gt;df&lt;/code&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;快照 &lt;code&gt;snapshot&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;可以快照任何一个文件或目录,语法: &lt;code&gt;mfsmakesnapshot src dst&lt;/code&gt; ,但是src和dst必须都属于mfs体系,即不能mfs体系中的文件快照到其他文件系统.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;&lt;strong&gt;mfsappendchunks&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;追加chunks到一个文件,追加文件块到另一个文件.如果目标文件不存在,则会创建一个空文件,然后继续将块进行追加.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;回收站机制&lt;/h2&gt;
&lt;p&gt;其实MFS有类似windows的回收站这种机制,当文件不小心删除了,不用担心,去回收站去找.随时可以恢复.当然,我所说的随时随地恢复要看你回收站的数据保存多长时间了(默认24小时).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先挂载辅助系统&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;单独安装或挂载 &lt;strong&gt;MFSMETA&lt;/strong&gt; 文件系统,它包含目录/trash (包含仍然可以被还原的删除文件的信息)和 &lt;code&gt;/trash/undel&lt;/code&gt; (用于获取文件),用一个 &lt;code&gt;-m&lt;/code&gt; 或 &lt;code&gt;-o mfsmeta&lt;/code&gt; 的选项,这样可以挂接一个辅助的文件系统MFSMETA,这么做的目的是对于意外的从MooseFS卷上删除文件或者是为了释放磁盘空间而移动的文件而又此文件又过去了垃圾文件存放期的恢复.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例如:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    mfsmount -m /mnt/mfsmeta -H mfs1.com.org
    或者
    mfsmount -o mfsmeta -H mfs1.com.org /mnt/mfsmeta
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;需要注意的是,如果要挂载mfsmeta,一定要在mfsmaster的mfsexports.cfg文件中加入如下条目:* . rw&lt;/p&gt;
&lt;p&gt;挂载后在/mnt/mfsmeta目录下分reserved和trash两个目录,trash为已删除文件存放目录,删除时间根据mfsgettrashtime设置时间来自动删除.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;设置文件或目录的删除时间
一个删除的文件能够存放在“ 垃圾箱”中的时间称为隔离时间,这个时间可以用 &lt;code&gt;mfsgettrashtime&lt;/code&gt; 命令来查看:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img alt="mfsgettrashtime命令" src="/pictures/mfs_pic4.png" /&gt;&lt;/p&gt;
&lt;p&gt;用 &lt;code&gt;mfssettrashtime&lt;/code&gt; 命令来设置上面的这个有效时间,要注意的是,保存时间单位为秒.
&lt;img alt="mfssettrashtime命令" src="/pictures/mfs_pic5.png" /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;恢复删除的文件&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;把删除的文件移到/trash/undel下,就可以恢复此文件.在MFSMETA的目录里,除了 &lt;code&gt;trash&lt;/code&gt; 和 &lt;code&gt;trash/undel&lt;/code&gt; 两个目录,还有第三个目录 &lt;code&gt;reserved&lt;/code&gt; ,该目录内有已经删除的文件,但却被其他用户一直打开着.
在用户关闭了这些被打开的文件后, &lt;code&gt;reserved&lt;/code&gt; 目录中的文件将被删除,文件的数据也将被立即删除.此目录不能进行操作.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;单点故障解决&lt;/h2&gt;
&lt;h3&gt;官方提供解决方案&lt;/h3&gt;
&lt;h4&gt;从备份中恢复一个master(1.6及以上版本)&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;安装一个mfsmaster&lt;/li&gt;
&lt;li&gt;利用同样的配置来配置这台mfsmaster(copy一份mfsmaster.cfg到备机)&lt;/li&gt;
&lt;li&gt;找回metadata.mfs.back文件,可以从备份中找,也可以中metalogger主机中找(如果启动了metalogger服务),然后把metadata.mfs.back放入data目录,一般为${prefix}/var/mfs.&lt;/li&gt;
&lt;li&gt;从在master宕掉之前的任何运行metalogger服务的服务器上拷贝最后metadata文件,然后放入mfsmaster的数据目录&lt;/li&gt;
&lt;li&gt;利用mfsmetarestore命令合并元数据changelogs,可以用自动恢复模式mfsmetarestore –a,也可以利用非自动化恢复模式,语法如下: &lt;code&gt;mfsmetarestore -m metadata.mfs.back -o metadata.mfs changelog_ml.*.mfs&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;DNS主从&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;详细的就需要看官网的手册了,不过CE版本不支持,需要用PRO版本才支持.具体好不好用我也不知道.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;UCARP方案&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;两台主机安装ucarp,ucarp允许多个主机共享一个虚拟的ip地址,以提供自动的故障恢复功能,当其中某个主机宕机时,其它的主机会自动接管服务,ARP协议的特点在于其非常低的开销,主机间使用加密数据传递信息,并且在冗余主机之间不需要任何额外的网络链接.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;双机采用虚拟共用一个虚拟IP地址来实现故障自动迁移,执行指令
&lt;code&gt;ucarp -zB -i eth1 -s 192.168.1.100 -v 42 -p moose -a 192.168.1.252 --upscript=/data/jingbo.li/mfs/sbin/vip-up --downscript=/data/jingbo.li/mfs/sbin/vip-down&lt;/code&gt;
当master宕机后从机可以即时启动恢复接管master的相应服务.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt; * &lt;/strong&gt; 此中方案中要保证两台机器之前的网络畅通,网络抖动都可能影响服务.另外关于脚本的编写恢复策略也影响着恢复状况.我的github上有提供相关脚本.&lt;/p&gt;
&lt;h4&gt;其他HA方案&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;其他高可用方案,例如: &lt;code&gt;DRBD+Heartbeat+Pacemaker&lt;/code&gt; 等,更多的就请教Google吧.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总结:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;根据实际测试(采用ucarp方案),在有些情况下无效,当在你刚写完文件时,在断掉master后,在metalogger机器上做恢复后,客户端上不能对某些文件正常访问,会长时间地卡在那里.通过 &lt;code&gt;mfsfileinfo&lt;/code&gt; 在查看文件属性时,会发现一些的块无效提示,在文件文件里也能看到一些提示信息.数据会丢失,完整性得不到保障.出现数据丢失或是读写错误可以尝试使用 &lt;code&gt;mfsfilerepair&lt;/code&gt; 修复.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;补充及总结&lt;/h2&gt;
&lt;p&gt;算是对MFS实际应用做的一些总结,对于实际来说,使用情况会复杂的多,实际应用肯定会遇到好多的问题.后续根据使用情况再做些总结和规整.&lt;/p&gt;
&lt;p&gt;另外做些补充:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;二次开发:&lt;a href="https://github.com/ops-baidu/shadow-mfs"&gt;百度对Moosefs二次开发&lt;/a&gt;,&lt;a href="http://www.zhangxiaolong.org/archives/242.html"&gt;相关文章&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;使用:实际使用来看,不可能使用每个客户端使用的时候都去安装其客户端,造成使用不太方便,其实可以找一台机器挂载MFS后,在其上面搭建一个&lt;strong&gt;FTP&lt;/strong&gt;等相关文件下载或是上传的服务,再加些权限限制,这样对使用者来说就非常方便和友好了.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;单线程是硬伤&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Moosefs更新其实还算快的,通过看其1.6.X版本源码,其实有些地方写的并不是很好,比如网络方面用的是&lt;strong&gt;poll&lt;/strong&gt;,不知道为什么没有采用更高效的&lt;strong&gt;epoll&lt;/strong&gt;,当然现在的最新版本是2.x版本,后续会跟进的.(经过查看最新版2.0.43版本,网络方面与1.6.X差别不大)&lt;/p&gt;
&lt;p&gt;另外,Master的单线程机制也不能够发挥多核CPU的优势,导致其性能受限,当海量文件(千万以上级别)存储的选型的时候就要注意了,也不适合高并发的一些业务.&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="分布式文件系统"></category><category term="Moosefs"></category><category term="分布式存储"></category></entry><entry><title>MooseFS浅析(一)</title><link href="http://bigbo.github.io/pages/2015/01/05/Moosefs_one/" rel="alternate"></link><updated>2015-01-06T22:50:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-05:pages/2015/01/05/Moosefs_one/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;之前面临大量数据存储问题,于是开始选择分布式文件系统.于是MooseFS便映入眼底.正好之前用过,所以直接拿来就用.光会用也不行,闲来之时对他进行了一些简单了解,不管是百度还是谷歌,搜到的都是零零散散的东西,更多的博客都是抄來抄去,所以打算自己做些整理,下面就我对MFS的认识进行一下总结.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;简介&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;MooseFS优越特性如下：&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;高可用性(数据可以存储在多个机器上的多个副本)&lt;/li&gt;
&lt;li&gt;可动态扩展随时新增加机器或者是磁盘&lt;/li&gt;
&lt;li&gt;可回收在指定时间内删除的文件(“垃圾回收站”是一个系统级别的服务)&lt;/li&gt;
&lt;li&gt;可以对整个文件甚至在正在写入的文件创建文件的快照.&lt;/li&gt;
&lt;li&gt;使用和部署非常简单,直接mount使用&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于 &lt;strong&gt;Moosefs&lt;/strong&gt; 的介绍我在此就不详细说了,更多介绍可以查看 &lt;a href="http://www.moosefs.org/"&gt;官网&lt;/a&gt; 以及 &lt;a href="http://www.moosefs.com/how_to_get.html"&gt;英文版权威指南&lt;/a&gt; 或是查看田逸所翻译总结的 &lt;a href="https://github.com/bigbo/tools/blob/master/study/mfs/MooseFS%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97.pdf"&gt;权威指南&lt;/a&gt; ,以上介绍的比自己总结的可能更加详细.我后面的总结是对以上内容的补充.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; *AD:更多资料详见&lt;a href="https://github.com/bigbo/tools/tree/master/study/mfs"&gt;GitHub&lt;/a&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;系统结构&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;MFS文件系统结构包含4种角色:&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;管理服务器managing server(master):负责各个数据存储服务器的管理,文件读写调度,文件空间回收以及恢复.多节点拷贝.单个机器管理整个文件系统,用来存储记录每一个文件的Metadata(记录文件的大小;文件的属性;文件的位置;也包括非规则文件的系统;如目录;sockets;管道和设备)&lt;/li&gt;
&lt;li&gt;元数据日志服务器Metalogger server(Metalogger):负责备份master服务器的变化日志文件,文件类型为changelog_ml.*.mfs,以便于在master server出问题的时候接替其进行工作.&lt;/li&gt;
&lt;li&gt;数据存储服务器data servers (chunkservers):负责连接管理服务器,听从管理服务器调度,提供存储空间,并为客户提供数据传输.&lt;/li&gt;
&lt;li&gt;客户机挂载使用client computers:通过fuse内核接口挂接远程管理服务器上所管理的数据存储服务器,看起来共享的文件系统和本地unix文件系统使用一样的效果.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;整体架构如图:&lt;/p&gt;
&lt;p&gt;&lt;img alt="MFS架构图" src="/pictures/mfs_pic3.png" /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;配置文件详解&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;主要对 &lt;strong&gt;V1.6.27-5&lt;/strong&gt; 版本的配置文件进行解析,后续跟进 &lt;strong&gt;2.x&lt;/strong&gt; 版本配置文件.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;master服务器&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Metadata元数据存储在master服务器的内存中,同时也保存在磁盘上(作为一个定期更新的二进制文件,并实时的更新changelog日志).如果存在metaloggers的话,主要的二进制文件以及日志也复制到metaloggers中.(权威手册中有详细性能测试信息)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;master主要配置文件&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;mfsmaster.cfg&lt;blockquote&gt;
&lt;p&gt;主配置文件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;参数说明如下：
 # WORKING_USER和WORKING_GROUP：是运行master server的用户和组；
 # SYSLOG_IDENT：是master server在syslog中的标识，也就是说明这是由master server产生的；
 # LOCK_MEMORY：是否执行mlockall()以避免mfsmaster 进程溢出(默认为0，即否)；
 # NICE_LEVE：运行的优先级(如果可以默认是 -19; 注意: 进程必须是用root启动)；
 # EXPORTS_FILENAME：被挂接目录及其权限控制文件的存放位置 
 # DATA_PATH：metadata files and lock file存放路径，此目录下大致有以下文件：metadata，changelog，sessions，stats，lock.
 # BACK_LOGS：metadata的change log文件数目(默认是 50);
 # BACK_META_KEEP_PREVIOUS = 1保留以前元文件数(默认是 1);
 # REPLICATIONS_DELAY_INIT：(initial delay in seconds before starting replications)初始延迟复制的时间(默认是300s);
 # REPLICATIONS_DELAY_DISCONNECT：(replication delay in seconds after chunkserver disconnection) chunkserver断开后复制延迟(默认是3600s)；
 # MATOML_LISTEN_HOST：用于metalogger连接的IP地址(默认是*,代表任何IP)；
 # MATOML_LISTEN_PORT：监听metalogger请求的端口地址(默认是9419)；
 # MATOCS_LISTEN_HOST：用于chunkserver连接的IP地址(默认是*，代表任何IP)；
 # MATOCS_LISTEN_PORT：监听chunkserver连接的端口地址(默认是9420)；
 # MATOCU_LISTEN_HOST：用于客户端挂接连接的IP地址(默认是*,代表任何IP)；
 # MATOCU_LISTEN_PORT：监听客户端挂载连接的端口地址(默认是9421)；
 # CHUNKS_LOOP_TIME ：(Chunks loop frequency in seconds)chunks的回环频率(默认是：300秒)；
 # CHUNKS_DEL_LIMIT：(Maximum number of chunks to delete in one loop)在一个loop中可以删除chunks的最大数 (默认：100)
 # CHUNKS_WRITE_REP_LIMIT：(Maximum number of chunks to replicate to one chunkserver in one loop)在一个loop里复制到一个chunkserver的最大chunk数目(默认是1)
 # CHUNKS_READ_REP_LIMIT：(Maximum number of chunks to replicate from one chunkserver in one loop)在一个loop里从一个chunkserver复制的最大chunk数目(默认是5)
 # REJECT_OLD_CLIENTS：弹出低于1.6.0的客户端挂接(0或1，默认是0)
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;mfsexports.cfg&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;MFS访问使用权限控制配置文件;地址可以指定的几种表现形式：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;所有ip，单个ip，IP网络地址/位数掩码，IP网络地址/子网掩码，ip段范围.
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;权限部分：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;   ro  只读模式共享  
   rw  读写方式共享  
   alldirs  许挂载任何指定的子目录  
   maproot   映射为root,还是指定的用户   
   password  指定客户端密码
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;metadata.mfs文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;metadata.mfs, metadata.mfs.back是MooseFS文件系统的元数据metadata的镜像,对集群的数据存储至关重要.做主从也好,做集群备份也好,都是对这些文件做的备份.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;changelog.*.mfs 文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;changelog.*.mfs 是MooseFS文件系统元数据的改变日志(每一个小时合并到metadata.mfs中一次)&lt;/li&gt;
&lt;li&gt;Metadata文件的大小取决于文件数(而不是他们的大小),Changelog的大小取决于每小时的操作次数.(mfsmaster.cfg配置文件中可以设置)&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3&gt;metalogger服务器&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;master备份服务器,在保证服务高可用的情况下使用(即使不做高可用也需要做个备份服务),服务器性能理论上要比master更好.至少不能比master次.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;metalogger主要配置文件&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;mfsmetalogger.cfg&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;WORKING_USER&lt;/span&gt;&lt;span class="err"&gt;和&lt;/span&gt;&lt;span class="nt"&gt;WORKING_GROUP&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="err"&gt;是运行&lt;/span&gt;&lt;span class="nt"&gt;mfsmetalogger&lt;/span&gt; &lt;span class="nt"&gt;server&lt;/span&gt;&lt;span class="err"&gt;的用户和组；&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;SYSLOG_IDENT&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="err"&gt;是&lt;/span&gt;&lt;span class="nt"&gt;mfsmetalogger&lt;/span&gt; &lt;span class="nt"&gt;server&lt;/span&gt;&lt;span class="err"&gt;在&lt;/span&gt;&lt;span class="nt"&gt;syslog&lt;/span&gt;&lt;span class="err"&gt;中的标识，也就是说明这是由&lt;/span&gt;&lt;span class="nt"&gt;mfsmetalogger&lt;/span&gt; &lt;span class="nt"&gt;server&lt;/span&gt;&lt;span class="err"&gt;产生的；&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;LOCK_MEMORY&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="err"&gt;是否执行&lt;/span&gt;&lt;span class="nt"&gt;mlockall&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;&lt;span class="err"&gt;以避免&lt;/span&gt;&lt;span class="nt"&gt;mfsmaster&lt;/span&gt; &lt;span class="err"&gt;进程溢出&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;默认为&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="err"&gt;，即否&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;NICE_LEVEL&lt;/span&gt;&lt;span class="err"&gt;：运行的优先级&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;如果可以默认是&lt;/span&gt; &lt;span class="nt"&gt;-19&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="err"&gt;注意&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="err"&gt;进程必须是用&lt;/span&gt;&lt;span class="nt"&gt;root&lt;/span&gt;&lt;span class="err"&gt;启动&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="err"&gt;；&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;DATA_PATH&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;metadata&lt;/span&gt; &lt;span class="nt"&gt;files&lt;/span&gt; &lt;span class="nt"&gt;and&lt;/span&gt; &lt;span class="nt"&gt;lock&lt;/span&gt; &lt;span class="nt"&gt;file&lt;/span&gt;&lt;span class="err"&gt;存放路径，此目录下大致有以下文件：&lt;/span&gt;&lt;span class="nt"&gt;metadata&lt;/span&gt;&lt;span class="err"&gt;，&lt;/span&gt;&lt;span class="nt"&gt;changelog&lt;/span&gt;&lt;span class="err"&gt;，&lt;/span&gt;&lt;span class="nt"&gt;sessions&lt;/span&gt;&lt;span class="err"&gt;，&lt;/span&gt;&lt;span class="nt"&gt;stats&lt;/span&gt;&lt;span class="err"&gt;，&lt;/span&gt;&lt;span class="nt"&gt;lock&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;BACK_LOGS&lt;/span&gt;&lt;span class="err"&gt;：&lt;/span&gt;&lt;span class="nt"&gt;metadata&lt;/span&gt;&lt;span class="err"&gt;的&lt;/span&gt;&lt;span class="nt"&gt;change&lt;/span&gt; &lt;span class="nt"&gt;log&lt;/span&gt;&lt;span class="err"&gt;文件数目&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;默认是&lt;/span&gt; &lt;span class="nt"&gt;50&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;META_DOWNLOAD_FREQ&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;1&lt;/span&gt; &lt;span class="nf"&gt;#metadata&lt;/span&gt;&lt;span class="err"&gt;元数据下载间隔时间&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;默认是&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="err"&gt;小时，单位是小时，至多是&lt;/span&gt;&lt;span class="nt"&gt;BACK_LOGS&lt;/span&gt;&lt;span class="err"&gt;的&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;MASTER_RECONNECTION_DELAY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;5&lt;/span&gt;   &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="err"&gt;在失去连接之后延迟多少秒重新连接&lt;/span&gt;&lt;span class="nt"&gt;master&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;MASTER_HOST&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;MASTERMFS&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;master&lt;/span&gt;&lt;span class="err"&gt;的&lt;/span&gt;&lt;span class="nt"&gt;HOST&lt;/span&gt;&lt;span class="err"&gt;地址&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;MASTER_PORT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;9419&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;MASTER_TIMEOUT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;60&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;Master&lt;/span&gt;&lt;span class="err"&gt;连接超时时间&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;单位是秒&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;deprecated&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;to&lt;/span&gt; &lt;span class="nt"&gt;be&lt;/span&gt; &lt;span class="nt"&gt;removed&lt;/span&gt; &lt;span class="nt"&gt;in&lt;/span&gt; &lt;span class="nt"&gt;MooseFS&lt;/span&gt; &lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="nc"&gt;.7&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;LOCK_FILE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;var&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;run&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;mfs&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;mfsmetalogger&lt;/span&gt;&lt;span class="nc"&gt;.lock&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;changelog_ml.*.mfs文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;changelog_ml.*.mfs是MooseFS文件系统的元数据的changelog日志(备份的Master 的Master的changelog日志)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;metadata.ml.mfs.back文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;metadata.ml.mfs.back是从Master主机上下载的最新的完整metadata.mfs.back的拷贝&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;sessions.ml.mfs文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;sessions.ml.mfs是从master下载的最新的sessions.mfs文件拷贝&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;chunker服务器&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;数据真实存储的位置,实际使用中,对硬件资源消耗不是很大,最终的瓶颈在网卡和磁盘IO.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;chunker主要配置文件&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;mfschunkserver.cfg&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; # WORKING_USER和WORKING_GROUP：是运行mfschunkserver server的用户和组；
 # SYSLOG_IDENT：是mfschunkserver server在syslog中的标识,也就是说明这是由mfschunkserver server产生的；
 # LOCK_MEMORY：是否执行mlockall()以避免mfschunkserver 进程溢出(默认为0，即否)；
 # NICE_LEVE：运行的优先级(如果可以默认是 -19; 注意: 进程必须是用root启动)；
 # DATA_PATH：metadata files and lock file存放路径,此目录下大致有以下文件：metadata，changelog，sessions，stats，lock.
 # MASTER_RECONNECTION_DELAY = 5 在失去连接之后延迟多少秒重新连接master
 # MASTER_HOST: 元数据服务器的名称或地址,可以是主机名，也可以是ip地址.只要数据存储服务器能访问到元数据服务器就行.
 # MASTER_PORT = 9420
 # MASTER_TIMEOUT = 60
 # CSSERV_LISTEN_HOST = *  #允许挂载的客户端连接的IP地址(*允许全部)
 # CSSERV_LISTEN_PORT = 9422
 # CSSERV_TIMEOUT = 5      #客户端挂载连接的超时时间(单位为秒)
 # HDD_CONF_FILENAME = /usr/local/mfs/etc/mfshdd.cfg #分配给MFS使用的磁盘空间配置文件的位置
 # HDD_TEST_FREQ = 10   # 块的测试期(单位为秒)
 # deprecated, to be removed in MooseFS 1.7
 # LOCK_FILE = /var/run/mfs/mfschunkserver.lock
 # BACK_LOGS = 50
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;mfshdd.cfg文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;目录列表（指定的）用于moosefs挂载存储&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;*AD&lt;/strong&gt;:当某块磁盘发生故障后可以在前面加*,集群便会在后续冗余中,把相应磁盘或是存储位置的数据转移到其他地方存储&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;mfsclient(mount)服务器&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;客户端,安装相应挂载程序使用mfsmount -H MASTER_MFS_HOST /mnt/mfs,进行磁盘挂载.关于使用嘛,找下man吧.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;测试&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;官网手册有详细测试信息&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;零零散散算是把相关配置文件大致介绍一遍,没想成已经有不少内容,不多多半都是配置文件内容,感觉以上介绍离实际用处好远.准备接下来写些MFS使用相关的介绍.此篇准备随时更新.&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="分布式文件系统"></category><category term="Moosefs"></category><category term="分布式存储"></category></entry><entry><title>2014年终总结</title><link href="http://bigbo.github.io/pages/2014/12/31/2014%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/" rel="alternate"></link><updated>2014-12-31T23:22:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2014-12-31:pages/2014/12/31/2014年终总结/</id><summary type="html">&lt;p&gt;在这2014年的结尾,陆陆续续的通过博客\微博\微信看到了好多人在对2014年做的一些总结.赶着2014的末班车,在此我也做些总结.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;工作&lt;/h3&gt;
&lt;p&gt;其实总的来说这一年是不平凡的一年.对于一个职场小白来说,应该从老东家说起.&lt;/p&gt;
&lt;p&gt;那时还是在东三环内的23层,同事还是那么的欢乐,口味依旧那么重.工作环境是那么的轻松欢乐,以至于时间过得那么快,快得都想说句"时间都去哪了".不知不觉公司3月份搬家如期而至;与此同时,项目上遇到的问题比想象中的困难的多的多.最终不得不以结束告终.队伍重组,从而走向了人生的转折.&lt;/p&gt;
&lt;p&gt;4月份来到了@大神的团队,追随一群大神的脚步.开始了一堆高大上的工作.监控\分析\报警,井井有条.让我感到工作的责任还是如此重大.工作内容是如此神圣,虽不能光宗耀祖,但是足可以向身边人吹嘘一番.&lt;/p&gt;
&lt;p&gt;7月犹豫而又慌乱的时代.想想终究算是过去了,就让它淹没在这个时代吧.&lt;/p&gt;
&lt;p&gt;10月没想到该来的还是来了,换了工作,从网到神奇的网站.算是第一次跳槽.想想现在依旧对老东家怀念.也因此终不再犹豫.踏入一个三无地带,从此红旗自己扛,不再有上午茶,中午的安稳觉,下午的集体会;更多的是自己寻找解决方案,尝试处理问题.&lt;/p&gt;
&lt;p&gt;总之找准自己的位置,朝向一个目标前进就是了.要说的是,感谢的人真的是太多了;@大忽悠,感谢把我带上了一条"不归"路;@张姐,感谢合作的那段时间给我指引了好多方向,感觉自己还是不给力,没能坚持到最后,没有给自己一个很好的交代.不过真的学了好多;@会长,感谢那么多的肺腑之言,可惜听了那么多的人生道理,可是依旧没有走好这段路.当然这是后话;@三斗@lantao@SevenShen,有幸跟你们擦肩而过,庆幸自己紧追随你们的步伐,虽然从来没追上过,只能心里默念"他们引擎是V8的".总的来说要感谢的人还是太多了.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;生活&lt;/h3&gt;
&lt;p&gt;改变生活的唯一途径就是自身努力.两年前就应该到手的驾照终于到手了;拥有了比较满意的"大白腿";参与了祖国提供的一次重反校园的考试;虽然与女票有过激烈的争执,但是感情还是一如既往的稳定.生活品质貌似没有提升,后续有待考证.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;主要技术&lt;/h3&gt;
&lt;h5&gt;Python+&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;历史问题,用自己所学,重构了一个内部系统,至于现在好用就不得而知了.算是对之前的学习总结.中间还用上了&lt;a href="http://gearman.org/"&gt;gearman&lt;/a&gt;,当然对于一向不会前端的我,照猫画虎的拼凑除了一个能看的页面也算是小有所成了.有展示,有监控,有搜索,有规整,有报警.维护的事情就交给@轩了,写的太烂不要骂我.&lt;/p&gt;
&lt;h5&gt;&lt;a href="http://www.moosefs.org/"&gt;MFS&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;分布式文件系统.研究跟大牛比不算深入.后续会在博客中做些总结.倒是在呆过的地方都留下了他的身影.还算是一个容易上手使用的文件系统.虽然被坑过,但还算是不错的(看使用场景).&lt;/p&gt;
&lt;h5&gt;&lt;a href="http://www.elasticsearch.com/"&gt;ELK&lt;/a&gt;框架&lt;/h5&gt;
&lt;p&gt;都不知从何说起了.跟随@三斗的脚步,学习研究整套方案的技术细节,调优方案.目前也正在使用打算推广的一套方案.后续如何,还都是未知.感觉自己慢慢的走向了数据挖掘的深坑.&lt;/p&gt;
&lt;h5&gt;GITHUB+Blog&lt;/h5&gt;
&lt;p&gt;终于动手做了,不知道能坚持多久,共勉.&lt;/p&gt;
&lt;p&gt;犹记得2014年初,当时对一年的期望是读一两本好书,coding坏一个键盘,如今的好书只翻了半本有余,键盘的按键依旧是那么轻快好用,对比一年前,只不过键帽发油发亮了.回想当时的期望,不由得对自己说声好傻好天真.如今展望2015,最大的期望就是能把blog坚持下去.&lt;/p&gt;</summary></entry><entry><title>用Pelican&amp;GitHubPages搭建个人博客</title><link href="http://bigbo.github.io/pages/2014/12/28/create-blog/" rel="alternate"></link><updated>2014-12-28T00:02:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2014-12-28:pages/2014/12/28/create-blog/</id><summary type="html">&lt;h3&gt;前言&lt;/h3&gt;
&lt;p&gt;对于github.io早有认识,但是趋于各种懒,至今才动手.想把这几年的一些自己总结的东西做些记录,匆匆那些年,也应该给自己做些积累了.&lt;/p&gt;
&lt;p&gt;那么问题来了,建立github page有各种框架,例如:&lt;a href="http://jekyllrb.com/"&gt;jekyll&lt;/a&gt;,&lt;a href="https://github.com/Shopify/liquid/wiki/Liquid-for-Designers"&gt;liquid&lt;/a&gt;,&lt;a href="http://pelican-docs-zh-cn.readthedocs.org/en/latest/"&gt;Pelican&lt;/a&gt;等等,本文采用后者Pelican,关于Pelican不做过多介绍,想了解的就去连接到的文档看吧.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;搭建基础&lt;/h3&gt;
&lt;p&gt;Pelican基于Python,相比Wordpress等其他框架来说,它比较轻,另外有些自己的&lt;a href="http://docs.getpelican.com/en/3.3.0/#features"&gt;特性&lt;/a&gt;,再配合免费的github pages,非常棒!主要是在linux下进行搭建,过程中会涉及如下技术知识,不过都是很初级的使用,即使新手也可以很容易的上手.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com"&gt;github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pages.github.com"&gt;github pages&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://git-scm.com/blog/2010/06/09/pro-git-zh.html"&gt;git&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.python.org"&gt;python&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pypi.python.org/pypi/pip"&gt;pip&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://pelican-docs-zh-cn.readthedocs.org/en/latest"&gt;pelican&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://wowubuntu.com/markdown/"&gt;markdown&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h3&gt;下载安装&lt;/h3&gt;
&lt;p&gt;由于是linux环境,大部分依赖是有的,没有的话可以通过yum/apt-get去安装.win的话就请参照安装.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;安装python (2.7+,低版本的不支持)&lt;/li&gt;
&lt;li&gt;安装git&lt;/li&gt;
&lt;li&gt;安装pip&lt;/li&gt;
&lt;li&gt;安装pelican&amp;amp;markdown    &lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install pelican
pip install markdown
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h3&gt;框架初建&lt;/h3&gt;
&lt;p&gt;创建文件夹,执行以下命令&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mkdir blog //注意命名
cd blog
pelican-quickstart
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;pelican-quickstart执行命令后,可以依照向导,输入相关配置项,怎么填写可以很随意,后续都可以在pelicanconf.py文件中进行更改.&lt;/p&gt;
&lt;p&gt;命令成功执行后,会出现pelican的框架,如下所示:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;blog/
|-- content             # 存放输入的markdown或RST源文件
|-- output              # 存放最终生成的静态博客
|-- pelicanconf.py      # 配置文件
|-- develop_server.sh   # 测试服务器
|-- Makefile            # 管理博客的Makefile
`-- publishconf.py      # 发布文件，可删除
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;以上完成整体大的框架.&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;填写内容&lt;/h4&gt;
&lt;p&gt;至此,我们可以开始使用Markdown创建一个页面,进入content文件夹,创建一个.md文件.大致如:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt text" src="/pictures/pic1.png" /&gt;&lt;/p&gt;
&lt;p&gt;可以通过截图看到我现在这个页面的Markdown版本的源文件,这里要说的是开头部分的&lt;strong&gt;Title,Category&lt;/strong&gt;等重点字段.详情见&lt;a href="http://pelican-docs-zh-cn.readthedocs.org/en/latest/getting_started.html#pelican"&gt;文档&lt;/a&gt;,涵义如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Title: 文章标题
Date: 创建日期
Modified: 修改日期
Category: 文章分类，标志本文处于该分类下
Tags: 文章标签，标志本文处于该标签下
Slug: URL中该文章的链接地址
Author: 作者
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以简单的写个内容做测试,然后回到&lt;strong&gt;blog&lt;/strong&gt;目录下.&lt;/p&gt;
&lt;p&gt;执行&lt;strong&gt;make html&lt;/strong&gt;生成html&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;[jingbo.li@zero bigbo-blog]$ make html 
pelican /home/jingbo.li/dev/bigbo-blog/content -o /home/jingbo.li/dev/bigbo-blog/output -s /home/jingbo.li/dev/bigbo-blog/pelicanconf.py 
Done: Processed 1 article(s), 0 draft(s) and 1 page(s) in 0.83 seconds.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;表示已经生成了html页面,可以去&lt;strong&gt;/blog/output&lt;/strong&gt;目录下查看已经生成的html页面.&lt;/p&gt;
&lt;p&gt;接着执行&lt;strong&gt;make server&lt;/strong&gt;开启服务,可以看到相关log&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;[jingbo.li@zero bigbo-blog]$ make serve 
cd /home/jingbo.li/dev/bigbo-blog/output &amp;amp;&amp;amp; python -m pelican.server
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;即可可以用浏览器访问&lt;strong&gt;http://localhost:8000&lt;/strong&gt;看到显示效果.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;*AD:更多便捷命令&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;make regenerate     #修改后自动创建静态界面(make html)
make devserver      #相当于regenerate+serve
make publish        #生成用于发布的html
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;文档中还有其他一些命令,请自行发掘.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;设置相关&lt;/h3&gt;
&lt;hr /&gt;
&lt;h4&gt;主题选择&lt;/h4&gt;
&lt;p&gt;如果你能到这一步,那么恭喜你,你已经搭建完一个属于自己的博客了.以下是对自己博客的包装.
首先打开&lt;a href="http://www.pelicanthemes.com/"&gt;主题官网&lt;/a&gt;挑选自己喜欢的主题,当然我们可以把整个&lt;a href="https://github.com/getpelican/pelican-themes"&gt;主题库&lt;/a&gt;clone到本地.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; git clone https://github.com/getpelican/pelican-themes.git
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;现在可以自由选择不错的主题了.打开&lt;strong&gt;pelicanconf.py&lt;/strong&gt;配置文件,添加或是更改&lt;strong&gt;THEME&lt;/strong&gt;为自己喜欢的主题.更多配置请见&lt;a href="http://pelican-docs-zh-cn.readthedocs.org/en/latest/settings.html#id20"&gt;官方文档&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;例如选择notmyidea-cms-fr主题:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;THEME = &amp;#39;pelican-themes/notmyidea-cms-fr&amp;#39; #相对路径或是绝对路径
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h5&gt;link的图标不加载&lt;/h5&gt;
&lt;p&gt;主题选择后打开页面一看,擦,有些瑕疵,旁边的一些github等连接没有图片,影响美观不说B格瞬减.
连接上的小图标:&lt;/p&gt;
&lt;p&gt;&lt;img alt="如图上面的小图标" src="/pictures/pic2.png" title="u&amp;quot;如图上面的小图标&amp;quot;" /&gt;&lt;/p&gt;
&lt;p&gt;通过分析查看原因,得知是由于css问题,来到主题文件夹下,尝试修改加载的css文件:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;  &lt;span class="nt"&gt;cd&lt;/span&gt; &lt;span class="nt"&gt;pelican-themes&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;notmyidea-cms-fr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;static&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;css&lt;/span&gt;
  &lt;span class="nt"&gt;vim&lt;/span&gt; &lt;span class="nt"&gt;main&lt;/span&gt;&lt;span class="nc"&gt;.css&lt;/span&gt;
  &lt;span class="err"&gt;#添加如下字段&lt;/span&gt;
  &lt;span class="nc"&gt;.social&lt;/span&gt; &lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;href&lt;/span&gt;&lt;span class="o"&gt;*=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;github.com&amp;#39;&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="nd"&gt;:before&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="k"&gt;content&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="sx"&gt;url(&amp;#39;../images/icons/github.png&amp;#39;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;margin-right&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;2px&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;vertical-align&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;-3px&lt;/span&gt;&lt;span class="p"&gt;;}&lt;/span&gt;
  &lt;span class="err"&gt;#注意在相应位置放上图标&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;久违的图标就会展现在你的眼前了,B格瞬间上升几个百分点.&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;添加评论系统&lt;/h4&gt;
&lt;p&gt;历经沧桑,终于算是大功告成.等下!貌似还缺一个功能,评论系统.评论可以促进交流,所以这个当然不能少了.目前采用的是国外的评论系统&lt;a href="https://disqus.com/"&gt;Disqus&lt;/a&gt;,安装流程注册填写,会给你博客相关站点分配一个&lt;strong&gt;Shortname&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;回到配置文件&lt;strong&gt;pelicanconf.py&lt;/strong&gt;添加配置&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;DISQUS_SITENAME = Shortname
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;现在大功告成,可以生成页面开始把玩一番吧!&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;编写文章&lt;/h3&gt;
&lt;p&gt;几经转辗,终于可以发篇文章炫耀下了,哈哈哈.本文给予&lt;strong&gt;github pages&lt;/strong&gt;,当然如果你有自己的服务器可以根据&lt;a href="https://help.github.com/articles/creating-pages-with-the-automatic-generator/"&gt;官方教程&lt;/a&gt;设置你自己的站点服务器.这样你就拥有一个二级域名和一个版本库.任性的更新.&lt;/p&gt;
&lt;p&gt;进入&lt;strong&gt;&lt;em&gt;blog&lt;/em&gt;&lt;/strong&gt;目录下的&lt;strong&gt;&lt;em&gt;output&lt;/em&gt;&lt;/strong&gt;文件夹内,依次执行以下命令:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;  git init
  git add .
  git remote add origin https://github.com/bigbo/bigbo.github.io
  git pull origin master
  git commit -m &amp;#39;create blog&amp;#39;
  git push origin master
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当然如果你不会git,没关系,现在先按照&lt;a href="http://www.git-scm.com/book/zh/v1"&gt;官方文档&lt;/a&gt;敲就可以了.熟悉git的同学可以选择使用框架提供的&lt;strong&gt;Makefile&lt;/strong&gt;文件进行一键上传.&lt;/p&gt;
&lt;p&gt;一个完整的博客创建发布流程算是完成了.最后打开浏览器访问github pages的域名即可访问.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;总结&lt;/h3&gt;
&lt;p&gt;目前博客已经可以满足基本的正常使用了.其实我们还可以对其进行不断完善,让其变得更优雅.后续再写些关于插件\配置等有关的内容.&lt;/p&gt;
&lt;p&gt;第一次建立属于自己的空间,写的过程中参见了网上不少的例子,内容都是参疵不齐.更多的是参照官方文档,或是请教&lt;a href="http://google.com"&gt;google&lt;/a&gt;,这个过程持续了3--4天,终于完成了第一篇,收获还是满满的.当然后续还会有第二第三篇.&lt;/p&gt;
&lt;p&gt;不管怎样,收获远大于付出.也算是为2014画上半个句号.希望 2015 come on!&lt;/p&gt;</summary><category term="github pages"></category><category term="pelican"></category></entry></feed>