<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>BigBo's blog</title><link href="http://bigbo.github.io/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>http://bigbo.github.io/</id><updated>2015-07-28T21:00:00+08:00</updated><entry><title>引发Elasticsearch OOM之type</title><link href="http://bigbo.github.io/pages/2015/07/20/elasticsearch_oom/" rel="alternate"></link><updated>2015-07-28T21:00:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-07-20:pages/2015/07/20/elasticsearch_oom/</id><summary type="html">&lt;p&gt;开源日志处理哪家强?当数 &lt;a href="https://www.elastic.co/"&gt;ELKstack&lt;/a&gt; ,但搭起来容易用起来难,尤其是ES,小脾气那叫一个多,不好好调教下时不时的就会给你来点颜色,什么脑裂,内存不足 &lt;code&gt;OOM&lt;/code&gt;,要不就是索引过慢,性能跟不上;应有尽有,自从用起来,一把心酸.&lt;/p&gt;
&lt;p&gt;最近又出问题了,之前好好的集群(已经正常运行3个多月了),当新接入了一个服务(大部分只有写),变得频繁罢工,一周就要重启4次左右,搞得身心疲惫,终于发现故障的原因,故记之,警示后人.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;0x01 ES 几个基本概念&lt;/h2&gt;
&lt;h3&gt;集群&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;cluster (集群)
代表一个集群,集群中有多个节点,其中有一个为主节点,这个主节点是可以通过选举产生的(可以设定主节点角色),主从节点是对于集群内部来说的.es的一个概念就是去中心化,字面上理解就是无中心节点,这是对于集群外部来说的,因为从外部来看es集群,在逻辑上是个整体,你与任何一个节点的通信和与整个es集群通信是等价的.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;shards (分片)
代表索引分片,es可以把一个完整的索引分成多个分片,这样的好处是可以把一个大的索引拆分成多个,分布到不同的节点上.构成分布式搜索.分片的数量只能在索引创建前指定,并且索引创建后不能更改.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;replicas (副本)
每个主分片可以有零个或多个副本.副本是主分片的一个拷贝,有两个作用:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;故障转移:如果主分片有问题,副本分片可以提升为主分片;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;提高性能:获取和搜索请求可以处理主分片或副本分片.当然,注意副本不是越多越好!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;默认情况下,每个主分片有一个副本,不过索引的副本数量可以动态地改变.在同一个节点上,一个副本分片将永远不会和其主分片一起运行.&lt;/p&gt;
&lt;h3&gt;文档元数据&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;index (索引)
索引就是像关系数据库中的"数据库".通过映射可以定义成多种类型.
索引是一个逻辑命名空间映射到一个或多个主要的分片,可以有零个或多个副本分片.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;document (文档)
文档是存储在elasticsearch中的一个JSON文件.这是相当与关系数据库中表的一行数据.每个文档被存储在索引中,并具有一个类型和一个id.一个文档是一个JSON对象(也被称为在其他语言中的 hash / hashmap / associative array(关联数组)),其中包含零个或多个字段 或者键值对.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;原始JSON文档将被存储在索引的_source字段.在获得(getting) 或者搜索(searching)默认的返回时,得到或搜索文档.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;mapping (映射):
映射是像关系数据库中的"模式定义".每个索引都有一个映射.它定义了每个索引的类型.再加上一些索引范围的设置.映射可以被明确地定义,或者在一个文档被索引的时候自动生成.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;type (类型):
Type是相当于关系数据库中的"表".每种类型都有一列字段,用来定义文档的类型.映射定义了对在文档中的每个字段如何进行分析.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;source field (源字段)
默认情况下,你的JSON文档将被索引存储在_source字段里面,所有的get(获取)和search(搜索)请求将返回的该字段。这将允许你直接从搜索结果中访问到源数据，而不需要再次发起请求检索。
注：索引将返回完整的的JSON字符串给你，即使它包含无效的JSON。此字段里的内容不表示任何该对象里面的数据如何被索引。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;field (字段)
文档中包含的一组字段或键值对.字段的值可以是一个简单的(标量)值(如字符串,整数,日期),或者一个嵌套的结构就像一个数组或对象.一个字段就是类似关系数据库表中的一列.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;映射的每个字段有一个字段的类型"type" ( &lt;strong&gt;不要与文档类型混淆&lt;/strong&gt; ),表示那种类型的数据可以存储在该字段里,如:整数 &lt;code&gt;&amp;lt;integer&amp;gt;&lt;/code&gt; , 字符串 &lt;code&gt;&amp;lt;string&amp;gt;&lt;/code&gt; , 对象 &lt;code&gt;&amp;lt;object&amp;gt;&lt;/code&gt; .映射还允许你定义(除其他事项外)一个字段的值如何进行分析.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;id (标识)
每个文档ID标识了一个文档.一个文档的 索引/类型/ ID 必须是唯一的.如果没有提供ID,将是自动生成. (还可以看到路由 &lt;code&gt;&amp;lt;routing&amp;gt;&lt;/code&gt; ）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;角色关系对照&lt;/h3&gt;
&lt;p&gt;elasticsearch 跟 MySQL 中定义数据格式的角色关系对照表如下:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;MySQL&lt;/th&gt;
&lt;th align="center"&gt;备注&lt;/th&gt;
&lt;th align="center"&gt;elasticsearch&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;database&lt;/td&gt;
&lt;td align="center"&gt;many tables&lt;/td&gt;
&lt;td align="center"&gt;index&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;table&lt;/td&gt;
&lt;td align="center"&gt;many rows;one schema&lt;/td&gt;
&lt;td align="center"&gt;type&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;row&lt;/td&gt;
&lt;td align="center"&gt;many columns&lt;/td&gt;
&lt;td align="center"&gt;document&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;以上都是一些基本概念的解释,参照对比MySQL,可以大致了了解ES存储结构关系.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;0x02 故障回顾&lt;/h2&gt;
&lt;h3&gt;问题发生现象&lt;/h3&gt;
&lt;p&gt;前天新接入一个需求,在elasticsearch建立索引,总是在不久之后崩溃,查看日志,ES甩出一坨坨内存不够用的警告,日志中并伴随着有java OutOfMemoryError的错误信息.用如下命令查看索引状态,发现在建的索引健康状态为Green.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;curl -XGET &amp;#39;http://localhost:9200/_cat/health&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;日志内存不足warn:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;[2015-07-21 11:39:01,458][WARN ][monitor.jvm              ] [Fagin] [gc][old][83840][226] duration [15.1s], collections [1]/[16.2s], total [15.1s]/[6.3m], memory [3.4gb]-&amp;gt;[2.7gb]/[3.8gb], all_pools {[young] [731.6mb]-&amp;gt;[115.9mb]/[1gb]}{[survivor] [136.5mb]-&amp;gt;[0b]/[136.5mb]}{[old] [2.5gb]-&amp;gt;[2.6gb]/[2.6gb]}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;然后逐渐有的节点不接受请求和响应,逐渐的脱离集群.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;[2015-07-21 11:45:25,978][WARN ][discovery.zen.publish    ] [Fagin] timed out waiting for all nodes to process published state [28846] (timeout [30s], pending nodes: [[Silvermane][o8o6aA_fTEu7TJnKlP9zNA][110-19-179.org][inet[/192.9.19.179:9300]]])
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;问题追查及分析&lt;/h3&gt;
&lt;p&gt;推测是由于内存分配的太小导致,于是重启服务,把内存调整到32G内存重启跑起来,并且对JVM的GC过程添加监控,以为从此可以安心睡觉了.但是想不到悲剧即将发生.不到8个小时,内存又要被撑爆了!于是继续追查原因.&lt;/p&gt;
&lt;p&gt;新建立一个小集群,小集群所有服务配置和大集群配置一样,唯一不同的是内存只分配为2g(大集群内存分配32G),开启双写模式,数据同时写入两个集群.&lt;/p&gt;
&lt;p&gt;通过对日志的查看以及对jvm的监控,发现日志中有大量的WARN,而且每条都不重复&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;WARN&lt;/span&gt; &lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mapper&lt;/span&gt;             &lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Blue&lt;/span&gt; &lt;span class="n"&gt;Marvel&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2015&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mo"&gt;07&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="n"&gt;_history&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;Type&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;xz&lt;/span&gt;&lt;span class="p"&gt;@&lt;/span&gt;&lt;span class="n"&gt;rl_tab&lt;/span&gt;&lt;span class="p"&gt;@&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tieba&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Theme_17&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;contains&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="sc"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;recommended&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;include&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt; &lt;span class="n"&gt;within&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;type&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;
&lt;span class="p"&gt;........&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;于是想起前几天接入的新的业务,可能是type字段有些非法字符,感觉不是问题所在,所以可以忽略.&lt;/p&gt;
&lt;p&gt;在开启双写模式下,经过不到1个小时的时间,小集群内存就OOM了,集群瘫痪无相应了.此时开始注意到上面说的WARN,并根据实际数据写入量做分析,发现实际写入数据size也就不到2g左右,集群内存就被撑爆,而我的硬盘空间远远大于2g存储空间,感觉所有数据都被存到内存当中了,而不是存到硬盘当中了.于是打开监控查看之前OOM的整个历史记录.
&lt;img alt="elasticsearch_oom1" src="/pictures/es_oom1.png" title="u&amp;quot;es_oom&amp;quot;" /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;0x03 故障分析总结&lt;/h2&gt;
&lt;p&gt;通过上面监控发现,随着我的数据写入量的增大,jvm每次完整一次gc后可用内存越来越少,存在内存泄露.而日志中继续不断报WARN.此时查看对应索引的mapping,发现长时间无法返回结果,查看数据写入逻辑得知,写入数据index中的type被当成一个变量,也就是每一个关键词都会在mapping中生成一个"[关键词]"的type,于是这会导致ES得到一条日志就会 &lt;code&gt;update_mapping&lt;/code&gt; ,更新 &lt;code&gt;cluster.metadata&lt;/code&gt;, &lt;code&gt;type&lt;/code&gt; 是 &lt;code&gt;mapping&lt;/code&gt; 中的一部分, &lt;code&gt;mapping&lt;/code&gt; 也用于配置元数据和type之间的关系;以上的使用可以理解为每有一个关键字,就会新建一张表,而 &lt;code&gt;mapping&lt;/code&gt; 是元数据,需要加载到内存,来管理各个索引每个对应字段的,最终会得到一个非常庞大的 &lt;code&gt;mapping&lt;/code&gt; ,从而内存不足,造成集群响应不了从而假死宕机.&lt;/p&gt;
&lt;p&gt;以上都是理论,实践出真知,在服务没有宕机之前赶紧把有问题索引干掉,于是美好的事情发生了,内存回收正常,通过上图可以看到18:30分以后的监控数据是删掉有问题索引以后的jvm gc过程,一切恢复正常.&lt;/p&gt;
&lt;p&gt;es索引的结构 &lt;code&gt;index -&amp;gt; shard -&amp;gt; segment&lt;/code&gt; ,是这样一个逻辑,如果用户搜 &lt;code&gt;/index/type/_search&lt;/code&gt; , 就需要有个办法快速过滤出满足需要的数据集,type是被索引起来的.有两种使用方式注意: &lt;strong&gt;不同type下不同field的类型如果不一样&lt;/strong&gt; 以及 &lt;strong&gt;不同_type下相同field&lt;/strong&gt; 都会在mapping新生成一个type,还是会浪费mapping空间,所以使用上需要注意.&lt;/p&gt;
&lt;p&gt;但凡集群不稳定经常OOM的话就需要追查原因了,首先要做到有据可查,也就是要把能加监控的加监控,观察宕机情况,然后查看log,log的记录还是很详细的,跟着log來查相应原因,一般都好解决.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;关于ES相关文档：
Elasticsearch权威指南1 &lt;sup id="fnref:ES_BOOK1"&gt;&lt;a class="footnote-ref" href="#fn:ES_BOOK1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;
ElasticSearch 权威指南2 &lt;sup id="fnref:ES_BOOK2"&gt;&lt;a class="footnote-ref" href="#fn:ES_BOOK2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:ES_BOOK1"&gt;
&lt;p&gt;https://www.gitbook.com/book/looly/elasticsearch-the-definitive-guide-cn/details&amp;#160;&lt;a class="footnote-backref" href="#fnref:ES_BOOK1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ES_BOOK2"&gt;
&lt;p&gt;https://www.gitbook.com/book/fuxiaopang/learnelasticsearch/details&amp;#160;&lt;a class="footnote-backref" href="#fnref:ES_BOOK2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="elasticsearch oom"></category><category term="elasticsearch 调优"></category></entry><entry><title>Mozilla Heka使用</title><link href="http://bigbo.github.io/pages/2015/05/23/mozilla_heka/" rel="alternate"></link><updated>2015-05-27T23:30:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-05-23:pages/2015/05/23/mozilla_heka/</id><summary type="html">&lt;p&gt;监控中时常需要对重要日志进行实时收集分析,之前一直使用 &lt;code&gt;logstash&lt;/code&gt; 來做agent,由于 &lt;code&gt;logstash&lt;/code&gt; 对系统强依赖 &lt;code&gt;Java_JDK&lt;/code&gt; ,从而使用起来需要受系统环境限制.
作为对日志转发工具,对系统环境有限制的情况下可以有两个选择:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/bloonix/awesant"&gt;awesant&lt;/a&gt; :基于perl写的轻量级logstash&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mozilla-services/heka"&gt;heka&lt;/a&gt; :基于go语言开发,无系统依赖,高并发&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;h2&gt;0x01 Heka简介&lt;/h2&gt;
&lt;p&gt;Heka 是 Mozilla 公司仿造 logstash 设计,用 Golang 重写的一个开源项目.采用了类 logstash 的 input -&amp;gt; splitters -&amp;gt; decoder -&amp;gt; filter -&amp;gt; encoder -&amp;gt; output 的流程概念.其特点在于,在中间的 decoder/filter/encoder 部分,设计了 sandbox 概念,可以采用内嵌 lua 脚本做这一部分的工作,降低了全程使用静态 Golang 编写的难度.此外,其 filter 阶段还提供了一些监控和统计报警功能.&lt;/p&gt;
&lt;p&gt;官网地址见：http://hekad.readthedocs.org/&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;0x02 架构简述&lt;/h2&gt;
&lt;p&gt;Heka 内部对数据的过滤;转发等,都是采用指针形式.有着高并发,速度快等特点(实际测试监听文件转发至 Kafka 速度是 logstash 的10倍左右) ,目前 heka 可以支持多种格式的消息.&lt;/p&gt;
&lt;p&gt;&lt;img alt="heka" src="/pictures/heka-overview-diagram.png" title="u&amp;quot;heka流程图&amp;quot;" /&gt;&lt;/p&gt;
&lt;p&gt;对日志处理流程如下:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[input] -&amp;gt; [splitter] -&amp;gt; [decoder] -&amp;gt; [filter] -&amp;gt; [encoder] -&amp;gt; [output]&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[input]:
输入插件从外部获得数据,并将其读入Heka管道进行处理,支持数据读取方式包含:网络传输(tcp/udp),消息队列支持(AMQP/KAFKA),文件监听等多种方式.&lt;/li&gt;
&lt;li&gt;[splitter]:
 对数据流进行分流,以区分不同来源日志.&lt;/li&gt;
&lt;li&gt;[decoder]:
 对数据流进行编码,把 message 的结构各个属性解析出来,支持 Lua 对数据进行编码处理.&lt;/li&gt;
&lt;li&gt;[filter]:
 Heka的处理引擎,可以对数据流进行过滤逻辑,包含统计/聚合甚至做些统计等操作.&lt;/li&gt;
&lt;li&gt;[encoder]
 相对[decoder]来说是互逆操作,重新把消息内容编码为一定的格式,格式化输出.&lt;/li&gt;
&lt;li&gt;[output]
 根据指定的匹配规则把某类型的消息输出到外部系统,支持多种协议和方式.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上是整个流程各个步骤实现的功能,当然实际使用的话,这几步不是必须都要有的,如果接收到的数据,没有加密或其他特殊格式需要单独编码,可以直接处理,那Decoder就不需要. 甚至不想输出任何东西,不提供Outputs都可以.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;0x03 Heka 配置使用&lt;/h2&gt;
&lt;p&gt;Heka的配置文件要设置好所需要的 Input/Decoder/Filter/Encoder/Output(不需要的可以不配置).
配置文件对于新手来说,编写不是那么友好,而且使用起来有些死板,不过可以调用 &lt;code&gt;lua&lt;/code&gt; 可以对日志进行灵活的定制转换.&lt;/p&gt;
&lt;p&gt;以对文件进行实时监听为例:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;#hekad的资源配置
[hekad]
#使用CPU核心数,最大性能是设置为CPU核心数*2,需要合理配置
maxprocs = 24
#heka的PID记录文件,便于监控heka进程的死活
pid_file = &amp;#39;/var/log/heka.pid&amp;#39;

#数据处理类,根据实际情况自己命名,eg:heka_test
[heka_test]
#input使用类型,根据实际情况选择
type = &amp;quot;LogstreamerInput&amp;quot;
#记录当前文件的读取位置保存目录,会把当前读取文件位置写入文件(文件名默认为:数据流的命名,例如这里为heka_test)
journal_directory = &amp;quot;/tmp/heka&amp;quot;
#被监听文件目录
log_directory = &amp;quot;/data0/nginxlogs&amp;quot;
#正则匹配路径此处是匹配log_directory后面的路径,例如现在监听的文件路径为
#/data0/nginxlogs/2015/05/23/test.log
file_match = &amp;#39;(?P&amp;lt;Year&amp;gt;\d+)/(?P&amp;lt;Month&amp;gt;\d+)/(?P&amp;lt;Day&amp;gt;\d+)/(?P&amp;lt;FileName&amp;gt;[^/]+)\.log&amp;#39;
#排序,以match匹配到的年月日对文件进行排序依次监听读取
priority = [&amp;quot;Year&amp;quot;,&amp;quot;Month&amp;quot;,&amp;quot;Day&amp;quot;]
#日志的最后修改时间在oldest_duration时间后,则不会监听
#heka 0.9.1及以前版本此处有bug,该设置无效
oldest_duration = &amp;quot;1h&amp;quot;
#分类设置,内部是修改全局变量 Logger,以备后面对日志流做来源区分,默认则为数据处理类名
differentiator = [&amp;quot;FileName&amp;quot;,&amp;quot;-&amp;quot;,&amp;quot;test&amp;quot;]

#编码设置
[PayloadEncoder]
#在每行log后面不自动添加&amp;quot;\n&amp;quot;
append_newlines = false

#output设置,同input设置
[test]
#output到kafka
type = &amp;quot;KafkaOutput&amp;quot;
#过滤log的类型,对不同日志发送到不同位置,&amp;quot;Logger == &amp;#39;a-test&amp;#39;其中a-test指数据流名即全局变量 Logger 的值
message_matcher = &amp;quot;Logger == &amp;#39;a-test&amp;#39;&amp;quot;
#写入哪个topic,或是采用 topic_variable 自动写入相应数据流对应topic
topic = &amp;quot;test&amp;quot;
#kafka机器列表
addrs = [&amp;quot;192.1.19.1:9092&amp;quot;,&amp;quot;192.1.19.2:9092&amp;quot;]
#采用相应编码输出
encoder = &amp;quot;PayloadEncoder&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;配置文件写好规则后可以使用 &lt;code&gt;heka-logstreamer&lt;/code&gt; 来查看匹配规则的是否是想要监听的文件.如下命令: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;heka-logstreamer -config&lt;span class="o"&gt;=&lt;/span&gt;test.toml
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;没问题的话,就可以愉快的把玩heka了.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;hekad -config=test.toml
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h2&gt;0x04 简单调试&lt;/h2&gt;
&lt;p&gt;整个来看配置文件的编写上手不是太简单,使用过程中有些规则的使用需要不断的调试.每次使用时可以通过先把log打印到终端进行简单调试来对规则进一步优化调整.
日志直接输出到终端配置如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;#相同地方不做注释,同上
[hekad]
maxprocs = 24
pid_file = &amp;#39;/var/log/heka.pid&amp;#39;

[heka_test]
type = &amp;quot;LogstreamerInput&amp;quot;
journal_directory = &amp;quot;/tmp/heka&amp;quot;
log_directory = &amp;quot;/data0/nginxlogs&amp;quot;
file_match = &amp;#39;(?P&amp;lt;Year&amp;gt;\d+)/(?P&amp;lt;Month&amp;gt;\d+)/(?P&amp;lt;Day&amp;gt;\d+)/(?P&amp;lt;FileName&amp;gt;[^/]+)\.log&amp;#39;
priority = [&amp;quot;Year&amp;quot;,&amp;quot;Month&amp;quot;,&amp;quot;Day&amp;quot;]
oldest_duration = &amp;quot;1h&amp;quot;
differentiator = [&amp;quot;FileName&amp;quot;,&amp;quot;-&amp;quot;,&amp;quot;test&amp;quot;]

#编码设置
[RstEncoder]

#输出每条日志的所有结构内容
[LogOutput]
message_matcher = &amp;quot;TRUE&amp;quot;
encoder = &amp;quot;RstEncoder&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;以上配置文件可以输出每条日志的所有结构信息值,包含系统的全局变量,显示例如:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;:Timestamp: 2015-05-20 09:34:19.386066825 +0000 UTC
:Type: logfile
:Hostname: xxx
:Pid: 0
:Uuid: aad4ca95-0332-4cf6-af06-ae7729788d29
:Logger: a-test
:Payload: &amp;lt;message&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在输出之前可以通过此方法进行调试判断.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;当然以上纯属测试体验简介,其实heka功能还是很强大的,支持多种协议和消息队列,更多的数据流处理可以在后续去体验挖掘.&lt;/p&gt;</summary><category term="文件监听"></category><category term="日志处理"></category><category term="日志转发"></category></entry><entry><title>elasticsearch配置小记</title><link href="http://bigbo.github.io/pages/2015/04/10/elasticsearch_config/" rel="alternate"></link><updated>2015-04-16T16:30:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-04-10:pages/2015/04/10/elasticsearch_config/</id><summary type="html">&lt;p&gt;基于 &lt;code&gt;elasticsearch 1.4.4&lt;/code&gt; 版本.安装方式为RPM安装.所有涉及路径需根据实际情况来设置判断.&lt;/p&gt;
&lt;h2&gt;0x01 内存调整&lt;/h2&gt;
&lt;p&gt;调整ES内存分配有多种方式,建议调整 &lt;code&gt;/etc/sysconfig/elasticsearch&lt;/code&gt; 中的设置(还可以直接修改bin下的启动脚本).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;# Directory where the Elasticsearch binary distribution resides
ES_HOME=/usr/share/elasticsearch

# Heap Size (defaults to 256m min, 1g max)
# 修改此处即可,ES_HEAP_SIZE表示JVM参数的-Xms and -Xmx设置
ES_HEAP_SIZE=32g

# Heap new generation
# 表示JVM参数的-Xmn设置
#ES_HEAP_NEWSIZE=

# max direct memory
# 表示JVM的-XX:MaxDirectMemorySize设置
#ES_DIRECT_SIZE=

# Additional Java OPTS
#ES_JAVA_OPTS=

# Maximum number of open files
MAX_OPEN_FILES=65535

# Maximum amount of locked memory
#MAX_LOCKED_MEMORY=

# Maximum number of VMA (Virtual Memory Areas) a process can own
MAX_MAP_COUNT=262144

# Elasticsearch log directory
LOG_DIR=/var/log/elasticsearch

# Elasticsearch data directory
DATA_DIR=/var/lib/elasticsearch

# Elasticsearch work directory
WORK_DIR=/tmp/elasticsearch

# Elasticsearch conf directory
CONF_DIR=/etc/elasticsearch

# Elasticsearch configuration file (elasticsearch.yml)
CONF_FILE=/etc/elasticsearch/elasticsearch.yml

# User to run as, change this to a specific elasticsearch user if possible
# Also make sure, this user can write into the log directories in case you change them
# This setting only works for the init script, but has to be configured separately for systemd startup
ES_USER=elasticsearch

# Configure restart on package upgrade (true, every other setting will lead to not restarting)
#RESTART_ON_UPGRADE=true
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;注:&lt;/strong&gt; 
只需要修改 &lt;code&gt;ES_HEAP_SIZE&lt;/code&gt; 设置即可,其他保持默认.除非你精通JVM的调优.
关于 &lt;a href="http://article.yeeyan.org/view/207217/336824"&gt;ES的JVM调优&lt;/a&gt;,可以查看下.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;0x02 集群设置&lt;/h2&gt;
&lt;p&gt;修改配置 &lt;code&gt;/etc/elasticsearch/elasticsearch.yml&lt;/code&gt; 以下对相关字段以注释方式进行解析.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;##################### Elasticsearch Configuration Example #####################
# 我只是挑些重要的配置选项进行注释,其实自带的已经有非常细致的英文注释了.有理解偏差的地方请以英文原版解释为准.

################################### Cluster ###################################

# 代表一个集群,集群中有多个节点,其中有一个为主节点,这个主节点是可以通过选举产生的,主从节点是对于集群内部来说的.
# es的一个概念就是去中心化,字面上理解就是无中心节点,这是对于集群外部来说的,因为从外部来看es集群,在逻辑上是个整体,你与任何一个节点的通信和与整个es集群通信是等价的。
# cluster.name可以确定你的集群名称,当你的elasticsearch集群在同一个网段中elasticsearch会自动的找到具有相同cluster.name的elasticsearch服务.
# 所以当同一个网段具有多个elasticsearch集群时cluster.name就成为同一个集群的标识.

#cluster.name: elasticsearch

#################################### Node #####################################

# 节点名称同理,可自动生成也可手动配置.
#node.name: &amp;quot;Franz Kafka&amp;quot;

# 允许一个节点是否可以成为一个master节点,es是默认集群中的第一台机器为master,如果这台机器停止就会重新选举master.
#node.master: true

# 允许该节点存储数据(默认开启)
#node.data: true

# 配置文件中给出了三种配置高性能集群拓扑结构的模式,如下：
# 1. 如果你想让节点从不选举为主节点,只用来存储数据,可作为负载器
# node.master: false
# node.data: true
#
# 2. 如果想让节点成为主节点,且不存储任何数据,并保有空闲资源,可作为协调器
# node.master: true
# node.data: false
#
# 3. 如果想让节点既不称为主节点,又不成为数据节点,那么可将他作为搜索器,从节点中获取数据,生成搜索结果等
# node.master: false
# node.data: false

# 监控集群状态有一下插件和API可以使用:
# Use the Cluster Health API [http://localhost:9200/_cluster/health], the
# Node Info API [http://localhost:9200/_nodes] or GUI tools
# such as &amp;lt;http://www.elasticsearch.org/overview/marvel/&amp;gt;,
# &amp;lt;http://github.com/karmi/elasticsearch-paramedic&amp;gt;,
# &amp;lt;http://github.com/lukas-vlcek/bigdesk&amp;gt; and
# &amp;lt;http://mobz.github.com/elasticsearch-head&amp;gt; to inspect the cluster state.

# A node can have generic attributes associated with it, which can later be used
# for customized shard allocation filtering, or allocation awareness. An attribute
# is a simple key value pair, similar to node.key: value, here is an example:
#
#node.rack: rack314

# By default, multiple nodes are allowed to start from the same installation location
# to disable it, set the following:
#node.max_local_storage_nodes: 1

#################################### Index ####################################

# 设置索引的分片数,默认为5
#index.number_of_shards: 5

# 设置索引的副本数,默认为1:
#index.number_of_replicas: 1

# 配置文件中提到的最佳实践是,如果服务器够多,可以将分片提高,尽量将数据平均分布到大集群中去
# 同时,如果增加副本数量可以有效的提高搜索性能
# 需要注意的是,&amp;quot;number_of_shards&amp;quot; 是索引创建后一次生成的,后续不可更改设置
# &amp;quot;number_of_replicas&amp;quot; 是可以通过API去实时修改设置的

#################################### Paths ####################################

# 配置文件存储位置
#path.conf: /path/to/conf

# 数据存储位置(单个目录设置)
#path.data: /path/to/data
# 多个数据存储位置,有利于性能提升
#path.data: /path/to/data1,/path/to/data2

# 临时文件的路径
#path.work: /path/to/work

# 日志文件的路径
#path.logs: /path/to/logs

# 插件安装路径
#path.plugins: /path/to/plugins

#################################### Plugin ###################################

# 设置插件作为启动条件,如果一下插件没有安装,则该节点服务不会启动
#plugin.mandatory: mapper-attachments,lang-groovy

################################### Memory ####################################

# 当JVM开始写入交换空间时（swapping）ElasticSearch性能会低下,你应该保证它不会写入交换空间
# 设置这个属性为true来锁定内存,同时也要允许elasticsearch的进程可以锁住内存,linux下可以通过 `ulimit -l unlimited` 命令
#bootstrap.mlockall: true

# 确保 ES_MIN_MEM 和 ES_MAX_MEM 环境变量设置为相同的值,以及机器有足够的内存分配给Elasticsearch
# 注意:内存也不是越大越好,一般64位机器,最大分配内存别才超过32G

############################## Network And HTTP ###############################

# 设置绑定的ip地址,可以是ipv4或ipv6的,默认为0.0.0.0
#network.bind_host: 192.168.0.1

# 设置其它节点和该节点交互的ip地址,如果不设置它会自动设置,值必须是个真实的ip地址
#network.publish_host: 192.168.0.1

# 同时设置bind_host和publish_host上面两个参数
#network.host: 192.168.0.1

# 设置节点间交互的tcp端口,默认是9300
#transport.tcp.port: 9300

# 设置是否压缩tcp传输时的数据，默认为false,不压缩
#transport.tcp.compress: true

# 设置对外服务的http端口,默认为9200
#http.port: 9200

# 设置请求内容的最大容量,默认100mb
#http.max_content_length: 100mb

# 使用http协议对外提供服务,默认为true,开启
#http.enabled: false

################################### Gateway ###################################

# gateway的类型,默认为local即为本地文件系统,可以设置为本地文件系统
#gateway.type: local

# 下面的配置控制怎样以及何时启动一整个集群重启的初始化恢复过程
# (当使用shard gateway时,是为了尽可能的重用local data(本地数据))

# 一个集群中的N个节点启动后,才允许进行恢复处理
#gateway.recover_after_nodes: 1

# 设置初始化恢复过程的超时时间,超时时间从上一个配置中配置的N个节点启动后算起
#gateway.recover_after_time: 5m

# 设置这个集群中期望有多少个节点.一旦这N个节点启动(并且recover_after_nodes也符合),
# 立即开始恢复过程(不等待recover_after_time超时)
#gateway.expected_nodes: 2

############################# Recovery Throttling #############################

# 下面这些配置允许在初始化恢复,副本分配,再平衡,或者添加和删除节点时控制节点间的分片分配
# 设置一个节点的并行恢复数

# 1.初始化数据恢复时,并发恢复线程的个数,默认为4
#cluster.routing.allocation.node_initial_primaries_recoveries: 4
#
# 2.添加删除节点或负载均衡时并发恢复线程的个数,默认为2
#cluster.routing.allocation.node_concurrent_recoveries: 2

# 设置恢复时的吞吐量(例如:100mb,默认为0无限制.如果机器还有其他业务在跑的话还是限制一下的好)
#indices.recovery.max_bytes_per_sec: 20mb

# 设置来限制从其它分片恢复数据时最大同时打开并发流的个数,默认为5
#indices.recovery.concurrent_streams: 5

# 注意: 合理的设置以上参数能有效的提高集群节点的数据恢复以及初始化速度

################################## Discovery ##################################

# 设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点.默认为1,对于大的集群来说,可以设置大一点的值(2-4)
#discovery.zen.minimum_master_nodes: 1

# 探查的超时时间,默认3秒,提高一点以应对网络不好的时候,防止脑裂
#discovery.zen.ping.timeout: 3s

# For more information, see
# &amp;lt;http://elasticsearch.org/guide/en/elasticsearch/reference/current/modules-discovery-zen.html&amp;gt;

# 设置是否打开多播发现节点.默认是true.
# 当多播不可用或者集群跨网段的时候集群通信还是用单播吧
#discovery.zen.ping.multicast.enabled: false

# 这是一个集群中的主节点的初始列表,当节点(主节点或者数据节点)启动时使用这个列表进行探测
#discovery.zen.ping.unicast.hosts: [&amp;quot;host1&amp;quot;, &amp;quot;host2:port&amp;quot;]

# Slow Log部分与GC log部分略,不过可以通过相关日志优化搜索查询速度

############## Memory(重点需要调优的部分) ################

# Cache部分:
# es有很多种方式来缓存其内部与索引有关的数据.其中包括filter cache

# filter cache部分:
# filter cache是用来缓存filters的结果的.默认的cache type是node type.node type的机制是所有的索引内部的分片共享filter cache.node type采用的方式是LRU方式.即:当缓存达到了某个临界值之后，es会将最近没有使用的数据清除出filter cache.使让新的数据进入es.

# 这个临界值的设置方法如下：indices.cache.filter.size 值类型：eg.:512mb 20%。默认的值是10%。

# out of memory错误避免过于频繁的查询时集群假死
# 1.设置es的缓存类型为Soft Reference,它的主要特点是据有较强的引用功能.只有当内存不够的时候,才进行回收这类内存,因此在内存足够的时候,它们通常不被回收.另外,这些引用对象还能保证在Java抛出OutOfMemory异常之前,被设置为null.它可以用于实现一些常用图片的缓存,实现Cache的功能,保证最大限度的使用内存而不引起OutOfMemory.在es的配置文件加上index.cache.field.type: soft即可.
# 2.设置es最大缓存数据条数和缓存失效时间,通过设置index.cache.field.max_size: 50000来把缓存field的最大值设置为50000,设置index.cache.field.expire: 10m把过期时间设置成10分钟.
#index.cache.field.max_size: 50000
#index.cache.field.expire: 10m
#index.cache.field.type: soft

# field data部分&amp;amp;&amp;amp;circuit breaker部分：
# 用于field data 缓存的内存数量,主要用于当使用排序,faceting操作时,elasticsearch会将一些热点数据加载到内存中来提供给客户端访问,但是这种缓存是比较珍贵的,所以对它进行合理的设置.

# 可以使用值：eg:50mb 或者 30％(节点 node heap内存量),默认是：unbounded
#indices.fielddata.cache.size： unbounded

# field的超时时间.默认是-1,可以设置的值类型: 5m
#indices.fielddata.cache.expire: -1

# circuit breaker部分:
# 断路器是elasticsearch为了防止内存溢出的一种操作,每一种circuit breaker都可以指定一个内存界限触发此操作,这种circuit breaker的设定有一个最高级别的设定:indices.breaker.total.limit 默认值是JVM heap的70%.当内存达到这个数量的时候会触发内存回收

# 另外还有两组子设置：
#indices.breaker.fielddata.limit:当系统发现fielddata的数量达到一定数量时会触发内存回收.默认值是JVM heap的70%

#indices.breaker.fielddata.overhead:在系统要加载fielddata时会进行预先估计,当系统发现要加载进内存的值超过limit * overhead时会进行进行内存回收.默认是1.03

#indices.breaker.request.limit:这种断路器是elasticsearch为了防止OOM(内存溢出),在每次请求数据时设定了一个固定的内存数量.默认值是40%

#indices.breaker.request.overhead:同上,也是elasticsearch在发送请求时设定的一个预估系数,用来防止内存溢出.默认值是1

# Translog部分:
# 每一个分片(shard)都有一个transaction log或者是与它有关的预写日志,(write log),在es进行索引(index)或者删除(delete)操作时会将没有提交的数据记录在translog之中,当进行flush 操作的时候会将tranlog中的数据发送给Lucene进行相关的操作.一次flush操作的发生基于如下的几个配置

#index.translog.flush_threshold_ops:当发生多少次操作时进行一次flush.默认是 unlimited

#index.translog.flush_threshold_size:当translog的大小达到此值时会进行一次flush操作.默认是512mb

#index.translog.flush_threshold_period:在指定的时间间隔内如果没有进行flush操作,会进行一次强制flush操作.默认是30m

#index.translog.interval:多少时间间隔内会检查一次translog,来进行一次flush操作.es会随机的在这个值到这个值的2倍大小之间进行一次操作,默认是5s

#index.gateway.local.sync:多少时间进行一次的写磁盘操作,默认是5s

# 以上的translog配置都可以通过API进行动态的设置
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h2&gt;0x03 模板使用&lt;/h2&gt;
&lt;p&gt;模板是对index内部存储的一个规划,合理的控制store和analyze,设置mapping是集群优化提高性能不可或缺的重要部分.可以通过 &lt;code&gt;curl -XGET 'http://localhost:9200/twitter/_mapping/tweet&lt;/code&gt; 来查看某个索引的mapping.&lt;/p&gt;
&lt;p&gt;template设定也有多种方法.最简单的就是和存储数据一样POST上去.长期的办法,就是写成json文件放在配置路径里 &lt;code&gt;/etc/elasticsearch/templates&lt;/code&gt; .不用重启ES,当你建立一个模板后,每次创建一个新的index,就会会自动加载模板中设置生效的索引名称,然后mapping就生效了.&lt;/p&gt;
&lt;p&gt;如果用logstash往es里面写数据的话,其实logstash已经支持模板的使用.
eg:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; elasticsearch {
    template =&amp;gt; ... # a valid filesystem path (optional)
    template_name =&amp;gt; ... # string (optional), default: &amp;quot;logstash&amp;quot;
    template_overwrite =&amp;gt; ... # boolean (optional), default: false
  }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash如果不设置上述设置,会自动指定一个默认模板.
默认模板在:&lt;code&gt;logstash_1.4.2/lib/logstash/outputs/elasticsearch/elasticsearch-template.json&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;相关连接:&lt;/li&gt;
&lt;li&gt;http://logstash.net/docs/1.4.2/outputs/elasticsearch#template&lt;/li&gt;
&lt;li&gt;http://tinytub.github.io/elasticsearch-configs.html#&lt;/li&gt;
&lt;li&gt;http://www.yubingzhe.com/?p=137&lt;/li&gt;
&lt;/ul&gt;</summary><category term="elasticsearch 配置"></category></entry><entry><title>logstash-input-file以及logstash-output-kafka插件性能测试</title><link href="http://bigbo.github.io/pages/2015/03/26/logstash_performance/" rel="alternate"></link><updated>2015-03-27T19:30:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-03-26:pages/2015/03/26/logstash_performance/</id><summary type="html">&lt;p&gt;最近项目需求,要了解下logstash的一些性能,根据现有的技术方案,主要是针对 &lt;code&gt;logstash-input-file&lt;/code&gt; 插件以及 &lt;code&gt;logstash-output-kafka&lt;/code&gt; 插件进行测试,不过最近关注 logstash 的人应该清楚,目前处于新老版本迭代期,老版本&lt;a href="https://download.elasticsearch.org/logstash/logstash/logstash-1.4.2.tar.gz"&gt;1.4.2版本&lt;/a&gt; 和新版本 &lt;a href="http://download.elasticsearch.org/logstash/logstash/logstash-1.5.0.rc2.tar.gz"&gt;1.5.0RC2版本&lt;/a&gt; ,&lt;a href="http://chenlinux.com/2015/02/10/logstash-outputs-elasticsearch-http-memory-leak/"&gt;1.4.2版本内存泄露&lt;/a&gt; 问题在1.5版本后得到改进,但是1.5还没出正式版本.以下是根据1.5RC2版本来进行测试对比.&lt;/p&gt;
&lt;p&gt;硬件环境:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CPU&lt;/th&gt;
&lt;th&gt;硬盘&lt;/th&gt;
&lt;th&gt;内存&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Intel CorporationXeonE5 v2/Core i7&lt;/td&gt;
&lt;td&gt;2TX1&lt;/td&gt;
&lt;td&gt;128G&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;软件环境:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;系统&lt;/th&gt;
&lt;th align="center"&gt;java_jdk&lt;/th&gt;
&lt;th align="center"&gt;JVM&lt;/th&gt;
&lt;th align="center"&gt;Kafka Configuration&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;centos6.5&lt;/td&gt;
&lt;td align="center"&gt;1.7.0_65&lt;/td&gt;
&lt;td align="center"&gt;-Xmx2000m -Xss2048k(其他默认)&lt;/td&gt;
&lt;td align="center"&gt;Replica X1 Partition X1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr /&gt;
&lt;h2&gt;各版本之间性能对比&lt;/h2&gt;
&lt;h3&gt;裸跑性能&lt;/h3&gt;
&lt;p&gt;先测试下两个版本裸跑性能(不加任何filter),官方在之前也出过关于为什么用JRuby而不是用MRI的 &lt;a href="https://gist.github.com/jordansissel/4171039"&gt;性能测试报告&lt;/a&gt;,以下测试也选择官方的测试方法:使用 &lt;code&gt;generator&lt;/code&gt; 插件产生数据,然后使用 &lt;code&gt;pv&lt;/code&gt; 命令做性能监控.out.conf文件如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
 generator { count =&amp;gt; 5000000 }
}

output {
    stdout {
        codec =&amp;gt; dots
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./bin/logstash agent -f out.conf &lt;span class="p"&gt;|&lt;/span&gt; pv -Wbart &amp;gt; /dev/null
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;注意:centos下yum安装的 &lt;code&gt;pv&lt;/code&gt; 版本相对较低,没有 &lt;code&gt;-a&lt;/code&gt; 这个参数,使用起来不太好观察,可以选择更新下 &lt;a href="http://pkgs.repoforge.org/pv/"&gt;新版本&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;logstash1.4.2裸跑性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;1.53MiB 0:00:34 [47.2kiB/s] [46.2kiB/s]
1.97MiB 0:00:44 [37.9kiB/s] [45.9kiB/s]
2.81MiB 0:01:03 [38.3kiB/s] [45.7kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.5.0RC2裸跑性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;1.41MiB 0:00:52 [25.6kiB/s] [27.8kiB/s]
1.65MiB 0:01:00 [  26kiB/s] [28.1kiB/s]
2.19MiB 0:01:19 [  31kiB/s] [28.4kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;裸跑性能见分晓了.不解的是不知道为什么1.5RC2的版本与1.4.2版本的差距那么大.好奇心的驱使,去翻了下github的 &lt;a href="https://github.com/elastic/logstash/issues/2870#issuecomment-86515699"&gt;issues&lt;/a&gt;.看来确实新版本有些性能倒退,根据上面说的使用其修改版本 &lt;code&gt;fix/perf_regression&lt;/code&gt; 测试性能如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 941kiB 0:00:26 [31.9kiB/s] [36.2kiB/s]
2.86MiB 0:01:20 [36.2kiB/s] [36.2kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;对比修改前1.5.0RC2版本确实有提升(其实提升性能更大的是在filter的时候).但实际测试提升没有issues中作者写的那么大.&lt;/p&gt;
&lt;h3&gt;logstash-input-file性能对比&lt;/h3&gt;
&lt;p&gt;有了上面的结果现在对后续结果也有些预估,下面的测试只需把上面的配置文件稍作修改,修改成监听文件模式:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
    file {
        path =&amp;gt; &amp;quot;/data0/lijingbo/0.log&amp;quot;
     }
}

output {
    stdout {
             codec =&amp;gt; dots
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;命令同上:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./bin/logstash agent -f out.conf &lt;span class="p"&gt;|&lt;/span&gt; pv -Wbart &amp;gt; /dev/null
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.4.2性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;2.31MiB 0:01:18 [34.9kiB/s] [30.3kiB/s]
2.39MiB 0:01:21 [27.3kiB/s] [30.3kiB/s]
2.48MiB 0:01:24 [34.7kiB/s] [30.3kiB/s]
2.65MiB 0:01:29 [42.3kiB/s] [30.5kiB/s]
2.81MiB 0:01:34 [  36kiB/s] [30.6kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.5.0RC2性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 376kiB 0:00:20 [23.9kiB/s] [18.8kiB/s]
 498kiB 0:00:25 [27.1kiB/s] [19.9kiB/s]
 777kiB 0:00:39 [22.4kiB/s] [19.9kiB/s]
 2.08MiB 0:01:44 [20.1kiB/s] [20.4kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.5.0fix版本性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 673kiB 0:00:27 [  31kiB/s] [24.9kiB/s]
 896kiB 0:00:36 [26.5kiB/s] [24.9kiB/s]
1.09MiB 0:00:45 [25.3kiB/s] [24.8kiB/s]
1.86MiB 0:01:17 [19.1kiB/s] [24.7kiB/s]
1.91MiB 0:01:19 [29.7kiB/s] [24.8kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过上面的结果,高下立判了.对于文件读取直接输出转发的话还是1.4.2性能比较好.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;logstash-output-kafka性能对比&lt;/h3&gt;
&lt;p&gt;对于kafka的输出,由于 &lt;code&gt;1.4.2版本&lt;/code&gt; 当时没有把kafka的插件并入到logstash的默认设置里.所以在此选择手工安装 &lt;a href="http://bigbo.github.io/pages/2015/01/23/logstash_kafka/"&gt;此前介绍过&lt;/a&gt;,所选各个插件版本如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;logstash1.4.2 + kafka_2.10-0.8.1.1 + logstash-kafka-0.6.2 + jruby-kafka-0.2.1-java&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;logstash 1.5.0RC2 + logstash-output-kafka 0.1.8&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/elastic/logstash/tree/fix/perf_regression"&gt;logstash 1.5.0 (fix/perf_regression branch)&lt;/a&gt; + logstash-output-kafka 0.1.8&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对此其实可以根据github上的issues追溯到还是之前的作者对此方面有 &lt;a href="https://github.com/elastic/logstash/issues/2899"&gt;相关测试&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;同步模式&lt;/h4&gt;
&lt;p&gt;配置文件如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
 generator { count =&amp;gt; 30000000 }
}

output {
    stdout {
             codec =&amp;gt; dots
    }
  kafka {
    broker_list =&amp;gt; &amp;quot;localhost:9092&amp;quot;
    topic_id =&amp;gt; &amp;quot;test&amp;quot;
    compression_codec =&amp;gt; &amp;quot;snappy&amp;quot;
  }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;以上配置其实就是默认配置,默认配置一些选项未列出,其实默认配置走的是 &lt;code&gt;sync&lt;/code&gt; 模式.&lt;/p&gt;
&lt;p&gt;执行命令:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./bin/logstash agent -f out.conf &lt;span class="p"&gt;|&lt;/span&gt; pv -Wbart &amp;gt; /dev/null
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.4.2 + kafka_2.10-0.8.1.1 + logstash-kafka-0.6.2 + jruby-kafka-0.2.1-java 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 191kiB 0:01:04 [3.54kiB/s] [   3kiB/s]
 233kiB 0:01:17 [2.92kiB/s] [3.04kiB/s]
 275kiB 0:01:29 [3.71kiB/s] [ 3.1kiB/s]
 329kiB 0:01:45 [3.08kiB/s] [3.14kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash 1.5.0RC2 + logstash-output-kafka 0.1.8 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 456kiB 0:01:32 [5.41kiB/s] [4.96kiB/s]
 505kiB 0:01:41 [5.88kiB/s] [   5kiB/s]
 557kiB 0:01:51 [4.85kiB/s] [5.02kiB/s]
 598kiB 0:01:59 [5.69kiB/s] [5.03kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash 1.5.0 (fix/perf_regression branch) + logstash-output-kafka 0.1.8 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 440kiB 0:01:15 [7.09kiB/s] [5.88kiB/s]
 569kiB 0:01:34 [7.03kiB/s] [6.05kiB/s]
 616kiB 0:01:41 [7.21kiB/s] [ 6.1kiB/s]
 630kiB 0:01:43 [7.44kiB/s] [6.12kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h4&gt;异步模式&lt;/h4&gt;
&lt;p&gt;配置文件如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
 generator { count =&amp;gt; 30000000 }
}

output {
    stdout {
             codec =&amp;gt; dots
    }

  kafka {
    topic_id =&amp;gt; &amp;quot;test&amp;quot;
    compression_codec =&amp;gt; &amp;quot;snappy&amp;quot;
    request_required_acks =&amp;gt; 1
    serializer_class =&amp;gt; &amp;quot;kafka.serializer.StringEncoder&amp;quot;
    request_timeout_ms =&amp;gt; 10000
    producer_type =&amp;gt; &amp;#39;async&amp;#39;
    message_send_max_retries =&amp;gt; 5
    retry_backoff_ms =&amp;gt; 100
    queue_buffering_max_ms =&amp;gt; 5000
    queue_buffering_max_messages =&amp;gt; 10000
    queue_enqueue_timeout_ms =&amp;gt; -1
    batch_num_messages =&amp;gt; 1000
  }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;此配置其实同issues上的配置相同,主要是我上面测试出来的跟已有的结果差距甚大,顾选择此配置再次测试.&lt;/p&gt;
&lt;p&gt;logstash1.4.2 + kafka_2.10-0.8.1.1 + logstash-kafka-0.6.2 + jruby-kafka-0.2.1-java 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 796kiB 0:01:07 [12.6kiB/s] [11.9kiB/s]
 834kiB 0:01:10 [  12kiB/s] [11.9kiB/s]
 967kiB 0:01:20 [13.7kiB/s] [12.1kiB/s]
1.08MiB 0:01:31 [12.5kiB/s] [12.1kiB/s]
1.11MiB 0:01:33 [15.7kiB/s] [12.2kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash 1.5.0RC2 + logstash-output-kafka 0.1.8 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 649kiB 0:01:14 [7.79kiB/s] [8.77kiB/s]
 711kiB 0:01:20 [11.6kiB/s] [8.89kiB/s]
 769kiB 0:01:26 [10.4kiB/s] [8.95kiB/s]
 901kiB 0:01:39 [9.31kiB/s] [ 9.1kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash 1.5.0 (fix/perf_regression branch) + logstash-output-kafka 0.1.8 性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 712kiB 0:01:16 [9.66kiB/s] [9.38kiB/s]
 765kiB 0:01:21 [11.4kiB/s] [9.45kiB/s]
 843kiB 0:01:29 [10.5kiB/s] [9.48kiB/s]
 884kiB 0:01:33 [  11kiB/s] [9.51kiB/s]
 945kiB 0:01:39 [9.38kiB/s] [9.55kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;结果显而易见了.不知道1.5版本性能问题会不会到正式解决或是提高.到时再来测试一翻.&lt;/p&gt;
&lt;h3&gt;logstash-input-file + logstash-out-kafka 性能对比&lt;/h3&gt;
&lt;p&gt;既然单独的插件测试过了, 综合的测试下两个一起使用的效果.所有条件均同上,差别仅是配置文件(异步模式).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
  file {
    path =&amp;gt; &amp;quot;/data0/lijingbo/0.log&amp;quot;
  }
}

output {
  stdout {
    codec =&amp;gt; dots
  }
  kafka {
    topic_id =&amp;gt; &amp;quot;test&amp;quot;
    compression_codec =&amp;gt; &amp;quot;snappy&amp;quot;
    request_required_acks =&amp;gt; 1
    serializer_class =&amp;gt; &amp;quot;kafka.serializer.StringEncoder&amp;quot;
    request_timeout_ms =&amp;gt; 10000
    producer_type =&amp;gt; &amp;#39;async&amp;#39;
    message_send_max_retries =&amp;gt; 5
    retry_backoff_ms =&amp;gt; 100
    queue_buffering_max_ms =&amp;gt; 5000
    queue_buffering_max_messages =&amp;gt; 10000
    queue_enqueue_timeout_ms =&amp;gt; -1
    batch_num_messages =&amp;gt; 1000
  }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;命令执行同之前.&lt;/p&gt;
&lt;p&gt;logstash1.4.2性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 735kiB 0:01:28 [12.9kiB/s] [8.36kiB/s]
 832kiB 0:01:36 [10.2kiB/s] [8.67kiB/s]
 898kiB 0:01:41 [14.1kiB/s] [ 8.9kiB/s]
 946kiB 0:01:45 [13.6kiB/s] [9.01kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.5RC2性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 720kiB 0:01:21 [11.6kiB/s] [8.89kiB/s]
 792kiB 0:01:29 [8.74kiB/s] [8.91kiB/s]
 851kiB 0:01:35 [10.1kiB/s] [8.96kiB/s]
 891kiB 0:01:39 [9.92kiB/s] [   9kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;logstash1.5fix性能:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; 986kiB 0:01:42 [10.8kiB/s] [9.67kiB/s]
 998kiB 0:01:43 [12.4kiB/s] [ 9.7kiB/s]
1.04MiB 0:01:50 [10.7kiB/s] [9.69kiB/s]
1.12MiB 0:01:58 [11.3kiB/s] [9.69kiB/s]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;测试后感觉与想象中有些差距,对1.5正式版性能稳定性提升抱有希望.后续会跟进,做一些其他更多相关测试.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更新:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;30.31日, &lt;code&gt;logstash1.5fix&lt;/code&gt; 分支的修改已经并入到master分支了,详细见 &lt;a href="https://github.com/elastic/logstash/commit/dbe4154aa689260e6233e3d8e3ad3b03bca4c274"&gt;merge&lt;/a&gt;,相信性能会在1.5的正式版得到回归.&lt;/p&gt;</summary><category term="kafka"></category><category term="消息队列"></category><category term="logstash插件"></category><category term="日志处理"></category></entry><entry><title>elasticsearch之hadoop插件使用</title><link href="http://bigbo.github.io/pages/2015/02/28/elasticsearch_hadoop/" rel="alternate"></link><updated>2015-03-19T23:30:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-02-28:pages/2015/02/28/elasticsearch_hadoop/</id><summary type="html">&lt;h2&gt;elastic与Hadoop的连接&lt;/h2&gt;
&lt;p&gt;几个月前,由于资源有限,而需求无限,不得已想到es与hadoop的连接,本来想的很好,尝试把HDFS作为es的存储后端,把index存入HDFS中,这样就能节省存储空间了.当然官网也有相关使用配置(这里就不介绍了),经过几天的奋斗还是没能实现当初的想法,也幸亏没实现,实现了性能也是一大坑(猜测性能非常差以至于官方的 &lt;a href="https://github.com/elastic/elasticsearch-hdfs"&gt;elasticsearch-hdfs&lt;/a&gt; 插件都几年没更新了!).&lt;/p&gt;
&lt;p&gt;不过倒是尝试了把HDFS作为后端存储,可以实现备份elasticsearch数据快照到HDFS或者是从HDFS中恢复数据.选择插件 &lt;a href="https://github.com/elastic/elasticsearch-hadoop/tree/master/repository-hdfs"&gt;repository-hdfs&lt;/a&gt;,其实就是使用了ES的 &lt;code&gt;snapshot/restore&lt;/code&gt; 功能.&lt;/p&gt;
&lt;h2&gt;安装插件&lt;/h2&gt;
&lt;p&gt;我的es版本为 &lt;code&gt;1.3.9-1&lt;/code&gt;,注意: &lt;code&gt;1.3.0-1.3.7 and 1.4.0-1.4.2&lt;/code&gt; 存在&lt;a href="https://www.elastic.co/blog/elasticsearch-1-4-3-and-1-3-8-released/"&gt;Grooy漏洞&lt;/a&gt;,所以选择版本的时候注意下,插件选择版本对应为2.0.2,后端Hadoop为2.5.0,安装方式如下: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;./bin/plugin -i elasticsearch/elasticsearch-repository-hdfs/2.0.2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当然像我这样没外网的可以选择 &lt;a href="https://oss.sonatype.org/content/repositories/snapshots/org/elasticsearch/elasticsearch-repository-hdfs/"&gt;插件下载&lt;/a&gt;,选择对应的版本,解压拷贝到es的plugin目录.&lt;/p&gt;
&lt;h2&gt;配置使用&lt;/h2&gt;
&lt;h4&gt;直接用curl法:&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;curl -XPUT &amp;#39;http://localhost:9200/_snapshot/backup&amp;#39; -d &amp;#39;{
  &amp;quot;type&amp;quot;: &amp;quot;hdfs&amp;quot;,
    &amp;quot;settings&amp;quot;: {
            &amp;quot;uri&amp;quot;: &amp;quot;hdfs://hadoop:8020&amp;quot;,
            &amp;quot;path&amp;quot;: &amp;quot;/test/es&amp;quot;,
            &amp;quot;conf_location&amp;quot;: &amp;quot;hdfs-site.xml&amp;quot;
    }
}&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;返回 &lt;code&gt;{"acknowledged":true}&lt;/code&gt; 表示创建成功.&lt;/p&gt;
&lt;h5&gt;查看创建的配置:&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;curl http://localhost:9200/_snapshot/_all
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以看到返回刚才配置信息.&lt;/p&gt;
&lt;h5&gt;测试备份数据&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;curl -XPUT &amp;quot;localhost:9200/_snapshot/backup/snapshot_1?wait_for_completion=true&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;尝试去看下HDFS上是否有刚才备份的文件,访问 &lt;code&gt;http://hadoop:50070/explorer.html#/test/es&lt;/code&gt; 便可以看到相关的快照文件.&lt;/p&gt;
&lt;h5&gt;测试还原数据&lt;/h5&gt;
&lt;p&gt;通过快照还原数据,测试前可以把之前测试做过备份的索引进行删除,然后通过如下命令进行数据恢复:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;curl -XPOST &amp;quot;localhost:9200/_snapshot/backup/snapshot_1/_restore?wait_for_completion=true&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;通过kopf插件进行设置&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/lmenezes/elasticsearch-kopf"&gt;elasticsearch-kopf&lt;/a&gt;,是一个对es集群管理综合插件,无需安装&lt;a href="http://lmenezes.com/elasticsearch-kopf/?location=http://localhost:9200"&gt;体验地址&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;备份恢复快照设置如图:&lt;/p&gt;
&lt;p&gt;&lt;img alt="rsyslog" src="/pictures/es_hdfs.png" title="u&amp;quot;kopf设置&amp;quot;" /&gt;&lt;/p&gt;</summary><category term="elasticsearch 快照"></category><category term="elasticsearch plugin"></category><category term="HDFS"></category></entry><entry><title>logstash的kafka插件使用</title><link href="http://bigbo.github.io/pages/2015/01/23/logstash_kafka/" rel="alternate"></link><updated>2015-01-23T19:30:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-23:pages/2015/01/23/logstash_kafka/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;关于logstash可以产看其 &lt;a href="http://logstash.net/"&gt;官网&lt;/a&gt; ,对于英文有障碍的人士,或是想知道更多插件使用技巧的用户请移步 &lt;a href="http://chenlinux.com/"&gt;@三斗室&lt;/a&gt; 所著作 &lt;a href="https://github.com/bigbo/logstash-best-practice-cn"&gt;logstash最佳实战&lt;/a&gt; ,本片内容已经并入其中相关章节.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Logstash-kafka简介&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/joekiller/logstash-kafka"&gt;https://github.com/joekiller/logstash-kafka&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;插件已经正式合并进官方仓库，以下使用介绍基于&lt;strong&gt;logstash 1.4相关版本&lt;/strong&gt;，1.5及以后版本的使用后续依照官方文档持续更新。&lt;/p&gt;
&lt;p&gt;插件本身内容非常简单，其主要依赖同一作者写的 &lt;a href="https://github.com/joekiller/jruby-kafka"&gt;jruby-kafka&lt;/a&gt; 模块。需要注意的是：&lt;strong&gt;该模块仅支持 Kafka－0.8 版本。如果是使用 0.7 版本 kafka 的，将无法直接使 jruby-kafka 该模块和 logstash-kafka 插件。&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;安装&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;安装按照官方文档完全自动化的安装.或是可以通过以下方式手动自己安装插件，不过重点注意的是 &lt;strong&gt;kafka 的版本&lt;/strong&gt;，上面已经指出了。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;下载 logstash 并解压重命名为 &lt;code&gt;./logstash-1.4.0&lt;/code&gt; 文件目录。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;下载 kafka 相关组件，以下示例选的为 &lt;a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.8.1.1/kafka-0.8.1.1-src.tgz"&gt;kafka_2.8.0-0.8.1.1-src&lt;/a&gt;，并解压重命名为 &lt;code&gt;./kafka_2.8.0-0.8.1.1&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;下载 logstash-kafka v0.4.2 从 &lt;a href="https://github.com/joekiller/logstash-kafka/releases"&gt;releases&lt;/a&gt;，并解压重命名为 &lt;code&gt;./logstash-kafka-0.4.2&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从 &lt;code&gt;./kafka_2.8.0-0.8.1.1/libs&lt;/code&gt; 目录下复制所有的 jar 文件拷贝到 &lt;code&gt;./logstash-1.4.0/vendor/jar/kafka_2.8.0-0.8.1.1/libs&lt;/code&gt; 下，其中你需要创建 &lt;code&gt;kafka_2.8.0-0.8.1.1/libs&lt;/code&gt; 相关文件夹及目录。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分别复制 &lt;code&gt;./logstash-kafka-0.4.2/logstash&lt;/code&gt; 里的 &lt;code&gt;inputs&lt;/code&gt; 和 &lt;code&gt;outputs&lt;/code&gt; 下的 &lt;code&gt;kafka.rb&lt;/code&gt;，拷贝到对应的 &lt;code&gt;./logstash-1.4.0/lib/logstash&lt;/code&gt; 里的 &lt;code&gt;inputs&lt;/code&gt; 和 &lt;code&gt;outputs&lt;/code&gt; 对应目录下。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;切换到 &lt;code&gt;./logstash-1.4.0&lt;/code&gt; 目录下，现在需要运行 logstash-kafka 的 gembag.rb 脚本去安装 jruby-kafka 库，执行以下命令： &lt;code&gt;GEM_HOME=vendor/bundle/jruby/1.9 GEM_PATH= java -jar vendor/jar/jruby-complete-1.7.11.jar --1.9 ../logstash-kafka-0.4.2/gembag.rb ../logstash-kafka-0.4.2/logstash-kafka.gemspec&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;现在可以使用 logstash-kafka 插件运行 logstash 了。例如：&lt;code&gt;bin/logstash agent -f logstash.conf&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Input 配置示例&lt;/h2&gt;
&lt;p&gt;以下配置可以实现对 kafka 读取端(consumer)的基本使用。&lt;/p&gt;
&lt;p&gt;消费端更多详细的配置请查看 &lt;a href="http://kafka.apache.org/documentation.html#consumerconfigs"&gt;http://kafka.apache.org/documentation.html#consumerconfigs&lt;/a&gt; kafka 官方文档的消费者部分配置文档。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;input {
    kafka {
        zk_connect =&amp;gt; &amp;quot;localhost:2181&amp;quot;
        group_id =&amp;gt; &amp;quot;logstash&amp;quot;
        topic_id =&amp;gt; &amp;quot;test&amp;quot;
        reset_beginning =&amp;gt; false # boolean (optional)， default: false
        consumer_threads =&amp;gt; 5  # number (optional)， default: 1
        decorate_events =&amp;gt; true # boolean (optional)， default: false
        }
    }
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Input 解释&lt;/h2&gt;
&lt;p&gt;消费端的一些比较有用的配置项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;group_id&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;消费者分组，可以通过组 ID 去指定，不同的组之间消费是相互不受影响的，相互隔离。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;topic_id&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;指定消费话题，也是必填项目，指定消费某个 &lt;code&gt;topic&lt;/code&gt; ，这个其实就是订阅某个主题，然后去消费。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;reset_beginning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;logstash 启动后从什么位置开始读取数据，默认是结束位置，也就是说 logstash 进程会以从上次读取结束时的偏移量开始继续读取，如果之前没有消费过，那么就开始从头读取.如果你是要导入原有数据，把这个设定改成 "true"， logstash 进程就从头开始读取.有点类似 &lt;code&gt;cat&lt;/code&gt; ，但是读到最后一行不会终止，而是变成 &lt;code&gt;tail -F&lt;/code&gt; ，继续监听相应数据。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;decorate_events&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在输出消息的时候会输出自身的信息包括:消费消息的大小， topic 来源以及 consumer 的 group 信息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rebalance_max_retries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当有新的 consumer(logstash) 加入到同一 group 时，将会 &lt;code&gt;reblance&lt;/code&gt; ，此后将会有 &lt;code&gt;partitions&lt;/code&gt; 的消费端迁移到新的 &lt;code&gt;consumer&lt;/code&gt; 上，如果一个 &lt;code&gt;consumer&lt;/code&gt; 获得了某个 &lt;code&gt;partition&lt;/code&gt; 的消费权限，那么它将会向 &lt;code&gt;zookeeper&lt;/code&gt; 注册， &lt;code&gt;Partition Owner registry&lt;/code&gt; 节点信息，但是有可能此时旧的 &lt;code&gt;consumer&lt;/code&gt; 尚没有释放此节点，此值用于控制，注册节点的重试次数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;consumer_timeout_ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;指定时间内没有消息到达就抛出异常，一般不需要改。&lt;/p&gt;
&lt;p&gt;以上是相对重要参数的使用示例，更多参数可以选项可以跟据 &lt;a href="https://github.com/joekiller/logstash-kafka/blob/master/README.md"&gt;https://github.com/joekiller/logstash-kafka/blob/master/README.md&lt;/a&gt; 查看 input 默认参数。&lt;/p&gt;
&lt;h2&gt;注意&lt;/h2&gt;
&lt;p&gt;1.想要使用多个 logstash 端协同消费同一个 &lt;code&gt;topic&lt;/code&gt; 的话，那么需要把两个或是多个 logstash 消费端配置成相同的 &lt;code&gt;group_id&lt;/code&gt; 和 &lt;code&gt;topic_id&lt;/code&gt;， 但是前提是要把&lt;strong&gt;相应的 topic 分多个 partitions (区)&lt;/strong&gt;，多个消费者消费是无法保证消息的消费顺序性的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里解释下，为什么要分多个 &lt;strong&gt;partitions(区)&lt;/strong&gt;， kafka 的消息模型是对 topic 分区以达到分布式效果。每个 &lt;code&gt;topic&lt;/code&gt; 下的不同的 &lt;strong&gt;partitions (区)&lt;/strong&gt;只能有一个 &lt;strong&gt;Owner&lt;/strong&gt; 去消费。所以只有多个分区后才能启动多个消费者，对应不同的区去消费。其中协调消费部分是由 server 端协调而成。不必使用者考虑太多。只是&lt;strong&gt;消息的消费则是无序的&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;总结:保证消息的顺序，那就用一个 &lt;strong&gt;partition&lt;/strong&gt;。 &lt;strong&gt;kafka 的每个 partition 只能同时被同一个 group 中的一个 consumer 消费&lt;/strong&gt;。&lt;/p&gt;
&lt;h2&gt;Output 配置&lt;/h2&gt;
&lt;p&gt;以下配置可以实现对 kafka 写入端 (producer) 的基本使用。&lt;/p&gt;
&lt;p&gt;生产端更多详细的配置请查看 &lt;a href="http://kafka.apache.org/documentation.html#producerconfigs"&gt;http://kafka.apache.org/documentation.html#producerconfigs&lt;/a&gt; kafka 官方文档的生产者部分配置文档。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; output {
    kafka {
        broker_list =&amp;gt; &amp;quot;localhost:9092&amp;quot;
        topic_id =&amp;gt; &amp;quot;test&amp;quot;
        compression_codec =&amp;gt; &amp;quot;snappy&amp;quot; # string (optional)， one of [&amp;quot;none&amp;quot;， &amp;quot;gzip&amp;quot;， &amp;quot;snappy&amp;quot;]， default: &amp;quot;none&amp;quot;
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Output 解释&lt;/h2&gt;
&lt;p&gt;生产的可设置性还是很多的，设置其实更多，以下是更多的设置：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;compression_codec&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;消息的压缩模式，默认是 none，可以有 gzip 和 snappy (暂时还未测试开启压缩与不开启的性能，数据传输大小等对比)。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;compressed_topics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以针对特定的 topic 进行压缩，设置这个参数为 &lt;code&gt;topic&lt;/code&gt; ，表示此 &lt;code&gt;topic&lt;/code&gt; 进行压缩。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;request_required_acks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;消息的确认模式:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;可以设置为 0: 生产者不等待 broker 的回应，只管发送.会有最低能的延迟和最差的保证性(在服务器失败后会导致信息丢失)&lt;/p&gt;
&lt;p&gt;可以设置为 1: 生产者会收到 leader 的回应在 leader 写入之后.(在当前 leader 服务器为复制前失败可能会导致信息丢失)&lt;/p&gt;
&lt;p&gt;可以设置为 -1: 生产者会收到 leader 的回应在全部拷贝完成之后。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;partitioner_class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分区的策略，默认是 hash 取模&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;send_buffer_bytes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;socket 的缓存大小设置，其实就是缓冲区的大小&lt;/p&gt;
&lt;h4&gt;消息模式相关&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;serializer_class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;消息体的系列化处理类，转化为字节流进行传输，&lt;strong&gt;请注意 encoder 必须和下面的 &lt;code&gt;key_serializer_class&lt;/code&gt; 使用相同的类型&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;key_serializer_class&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;默认的是与 &lt;code&gt;serializer_class&lt;/code&gt; 相同&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;producer_type&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;生产者的类型 &lt;code&gt;async&lt;/code&gt; 异步执行消息的发送 &lt;code&gt;sync&lt;/code&gt; 同步执行消息的发送&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;queue_buffering_max_ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;异步模式下&lt;/strong&gt;，那么就会在设置的时间缓存消息，并一次性发送&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;queue_buffering_max_messages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;异步的模式下&lt;/strong&gt;，最长等待的消息数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;queue_enqueue_timeout_ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;异步模式下&lt;/strong&gt;，进入队列的等待时间，若是设置为0，那么要么进入队列，要么直接抛弃&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;batch_num_messages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;异步模式下&lt;/strong&gt;，每次发送的最大消息数，前提是触发了 &lt;code&gt;queue_buffering_max_messages&lt;/code&gt; 或是 &lt;code&gt;queue_enqueue_timeout_ms&lt;/code&gt; 的限制&lt;/p&gt;
&lt;p&gt;以上是相对重要参数的使用示例，更多参数可以选项可以跟据 &lt;a href="https://github.com/joekiller/logstash-kafka/blob/master/README.md"&gt;https://github.com/joekiller/logstash-kafka/blob/master/README.md&lt;/a&gt; 查看 output 默认参数。&lt;/p&gt;
&lt;h3&gt;小贴士&lt;/h3&gt;
&lt;p&gt;默认情况下，插件是使用 json 编码来输入和输出相应的消息，消息传递过程中 logstash 默认会为消息编码内加入相应的时间戳和 hostname 等信息。如果不想要以上信息(一般做消息转发的情况下)，可以使用以下配置，例如:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; output {
    kafka {
        codec =&amp;gt; plain {
            format =&amp;gt; &amp;quot;%{message}&amp;quot;
        }
    }
}
&lt;/pre&gt;&lt;/div&gt;</summary><category term="kafka"></category><category term="消息队列"></category><category term="logstash"></category><category term="日志处理"></category></entry><entry><title>rsyslog与Kafka结合使用</title><link href="http://bigbo.github.io/pages/2015/01/21/syslog_kafka/" rel="alternate"></link><updated>2015-01-21T15:40:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-21:pages/2015/01/21/syslog_kafka/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;最近在折腾 &lt;a href="http://www.rsyslog.com/"&gt;Rsyslog&lt;/a&gt; ,传输日志,对他怎么说呢,谁用谁知道,我仅仅是了解使用的程度,对于里面的坑以及使用策略还没有那么深入,不过日后会逐步的细化了解,其实现在对于日志传输来过网上一大堆技术方案任你选.但是感觉用rsyslog传输还是最方便,最快捷的.他以不变应万变,看图说话:&lt;/p&gt;
&lt;p&gt;&lt;img alt="rsyslog" src="/pictures/rsyslog_1.png" title="u&amp;quot;rsyslog支持图&amp;quot;" /&gt;&lt;/p&gt;
&lt;p&gt;可见rsyslog的覆盖面是相当的广泛.奈何近几日,打算把redis替换为 &lt;a href="http://kafka.apache.org/"&gt;kafka&lt;/a&gt; ,本篇主要记录 &lt;code&gt;rsyslog&lt;/code&gt; 与 &lt;code&gt;kafka&lt;/code&gt; 的对接使用. 上了.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Rsyslog对kafka的支持&lt;/h2&gt;
&lt;p&gt;通过对 &lt;a href="http://www.rsyslog.com/doc/master/configuration/modules/omkafka.html#example"&gt;rsyslog官方文档&lt;/a&gt; 查看,得知 &lt;code&gt;rsyslog&lt;/code&gt; 对 &lt;code&gt;kafka&lt;/code&gt; 的支持是 &lt;code&gt;v8.7.0&lt;/code&gt; 版本后才提供的支持.通过 &lt;a href="https://github.com/rsyslog/rsyslog/blob/v8-stable/ChangeLog"&gt;ChangeLog&lt;/a&gt; 也可以看出 &lt;code&gt;V8.X&lt;/code&gt; 的版本变化.&lt;/p&gt;
&lt;p&gt;查看本机的rsyslog版本:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;rsyslog.x86_64                                      7.6.3-1.el6
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;先是升级.升级方式有多种,推荐使用 &lt;a href="http://www.rsyslog.com/rhelcentos-rpms/"&gt;官方源用&lt;/a&gt; &lt;code&gt;yum&lt;/code&gt; 方式升级.使用源升级后的稳定版目前最新的是 &lt;code&gt;8.7.0-1.el6&lt;/code&gt; ,来查看下rpm包中是否包含 &lt;code&gt;omkafka&lt;/code&gt; 这个插件.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;# rpm -ql rsyslog
.......
/lib64/rsyslog/lmzlibw.so
/lib64/rsyslog/mmpstrucdata.so
.......
#主要看/lib64/rsyslog/目录下的.so文件
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;经过查看其实rpm包编译的版本中是不包含 &lt;code&gt;kafka&lt;/code&gt; 的插件的.经过下载源码包查看,源码包中包含此模块,估计是rpm包编译的时候没有加入进去吧.所以选择自己编译这个模块,编译好了拷贝到相应目录.&lt;/p&gt;
&lt;p&gt;下载源码包,使用 &lt;code&gt;./configure -h&lt;/code&gt; 查看帮助信息.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;  --enable-omkafka        Compiles omkafka module [default=no]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以清楚的查看到其实这个模块默认是不开启的.所以自己编译加入这个模块,编译好会在相应目录产生 &lt;code&gt;omkafka.so&lt;/code&gt; 这个文件,然后拷贝到 &lt;code&gt;/lib64/rsyslog/&lt;/code&gt; 目录下即可.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;体验+设置&lt;/h2&gt;
&lt;p&gt;使用需要在 &lt;code&gt;rsyslog.conf&lt;/code&gt; 配置文件下或是相应的配置文件中加入 &lt;code&gt;module(load="omkafka")&lt;/code&gt; 表示引入该模块.测试使用可以参照 &lt;a href="http://www.rsyslog.com/doc/master/configuration/modules/omkafka.html#example"&gt;文档中的示例&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;其实文档是相当的简陋,使用示例感觉就是配置上仅仅能使用,更多更详细的根本没有介绍,索性 &lt;a href="http://kafka.apache.org/documentation.html#producerconfigs"&gt;kafka官方的文档&lt;/a&gt; 是相当的详细.在使用的角度看,rsyslog目前是作为一个 &lt;strong&gt;Producer&lt;/strong&gt; 的角色,所以可以依照kafka的文档的 &lt;strong&gt;3.3Producer Configs&lt;/strong&gt; 章节设置,设置相应的参数可以放到 &lt;code&gt;confParam&lt;/code&gt; 或是 &lt;code&gt;topicConfParam&lt;/code&gt; 中就可以了.当然这个参数列表不是无限任何参数都可以往里面仍,根据rsyslog官方文档对这个参数的表述是:其实 &lt;strong&gt;omkafka&lt;/strong&gt; 是使用 &lt;code&gt;librdkafka&lt;/code&gt; 连接卡夫卡的,所以参数实际上那些 &lt;code&gt;librdkafka&lt;/code&gt; 支持的参数.&lt;/p&gt;
&lt;p&gt;仅仅测试的话,根据rsyslog官方文档中配置即可生效.更多的设置和方法还是参照kafka相关设置,以及经过自己充分测试再另行体验,由于我也是才接触配置,更多的使用也不太了解.没有文档真的很瞎啊,但是至少知道了大致怎么使用了.目前的体验来看 &lt;code&gt;partitions.number&lt;/code&gt; 等参数是很好用的.&lt;/p&gt;
&lt;p&gt;rsyslog的kafka模块使用 &lt;a href="http://lists.adiscon.net/pipermail/rsyslog/2014-December/039291.html"&gt;问答列表&lt;/a&gt;&lt;/p&gt;</summary><category term="kafka"></category><category term="消息队列"></category><category term="rsyslog"></category></entry><entry><title>kafka监控web端(添砖)</title><link href="http://bigbo.github.io/pages/2015/01/17/kafka_web_console/" rel="alternate"></link><updated>2015-01-17T15:40:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-17:pages/2015/01/17/kafka_web_console/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;最近在了解消息队列,主要是之前用的是redis,redis固然非常好用,但是也有相应的使用场景.随着数据量的增长,redis已经不能满足现在的需求了.所以需要找个更好的替代品.问了一圈大牛,也google一番,锁定在&lt;a href="http://kafka.apache.org/"&gt;kafka&lt;/a&gt;上了.关于&lt;strong&gt;kafka&lt;/strong&gt;怎么"玩",我也不知道,算是在摸索当中,想要知道安装使用等方法,请移步Google吧.虽然kafka我不会玩,但是我会玩怎么监控它.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;简介&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com/claudemamo/kafka-web-console"&gt;kafka-web-console&lt;/a&gt;,是kafka自己的一个Web管理界面.开源的东西好是好,但是不知道是不是开源的大牛B们都不愿意写文档!!出来个东西,居然没有安装步骤,只是有一些简单的使用说明,甚至说明都不详细,对于此点表示很坑!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;安装&lt;/h2&gt;
&lt;blockquote&gt;
&lt;h5&gt;1.先下载安装scala构建工具&lt;a href="http://www.scala-sbt.org/0.13/tutorial/Installing-sbt-on-Linux.html"&gt;sbt&lt;/a&gt;&lt;/h5&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; #本安装环境为centos6.5
 curl https://bintray.com/sbt/rpm/rpm &amp;gt; bintray-sbt-rpm.repo
 sudo mv bintray-sbt-rpm.repo /etc/yum.repos.d/
 sudo yum install sbt
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;h5&gt;2.下载&lt;strong&gt;kafka-web-console&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;git clone https://github.com/claudemamo/kafka-web-console&lt;/code&gt;&lt;/p&gt;
&lt;h5&gt;3.构建包&lt;/h5&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cd kafka-web-console/  
sbt dist
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;此处是构建出一个可用的standalone包来,以后用的话直接部署使用即可.另外,网上有写教程有说需要设置下数据库等设置,看着有些麻烦,默认的数据库是H2,我没有设置其他的数据库,以我的成功案例来看,此处保持默认设置即可.&lt;/p&gt;
&lt;p&gt;补充:其实早就相对GFW说生祝福了,用sbt构建包的时候问题多多,主要都是下载相关依赖的问题.好多依赖已经被墙了,以至于下载巨慢无比,甚至下载失败.有此问题的请挂代理.sbt怎么设置代理?你问我,我也不会,但是总有人会,请异步---&amp;gt;&lt;a href="http://stackoverflow.com/questions/13803459/how-to-use-sbt-from-behind-proxy"&gt;sbt构建代理设置&lt;/a&gt;&lt;/p&gt;
&lt;h5&gt;4.部署运行&lt;/h5&gt;
&lt;p&gt;当你顺利的构建完成之后,在&lt;code&gt;kafka-web-console/target/universal&lt;/code&gt;下出先一个压缩包.此压缩包正是刚才编译出的应用端.解压zip即可.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;unzip kafka-web-console-2.1.0-SNAPSHOT.zip  
cd kafka-web-console-2.1.0-SNAPSHOT/bin
#第一次启动加个参数不然报错
./kafka-web-console -DapplyEvolutions.default=true
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;至此你可以访问相应的机器的9000端口就可以体验了.&lt;/p&gt;
&lt;h5&gt;查看帮助以及后台运行&lt;/h5&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;./kafka-web-console -h  
nohup ./kafka-web-console &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;其实关于kafka相关的知识相当匮乏,林林总总的通过各种博客看了一些简介,摸着石头过河.后续有对kafka的研究再进行记录了解.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 提示: &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;关于kafka-web-console的使用要注意,实际使用发现,&lt;strong&gt; 会产生过多的TCP连接,导致抢占过多系统资源不说还占用过多的系统端口 &lt;/strong&gt;.由于对java一窍不通,所以也没搞明白什么原因导致.另外其监控效果也不好,图形非常不准.&lt;/p&gt;
&lt;p&gt;推荐另外一个监控系统 &lt;code&gt;KafkaOffsetMonitor&lt;/code&gt; ,用来实时监控Kafka集群的consumers以及它们在partition中的offset(偏移量).体验非常不错.唯一缺点是其中前端js部分可能用到了Google的前端公开库,导致身在天朝的人打开较慢或是直接打不开,需要注意下.&lt;/p&gt;</summary><category term="kafka"></category><category term="消息队列"></category><category term="监控"></category></entry><entry><title>MooseFS浅析(三)--chunk存储选择算法(搬砖)</title><link href="http://bigbo.github.io/pages/2015/01/16/Moosefs_three/" rel="alternate"></link><updated>2015-01-17T19:40:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-16:pages/2015/01/16/Moosefs_three/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;如果自己设计一套chunkserver选择算法,我们要达到哪些目标呢?&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;文件打散后尽量平均分布到各台chunkserver上&lt;/li&gt;
&lt;li&gt;各台chunkserver上的chunk数量尽可能的平均&lt;/li&gt;
&lt;li&gt;数据分发过程衡量系统负载，尽量把数据放在负载低的chunkserver上&lt;/li&gt;
&lt;li&gt;数据分发过程是否应该衡量各台chunkserver的可用空间?&lt;/li&gt;
&lt;li&gt;机架感应?&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;回到MFS使用过程中会有一个疑问.chunkserver的选择是怎么选择的.怎么才能保证数据保存占用空间平衡甚至平均?这就是数据分布算法.也正是分布式文件系统的核心容.所以在此,转来一篇关于MFS的chunk存储选择算法的文章.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;核心算法&lt;/h2&gt;
&lt;p&gt;还记得matocsserventry结构中的carry字段么,这个字段就是分布算法的核心.每台chunkserver会有自己的carry值,在选择chunkserver会将每台chunkserver按照carry从大到小做快速排序,优先选择carry值大的chunkserver来使用.&lt;/p&gt;
&lt;p&gt;在描述具体算法前,先介绍三个概念:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;allcnt:mfs中可用的chunkserver的个数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;availcnt:mfs中当前可以直接存储数据的chunkserver的个数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;demand:当前文件的副本数目&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;先说allcnt,可用的chunkserver要满足下面几个条件:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;chunkserver是活着的&lt;/li&gt;
&lt;li&gt;chunkserver的总空间大于0&lt;/li&gt;
&lt;li&gt;chunkserver的可用空间(总空间-使用空间)大于1G&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;availcnt指的是carry值大于1的可用chunkserver的个数.也就是在allcnt的约束条件上加一条carry值大于1.文件1.txt需要存储2个副本,但是mfs中仅仅有1台chunkserver可用,也就是&lt;code&gt;demand&amp;gt;allcnt&lt;/code&gt;的时候,mfs会自动减少文件的副本个数到allcnt,保证文件可以成功写入系统.&lt;/p&gt;
&lt;p&gt;关于carry有下面几个规则:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;仅carry值大于1的chunkserver可以存储新数据&lt;/li&gt;
&lt;li&gt;每台chunkserver存储新数据后其carry会减1&lt;/li&gt;
&lt;li&gt;demand&amp;gt;availcnt的时候，会递归的增加每台chunkserver的carry值，直到&lt;code&gt;demand&amp;lt;=availcnt&lt;/code&gt;为止&lt;/li&gt;
&lt;li&gt;每台chunkserver每次carry值的增加量等于当前chunkserver总空间除以最大的chunkserver总空间&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;上面的规则比较复杂.举个例子就更加清晰了.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：totalspace:3.94G carry:0.463254
chunkserver 2：totalspace:7.87G carry:0.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;文件1.txt大小1k,mfs默认一个chunk大小为64M,所以仅仅需要一个chunk就够了.此时 availcnt=0,demand=1,所以需要增加carry值&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：carry=0.463254 + (3.94/7.87) = 0.463254 + 0.500005 = 0.963259
chunkserver 2：carry=0.885674 + (7.87/7.87) = 0.885674 + 1.000000 = 1.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;此时 availcnt=1,demand=1,所以不需要增加carry值,对chunkserver按照carry从大到小排序结果为:&lt;code&gt;chunkserver 2 &amp;gt; chunkserver 1&lt;/code&gt;,文件1.txt的chunk会存储到chunkserver 2上,同时chunkserver 2的carry会减1&lt;/p&gt;
&lt;p&gt;如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：carry=0.963259
chunkserver 2：carry=1.885674 – 1 = 0.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;文件2.txt大小1k,mfs默认一个chunk大小为64M,所以仅仅需要一个chunk就够了.此时 availcnt=0,demand=1.所以需要增加carry值&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：carry=0.963259 + (3.94/7.87) = 0.963259 + 0.500005 = 1.463264
chunkserver 2：carry=0.885674 + (7.87/7.87) = 0.885674 + 1.000000 = 1.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;此时 availcnt=2,demand=1,所以不需要增加carry值,对chunkserver按照carry从大到小排序结果为:&lt;code&gt;chunkserver 2 &amp;gt; chunkserver 1&lt;/code&gt;,文件2.txt的chunk会存储到chunkserver 2上,同时chunkserver 2的carry会减1&lt;/p&gt;
&lt;p&gt;如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：carry=1.463264
chunkserver 2：carry=1.885674 – 1 = 0.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;文件3.txt大小1k,mfs默认一个chunk大小为64M,所以仅仅需要一个chunk就够了.此时availcnt=1,demand=1,所以不需要增加carry值.对chunkserver按照carry从大到小排序结果为:&lt;code&gt;chunkserver 1 &amp;gt; chunkserver 2&lt;/code&gt;,文件3.txt的chunk会存储到chunkserver 1上,同时chunkserver 1的carry会减1&lt;/p&gt;
&lt;p&gt;如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;chunkserver 1：carry=1.463264 – 1 = 0.463264
chunkserver 2：carry=0.885674
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;因为两台chunkserver的总空间大小不一致,根据算法总空间大的那台chunkserver会存储更多的新数据.&lt;/p&gt;
&lt;p&gt;记住:&lt;strong&gt;仅仅和chunkserver的总空间有关系和可用空间没有任何关系&lt;/strong&gt;,也就是说,当各台chunkserver总空间大小差不多的情况下,chunk能更好的平均分布,否则mfs会更倾向于选择总空间大的机器来使用.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;最后一个问题,当mfs刚刚启动的时候,carry值是如果获得的?&lt;/p&gt;
&lt;p&gt;答案:随机产生,通过rndu32()这个函数,随机产生一个小于1,大于等于0的数.&lt;/p&gt;
&lt;p&gt;测试结果如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Nov 23 01:01:25 sunwg mfsmaster[13175]: 192.168.0.159,0.594834
Nov 23 01:01:25 sunwg mfsmaster[13175]: 192.168.0.160,0.000000
Nov 23 01:03:58 sunwg mfsmaster[13187]: 192.168.0.159,0.516242
Nov 23 01:03:58 sunwg mfsmaster[13187]: 192.168.0.160,0.826559
Nov 23 01:04:17 sunwg mfsmaster[13192]: 192.168.0.159,0.123765
Nov 23 01:04:17 sunwg mfsmaster[13192]: 192.168.0.160,0.389592
&lt;/pre&gt;&lt;/div&gt;</summary><category term="分布式文件系统"></category><category term="Moosefs"></category><category term="分布式存储"></category></entry><entry><title>Pelican设置及插件使用</title><link href="http://bigbo.github.io/pages/2015/01/13/blog_plugin/" rel="alternate"></link><updated>2015-01-14T13:50:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-13:pages/2015/01/13/blog_plugin/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;博客算是正式用起来了,觉得还不错,但是经过查看或是浏览其他人的博客,感觉自己的还是那么的low.为什么呢?因为没有选择一个高大上的主题,没有使用优秀的插件,没有做相关优化.查了查,还有好多后续工作要做.以下就对博客的插件等设置使用总结下.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;主题设置&lt;/h2&gt;
&lt;p&gt;简单粗暴的设置可以看&lt;a href="http://bigbo.github.io/pages/2014/12/28/create-blog/"&gt;这里&lt;/a&gt;主题设置相关简介.但是我还想说,上面的那些设置还远远不够.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这里推荐一些优秀的主题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/talha131/pelican-elegant"&gt;Elegant&lt;/a&gt;,清俗淡雅.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/DandyDev/pelican-bootstrap3"&gt;pelican-bootstrap3&lt;/a&gt;,我早期用的一个主题,其中自己改了一些东西.此主题有些问题在于宽屏展示的会出现字体有宽边.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/jsliang/pelican-fresh"&gt;pelican-fresh&lt;/a&gt;.我现在使用的主题.各方面还都不错.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然其实还有好多的优秀主题没有加入到&lt;a href="https://github.com/getpelican/pelican-themes"&gt;官方主题库&lt;/a&gt;,要善用github的搜索功能.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;插件设置&lt;/h2&gt;
&lt;p&gt;插件的使用会使你的博客增添一些好的功能.例如评论功能.这里我推荐一些不错值得装的插件.另外官方也有提供&lt;a href="https://github.com/getpelican/pelican-plugins"&gt;插件库&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;sitemap&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/sitemap"&gt;sitemap&lt;/a&gt;可以生成xml和txt格式的网站地图,配置见插件的readme.&lt;/p&gt;
&lt;h4&gt;gzip_cache&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/gzip_cache"&gt;gzip_cache&lt;/a&gt;,可以将所有的页面压缩为gz格式,相对来说能加快页面的加载速度.&lt;/p&gt;
&lt;h4&gt;neighbors&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/davidlesieur/multi_neighbors"&gt;neighbors&lt;/a&gt;,邻居导航,也就是我们常说的上一篇下一篇文章&lt;/p&gt;
&lt;h4&gt;related_posts&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://github.com/LawrenceWoodman/related_posts-jekyll_plugin"&gt;related_posts&lt;/a&gt;,相关文章,根据tags判断的&lt;/p&gt;
&lt;p&gt;想使用当然还需要在配置文件&lt;strong&gt;pelicanconf.py&lt;/strong&gt;中进行设置.例如:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;## 插件目录
PLUGIN_PATHS = [u&amp;quot;pelican-plugins&amp;quot;]

PLUGINS = [u&amp;quot;sitemap&amp;quot;,u&amp;quot;gzip_cache&amp;quot;,u&amp;quot;neighbors&amp;quot;,u&amp;quot;related_posts&amp;quot;]

## 配置sitemap 插件
SITEMAP = {
    &amp;quot;format&amp;quot;: &amp;quot;xml&amp;quot;,
    &amp;quot;priorities&amp;quot;: {
        &amp;quot;articles&amp;quot;: 0.7,
        &amp;quot;indexes&amp;quot;: 0.5,
        &amp;quot;pages&amp;quot;: 0.3,
    },
    &amp;quot;changefreqs&amp;quot;: {
        &amp;quot;articles&amp;quot;: &amp;quot;monthly&amp;quot;,
        &amp;quot;indexes&amp;quot;: &amp;quot;daily&amp;quot;,
        &amp;quot;pages&amp;quot;: &amp;quot;monthly&amp;quot;,
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h2&gt;加载慢的解决&lt;/h2&gt;
&lt;p&gt;当博客上传到github能正常访问后,你就会发现一个问题,加载太TMD慢了!还能不能让然正常的访问了!经过调试,发现是前端&lt;strong&gt;css&lt;/strong&gt;资源需要加载&lt;a href="fonts.googleapi.com"&gt;Google的字体服务&lt;/a&gt;时间过长导致.可以认定是GFW给封了.罪过罪过.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;解决方法&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1.下载字体文件,到网站的静态文件夹内,具体可以参考&lt;a href="http://sudodev.cn/articles/354.html"&gt;让wordpress主题绕开对google的依赖&lt;/a&gt;.不过此种方法也有些问题.把静态资源放到Github上加载时间也没别之前好多少.&lt;/li&gt;
&lt;li&gt;2.把Google的静态公共库替换为国内的公共库.例如我的给替换成&lt;a href="fonts.useso.com"&gt;360的镜像地址&lt;/a&gt;.其实这种方法也有些弊端,例如国外用户访问就会出现加载过慢的问题.但是毕竟我们在'朝内',所以就换成360的资源库吧.操作如下:&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#static/css/目录下css文件中,例如main.css&lt;/span&gt;
&lt;span class="nd"&gt;@import&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;fonts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;googleapi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="n"&gt;family&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Overlock&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;700&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;900&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nd"&gt;@import&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;fonts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;googleapi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="n"&gt;family&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PT&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;Mono&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="c"&gt;#替换为&lt;/span&gt;
&lt;span class="nd"&gt;@import&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;fonts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;useso&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="n"&gt;family&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Overlock&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;700&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;900&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nd"&gt;@import&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;fonts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;useso&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="err"&gt;?&lt;/span&gt;&lt;span class="n"&gt;family&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PT&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;Mono&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;可以上传后测试下,基本上能在10s内刷新出来.效果明显.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;*国内其他开公共库&lt;/strong&gt;:
 &lt;a href="http://developer.baidu.com/wiki/index.php?title=docs/cplat/libs"&gt;百度CDN公共库&lt;/a&gt;; 
 &lt;a href="http://lib.sinaapp.com/"&gt;新浪云计算CDN公共库&lt;/a&gt;; 
 &lt;a href="http://jscdn.upai.com/"&gt;又拍云JS库CDN服务&lt;/a&gt;; 
 &lt;a href="http://www.staticfile.org/"&gt;七牛云静态文件CDN&lt;/a&gt;; &lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Google(百度) Analytics和Webmasters设置&lt;/h2&gt;
&lt;p&gt;注册&lt;a href="http://www.google.com/analytics/"&gt;Google Analytics&lt;/a&gt;和&lt;a href="http://www.google.com/webmasters/"&gt;Webmasters&lt;/a&gt;可以更好的管理自己的站点,&lt;a href="http://zhanzhang.baidu.com/"&gt;百度站长工具&lt;/a&gt;更好的让搜索引擎收录.认证有多种形式,可以根据注册使用向导来完成进一步设置.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;添加多说评论&lt;/h2&gt;
&lt;p&gt;首先在&lt;a href="http://duoshuo.com/"&gt;多说&lt;/a&gt;的网站中注册一个账号.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;修改模板文件&lt;/h4&gt;
&lt;p&gt;修改&lt;code&gt;templates/article.html&lt;/code&gt;内容,在最后一个endif之后添加如下内容&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;{%&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nv"&gt;DUOSHUO_SITENAME&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;SITEURL&lt;/span&gt; &lt;span class="k"&gt;and&lt;/span&gt; &lt;span class="nv"&gt;article.status&lt;/span&gt; &lt;span class="p"&gt;!&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;draft&amp;quot;&lt;/span&gt; &lt;span class="cp"&gt;%}&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;comments&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;h2&amp;gt;&lt;/span&gt;Comments !&lt;span class="nt"&gt;&amp;lt;/h2&amp;gt;&lt;/span&gt;
    &lt;span class="c"&gt;&amp;lt;!-- Duoshuo Comment BEGIN --&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;div&lt;/span&gt; &lt;span class="na"&gt;class=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ds-thread&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;script&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;text/javascript&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        var duoshuoQuery = {short_name:&amp;quot;&lt;span class="cp"&gt;{{&lt;/span&gt; &lt;span class="nv"&gt;DUOSHUO_SITENAME&lt;/span&gt; &lt;span class="cp"&gt;}}&lt;/span&gt;&amp;quot;};
  (function() {
   var ds = document.createElement(&amp;#39;script&amp;#39;);
   ds.type = &amp;#39;text/javascript&amp;#39;;ds.async = true;
   ds.src = &amp;#39;http://static.duoshuo.com/embed.js&amp;#39;;
   ds.charset = &amp;#39;UTF-8&amp;#39;;
   (document.getElementsByTagName(&amp;#39;head&amp;#39;)[0]
    || document.getElementsByTagName(&amp;#39;body&amp;#39;)[0]).appendChild(ds);

   })();
  &lt;span class="nt"&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;noscript&amp;gt;&lt;/span&gt;Please enable JavaScript to view the comments.&lt;span class="nt"&gt;&amp;lt;/noscript&amp;gt;&lt;/span&gt;
&lt;span class="c"&gt;&amp;lt;!-- Duoshuo Comment END --&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/endif&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;这段代码会自动引入多说的评论插件,显示评论内容.&lt;/p&gt;
&lt;h4&gt;修改配置文件&lt;/h4&gt;
&lt;p&gt;在Pelicanconf.py中添加&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;DUOSHUO_SITENAME = &amp;quot;你的blog名称&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;然后重新生成网站就会看到相关的评论界面了.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;配置文件其他配置&lt;/h2&gt;
&lt;p&gt;还有一些其他配置就不一一详解了,以下列出仅供参考.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;## 设置URL按照日期显示
ARTICLE_URL = &amp;#39;pages/{date:%Y}/{date:%m}/{date:%d}/{slug}/&amp;#39;
ARTICLE_SAVE_AS = &amp;#39;pages/{date:%Y}/{date:%m}/{date:%d}/{slug}/index.html&amp;#39;
PAGE_URL = &amp;#39;pages/{slug}/&amp;#39;
PAGE_SAVE_AS = &amp;#39;pages/{slug}/index.html&amp;#39;

## 分页
DEFAULT_PAGINATION = 2

## 静态目录设置
STATIC_PATHS = [&amp;quot;pictures&amp;quot;, ]

## 顶部菜单项
MENUITEMS = [
            (&amp;#39;archives&amp;#39;,SITEURL+&amp;#39;/archives.html&amp;#39;),
            ]
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;以上算是对之前&lt;strong&gt;创建静态博客&lt;/strong&gt;的补充.其实都算是基本的设置,其实还有好多的设置应该做些总结,例如:增加站内搜索框等.时间关系吧,随着对自己博客的改造逐渐进行补充.&lt;/p&gt;</summary><category term="github pages"></category><category term="pelican_plugin"></category></entry><entry><title>MooseFS浅析(二)</title><link href="http://bigbo.github.io/pages/2015/01/08/Moosefs_two/" rel="alternate"></link><updated>2015-01-09T16:00:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-08:pages/2015/01/08/Moosefs_two/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;继上篇,感觉说了好多废话,多半是配置文件相关参数,作为一个基础运维人员,更关注的是怎么让服务更加稳定(高可用),出现问题如何恢复(容错)等,更接地气的东西打算在下面介绍下.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;启动和关闭顺序&lt;/h2&gt;
&lt;p&gt;master启动后,metalogger\chunker\client三个元素都能自动与master建立连接.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;正常启动顺序:matser---chunker---metalogger---client.&lt;/p&gt;
&lt;p&gt;关闭顺序:client---chunker---metalogger---master&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;Client操作与修复&lt;/h2&gt;
&lt;p&gt;客户端强制 &lt;code&gt;kill -9&lt;/code&gt; 杀掉 &lt;code&gt;mfsmount&lt;/code&gt; 进程,需要先 &lt;code&gt;umount&lt;/code&gt; ,然后再 &lt;code&gt;mount&lt;/code&gt; ,否则会提示:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;fuse&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;bad&lt;/span&gt; &lt;span class="n"&gt;mount&lt;/span&gt; &lt;span class="n"&gt;point&lt;/span&gt; &lt;span class="err"&gt;`&lt;/span&gt;&lt;span class="sr"&gt;/mnt/test/&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Transport&lt;/span&gt; &lt;span class="n"&gt;endpoint&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;connected&lt;/span&gt;
&lt;span class="n"&gt;see&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="sr"&gt;/data/jingbo.li/mfs/bin/&lt;/span&gt;&lt;span class="n"&gt;mfsmount&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;help&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;关于修复&lt;/h3&gt;
&lt;p&gt;使用过程中遭遇master断电导致服务停止,可以使用 &lt;code&gt;mfsmetarestore -a&lt;/code&gt; 修复才能启动,如果无法修复,使用 &lt;code&gt;metalogger&lt;/code&gt; 上的备份日志进行恢复: &lt;code&gt;mfsmetarestore -m metadata.mfs.back -o metadata.mfs changelog_ml.*.mfs&lt;/code&gt; ,但是此方法也不是万能的,但凡此过程chunks块出现问题,可以使用 &lt;code&gt;mfsfilerepair&lt;/code&gt; 进行修复.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mfsfilerepair&lt;/code&gt; 主要是处理坏文件的(如写操作引起的I/O错误)使文件能够部分可读.作用如下:在丢失块的情况下使用0对丢失文件进行填充;在块的版本号不匹配时设置快的版本号为master上已知的能在chunkerservers找到的最高版本号;&lt;/p&gt;
&lt;p&gt;注意:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;因为在第二种情况的内容不匹配,可能发生在块具有相同的版本,建议进行文件的拷贝(而不是进行不快照!),并删除原始文件再进行文件的修复.恢复后会有文件丢失或损坏.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;Chunker的空间&lt;/h2&gt;
&lt;p&gt;查看MooseFS文件的使用情况,请使用 &lt;code&gt;mfsdirinfo&lt;/code&gt; 命令,相当于 &lt;code&gt;df&lt;/code&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;快照 &lt;code&gt;snapshot&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;可以快照任何一个文件或目录,语法: &lt;code&gt;mfsmakesnapshot src dst&lt;/code&gt; ,但是src和dst必须都属于mfs体系,即不能mfs体系中的文件快照到其他文件系统.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;&lt;strong&gt;mfsappendchunks&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;追加chunks到一个文件,追加文件块到另一个文件.如果目标文件不存在,则会创建一个空文件,然后继续将块进行追加.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;回收站机制&lt;/h2&gt;
&lt;p&gt;其实MFS有类似windows的回收站这种机制,当文件不小心删除了,不用担心,去回收站去找.随时可以恢复.当然,我所说的随时随地恢复要看你回收站的数据保存多长时间了(默认24小时).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先挂载辅助系统&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;单独安装或挂载 &lt;strong&gt;MFSMETA&lt;/strong&gt; 文件系统,它包含目录/trash (包含仍然可以被还原的删除文件的信息)和 &lt;code&gt;/trash/undel&lt;/code&gt; (用于获取文件),用一个 &lt;code&gt;-m&lt;/code&gt; 或 &lt;code&gt;-o mfsmeta&lt;/code&gt; 的选项,这样可以挂接一个辅助的文件系统MFSMETA,这么做的目的是对于意外的从MooseFS卷上删除文件或者是为了释放磁盘空间而移动的文件而又此文件又过去了垃圾文件存放期的恢复.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例如:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    mfsmount -m /mnt/mfsmeta -H mfs1.com.org
    或者
    mfsmount -o mfsmeta -H mfs1.com.org /mnt/mfsmeta
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;需要注意的是,如果要挂载mfsmeta,一定要在mfsmaster的mfsexports.cfg文件中加入如下条目:* . rw&lt;/p&gt;
&lt;p&gt;挂载后在/mnt/mfsmeta目录下分reserved和trash两个目录,trash为已删除文件存放目录,删除时间根据mfsgettrashtime设置时间来自动删除.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;设置文件或目录的删除时间
一个删除的文件能够存放在“ 垃圾箱”中的时间称为隔离时间,这个时间可以用 &lt;code&gt;mfsgettrashtime&lt;/code&gt; 命令来查看:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img alt="mfsgettrashtime命令" src="/pictures/mfs_pic4.png" /&gt;&lt;/p&gt;
&lt;p&gt;用 &lt;code&gt;mfssettrashtime&lt;/code&gt; 命令来设置上面的这个有效时间,要注意的是,保存时间单位为秒.
&lt;img alt="mfssettrashtime命令" src="/pictures/mfs_pic5.png" /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;恢复删除的文件&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;把删除的文件移到/trash/undel下,就可以恢复此文件.在MFSMETA的目录里,除了 &lt;code&gt;trash&lt;/code&gt; 和 &lt;code&gt;trash/undel&lt;/code&gt; 两个目录,还有第三个目录 &lt;code&gt;reserved&lt;/code&gt; ,该目录内有已经删除的文件,但却被其他用户一直打开着.
在用户关闭了这些被打开的文件后, &lt;code&gt;reserved&lt;/code&gt; 目录中的文件将被删除,文件的数据也将被立即删除.此目录不能进行操作.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;单点故障解决&lt;/h2&gt;
&lt;h3&gt;官方提供解决方案&lt;/h3&gt;
&lt;h4&gt;从备份中恢复一个master(1.6及以上版本)&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;安装一个mfsmaster&lt;/li&gt;
&lt;li&gt;利用同样的配置来配置这台mfsmaster(copy一份mfsmaster.cfg到备机)&lt;/li&gt;
&lt;li&gt;找回metadata.mfs.back文件,可以从备份中找,也可以中metalogger主机中找(如果启动了metalogger服务),然后把metadata.mfs.back放入data目录,一般为${prefix}/var/mfs.&lt;/li&gt;
&lt;li&gt;从在master宕掉之前的任何运行metalogger服务的服务器上拷贝最后metadata文件,然后放入mfsmaster的数据目录&lt;/li&gt;
&lt;li&gt;利用mfsmetarestore命令合并元数据changelogs,可以用自动恢复模式mfsmetarestore –a,也可以利用非自动化恢复模式,语法如下: &lt;code&gt;mfsmetarestore -m metadata.mfs.back -o metadata.mfs changelog_ml.*.mfs&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;DNS主从&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;详细的就需要看官网的手册了,不过CE版本不支持,需要用PRO版本才支持.具体好不好用我也不知道.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;UCARP方案&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;两台主机安装ucarp,ucarp允许多个主机共享一个虚拟的ip地址,以提供自动的故障恢复功能,当其中某个主机宕机时,其它的主机会自动接管服务,ARP协议的特点在于其非常低的开销,主机间使用加密数据传递信息,并且在冗余主机之间不需要任何额外的网络链接.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;双机采用虚拟共用一个虚拟IP地址来实现故障自动迁移,执行指令
&lt;code&gt;ucarp -zB -i eth1 -s 192.168.1.100 -v 42 -p moose -a 192.168.1.252 --upscript=/data/jingbo.li/mfs/sbin/vip-up --downscript=/data/jingbo.li/mfs/sbin/vip-down&lt;/code&gt;
当master宕机后从机可以即时启动恢复接管master的相应服务.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt; * &lt;/strong&gt; 此中方案中要保证两台机器之前的网络畅通,网络抖动都可能影响服务.另外关于脚本的编写恢复策略也影响着恢复状况.我的github上有提供相关脚本.&lt;/p&gt;
&lt;h4&gt;其他HA方案&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;其他高可用方案,例如: &lt;code&gt;DRBD+Heartbeat+Pacemaker&lt;/code&gt; 等,更多的就请教Google吧.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总结:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;根据实际测试(采用ucarp方案),在有些情况下无效,当在你刚写完文件时,在断掉master后,在metalogger机器上做恢复后,客户端上不能对某些文件正常访问,会长时间地卡在那里.通过 &lt;code&gt;mfsfileinfo&lt;/code&gt; 在查看文件属性时,会发现一些的块无效提示,在文件文件里也能看到一些提示信息.数据会丢失,完整性得不到保障.出现数据丢失或是读写错误可以尝试使用 &lt;code&gt;mfsfilerepair&lt;/code&gt; 修复.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;补充及总结&lt;/h2&gt;
&lt;p&gt;算是对MFS实际应用做的一些总结,对于实际来说,使用情况会复杂的多,实际应用肯定会遇到好多的问题.后续根据使用情况再做些总结和规整.&lt;/p&gt;
&lt;p&gt;另外做些补充:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;二次开发:&lt;a href="https://github.com/ops-baidu/shadow-mfs"&gt;百度对Moosefs二次开发&lt;/a&gt;,&lt;a href="http://www.zhangxiaolong.org/archives/242.html"&gt;相关文章&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;使用:实际使用来看,不可能使用每个客户端使用的时候都去安装其客户端,造成使用不太方便,其实可以找一台机器挂载MFS后,在其上面搭建一个&lt;strong&gt;FTP&lt;/strong&gt;等相关文件下载或是上传的服务,再加些权限限制,这样对使用者来说就非常方便和友好了.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;单线程是硬伤&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Moosefs更新其实还算快的,通过看其1.6.X版本源码,其实有些地方写的并不是很好,比如网络方面用的是&lt;strong&gt;poll&lt;/strong&gt;,不知道为什么没有采用更高效的&lt;strong&gt;epoll&lt;/strong&gt;,当然现在的最新版本是2.x版本,后续会跟进的.(经过查看最新版2.0.43版本,网络方面与1.6.X差别不大)&lt;/p&gt;
&lt;p&gt;另外,Master的单线程机制也不能够发挥多核CPU的优势,导致其性能受限,当海量文件(千万以上级别)存储的选型的时候就要注意了,也不适合高并发的一些业务.&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="分布式文件系统"></category><category term="Moosefs"></category><category term="分布式存储"></category></entry><entry><title>MooseFS浅析(一)</title><link href="http://bigbo.github.io/pages/2015/01/05/Moosefs_one/" rel="alternate"></link><updated>2015-01-06T22:50:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2015-01-05:pages/2015/01/05/Moosefs_one/</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;之前面临大量数据存储问题,于是开始选择分布式文件系统.于是MooseFS便映入眼底.正好之前用过,所以直接拿来就用.光会用也不行,闲来之时对他进行了一些简单了解,不管是百度还是谷歌,搜到的都是零零散散的东西,更多的博客都是抄來抄去,所以打算自己做些整理,下面就我对MFS的认识进行一下总结.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;简介&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;MooseFS优越特性如下：&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;高可用性(数据可以存储在多个机器上的多个副本)&lt;/li&gt;
&lt;li&gt;可动态扩展随时新增加机器或者是磁盘&lt;/li&gt;
&lt;li&gt;可回收在指定时间内删除的文件(“垃圾回收站”是一个系统级别的服务)&lt;/li&gt;
&lt;li&gt;可以对整个文件甚至在正在写入的文件创建文件的快照.&lt;/li&gt;
&lt;li&gt;使用和部署非常简单,直接mount使用&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于 &lt;strong&gt;Moosefs&lt;/strong&gt; 的介绍我在此就不详细说了,更多介绍可以查看 &lt;a href="http://www.moosefs.org/"&gt;官网&lt;/a&gt; 以及 &lt;a href="http://www.moosefs.com/how_to_get.html"&gt;英文版权威指南&lt;/a&gt; 或是查看田逸所翻译总结的 &lt;a href="https://github.com/bigbo/tools/blob/master/study/mfs/MooseFS%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97.pdf"&gt;权威指南&lt;/a&gt; ,以上介绍的比自己总结的可能更加详细.我后面的总结是对以上内容的补充.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; *AD:更多资料详见&lt;a href="https://github.com/bigbo/tools/tree/master/study/mfs"&gt;GitHub&lt;/a&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;系统结构&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;MFS文件系统结构包含4种角色:&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;管理服务器managing server(master):负责各个数据存储服务器的管理,文件读写调度,文件空间回收以及恢复.多节点拷贝.单个机器管理整个文件系统,用来存储记录每一个文件的Metadata(记录文件的大小;文件的属性;文件的位置;也包括非规则文件的系统;如目录;sockets;管道和设备)&lt;/li&gt;
&lt;li&gt;元数据日志服务器Metalogger server(Metalogger):负责备份master服务器的变化日志文件,文件类型为changelog_ml.*.mfs,以便于在master server出问题的时候接替其进行工作.&lt;/li&gt;
&lt;li&gt;数据存储服务器data servers (chunkservers):负责连接管理服务器,听从管理服务器调度,提供存储空间,并为客户提供数据传输.&lt;/li&gt;
&lt;li&gt;客户机挂载使用client computers:通过fuse内核接口挂接远程管理服务器上所管理的数据存储服务器,看起来共享的文件系统和本地unix文件系统使用一样的效果.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;整体架构如图:&lt;/p&gt;
&lt;p&gt;&lt;img alt="MFS架构图" src="/pictures/mfs_pic3.png" /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;配置文件详解&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;主要对 &lt;strong&gt;V1.6.27-5&lt;/strong&gt; 版本的配置文件进行解析,后续跟进 &lt;strong&gt;2.x&lt;/strong&gt; 版本配置文件.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;master服务器&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Metadata元数据存储在master服务器的内存中,同时也保存在磁盘上(作为一个定期更新的二进制文件,并实时的更新changelog日志).如果存在metaloggers的话,主要的二进制文件以及日志也复制到metaloggers中.(权威手册中有详细性能测试信息)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;master主要配置文件&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;mfsmaster.cfg&lt;blockquote&gt;
&lt;p&gt;主配置文件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;参数说明如下：
 # WORKING_USER和WORKING_GROUP：是运行master server的用户和组；
 # SYSLOG_IDENT：是master server在syslog中的标识，也就是说明这是由master server产生的；
 # LOCK_MEMORY：是否执行mlockall()以避免mfsmaster 进程溢出(默认为0，即否)；
 # NICE_LEVE：运行的优先级(如果可以默认是 -19; 注意: 进程必须是用root启动)；
 # EXPORTS_FILENAME：被挂接目录及其权限控制文件的存放位置 
 # DATA_PATH：metadata files and lock file存放路径，此目录下大致有以下文件：metadata，changelog，sessions，stats，lock.
 # BACK_LOGS：metadata的change log文件数目(默认是 50);
 # BACK_META_KEEP_PREVIOUS = 1保留以前元文件数(默认是 1);
 # REPLICATIONS_DELAY_INIT：(initial delay in seconds before starting replications)初始延迟复制的时间(默认是300s);
 # REPLICATIONS_DELAY_DISCONNECT：(replication delay in seconds after chunkserver disconnection) chunkserver断开后复制延迟(默认是3600s)；
 # MATOML_LISTEN_HOST：用于metalogger连接的IP地址(默认是*,代表任何IP)；
 # MATOML_LISTEN_PORT：监听metalogger请求的端口地址(默认是9419)；
 # MATOCS_LISTEN_HOST：用于chunkserver连接的IP地址(默认是*，代表任何IP)；
 # MATOCS_LISTEN_PORT：监听chunkserver连接的端口地址(默认是9420)；
 # MATOCU_LISTEN_HOST：用于客户端挂接连接的IP地址(默认是*,代表任何IP)；
 # MATOCU_LISTEN_PORT：监听客户端挂载连接的端口地址(默认是9421)；
 # CHUNKS_LOOP_TIME ：(Chunks loop frequency in seconds)chunks的回环频率(默认是：300秒)；
 # CHUNKS_DEL_LIMIT：(Maximum number of chunks to delete in one loop)在一个loop中可以删除chunks的最大数 (默认：100)
 # CHUNKS_WRITE_REP_LIMIT：(Maximum number of chunks to replicate to one chunkserver in one loop)在一个loop里复制到一个chunkserver的最大chunk数目(默认是1)
 # CHUNKS_READ_REP_LIMIT：(Maximum number of chunks to replicate from one chunkserver in one loop)在一个loop里从一个chunkserver复制的最大chunk数目(默认是5)
 # REJECT_OLD_CLIENTS：弹出低于1.6.0的客户端挂接(0或1，默认是0)
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;mfsexports.cfg&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;MFS访问使用权限控制配置文件;地址可以指定的几种表现形式：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;所有ip，单个ip，IP网络地址/位数掩码，IP网络地址/子网掩码，ip段范围.
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;权限部分：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;   ro  只读模式共享  
   rw  读写方式共享  
   alldirs  许挂载任何指定的子目录  
   maproot   映射为root,还是指定的用户   
   password  指定客户端密码
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;metadata.mfs文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;metadata.mfs, metadata.mfs.back是MooseFS文件系统的元数据metadata的镜像,对集群的数据存储至关重要.做主从也好,做集群备份也好,都是对这些文件做的备份.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;changelog.*.mfs 文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;changelog.*.mfs 是MooseFS文件系统元数据的改变日志(每一个小时合并到metadata.mfs中一次)&lt;/li&gt;
&lt;li&gt;Metadata文件的大小取决于文件数(而不是他们的大小),Changelog的大小取决于每小时的操作次数.(mfsmaster.cfg配置文件中可以设置)&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h3&gt;metalogger服务器&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;master备份服务器,在保证服务高可用的情况下使用(即使不做高可用也需要做个备份服务),服务器性能理论上要比master更好.至少不能比master次.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;metalogger主要配置文件&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;mfsmetalogger.cfg&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;WORKING_USER&lt;/span&gt;&lt;span class="err"&gt;和&lt;/span&gt;&lt;span class="nt"&gt;WORKING_GROUP&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="err"&gt;是运行&lt;/span&gt;&lt;span class="nt"&gt;mfsmetalogger&lt;/span&gt; &lt;span class="nt"&gt;server&lt;/span&gt;&lt;span class="err"&gt;的用户和组；&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;SYSLOG_IDENT&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="err"&gt;是&lt;/span&gt;&lt;span class="nt"&gt;mfsmetalogger&lt;/span&gt; &lt;span class="nt"&gt;server&lt;/span&gt;&lt;span class="err"&gt;在&lt;/span&gt;&lt;span class="nt"&gt;syslog&lt;/span&gt;&lt;span class="err"&gt;中的标识，也就是说明这是由&lt;/span&gt;&lt;span class="nt"&gt;mfsmetalogger&lt;/span&gt; &lt;span class="nt"&gt;server&lt;/span&gt;&lt;span class="err"&gt;产生的；&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;LOCK_MEMORY&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="err"&gt;是否执行&lt;/span&gt;&lt;span class="nt"&gt;mlockall&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;&lt;span class="err"&gt;以避免&lt;/span&gt;&lt;span class="nt"&gt;mfsmaster&lt;/span&gt; &lt;span class="err"&gt;进程溢出&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;默认为&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="err"&gt;，即否&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;NICE_LEVEL&lt;/span&gt;&lt;span class="err"&gt;：运行的优先级&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;如果可以默认是&lt;/span&gt; &lt;span class="nt"&gt;-19&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="err"&gt;注意&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="err"&gt;进程必须是用&lt;/span&gt;&lt;span class="nt"&gt;root&lt;/span&gt;&lt;span class="err"&gt;启动&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="err"&gt;；&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;DATA_PATH&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;metadata&lt;/span&gt; &lt;span class="nt"&gt;files&lt;/span&gt; &lt;span class="nt"&gt;and&lt;/span&gt; &lt;span class="nt"&gt;lock&lt;/span&gt; &lt;span class="nt"&gt;file&lt;/span&gt;&lt;span class="err"&gt;存放路径，此目录下大致有以下文件：&lt;/span&gt;&lt;span class="nt"&gt;metadata&lt;/span&gt;&lt;span class="err"&gt;，&lt;/span&gt;&lt;span class="nt"&gt;changelog&lt;/span&gt;&lt;span class="err"&gt;，&lt;/span&gt;&lt;span class="nt"&gt;sessions&lt;/span&gt;&lt;span class="err"&gt;，&lt;/span&gt;&lt;span class="nt"&gt;stats&lt;/span&gt;&lt;span class="err"&gt;，&lt;/span&gt;&lt;span class="nt"&gt;lock&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;BACK_LOGS&lt;/span&gt;&lt;span class="err"&gt;：&lt;/span&gt;&lt;span class="nt"&gt;metadata&lt;/span&gt;&lt;span class="err"&gt;的&lt;/span&gt;&lt;span class="nt"&gt;change&lt;/span&gt; &lt;span class="nt"&gt;log&lt;/span&gt;&lt;span class="err"&gt;文件数目&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;默认是&lt;/span&gt; &lt;span class="nt"&gt;50&lt;/span&gt;&lt;span class="o"&gt;);&lt;/span&gt;

 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;META_DOWNLOAD_FREQ&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;1&lt;/span&gt; &lt;span class="nf"&gt;#metadata&lt;/span&gt;&lt;span class="err"&gt;元数据下载间隔时间&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;默认是&lt;/span&gt;&lt;span class="nt"&gt;24&lt;/span&gt;&lt;span class="err"&gt;小时，单位是小时，至多是&lt;/span&gt;&lt;span class="nt"&gt;BACK_LOGS&lt;/span&gt;&lt;span class="err"&gt;的&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;MASTER_RECONNECTION_DELAY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;5&lt;/span&gt;   &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="err"&gt;在失去连接之后延迟多少秒重新连接&lt;/span&gt;&lt;span class="nt"&gt;master&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;MASTER_HOST&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;MASTERMFS&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;master&lt;/span&gt;&lt;span class="err"&gt;的&lt;/span&gt;&lt;span class="nt"&gt;HOST&lt;/span&gt;&lt;span class="err"&gt;地址&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;MASTER_PORT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;9419&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;MASTER_TIMEOUT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;60&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;Master&lt;/span&gt;&lt;span class="err"&gt;连接超时时间&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="err"&gt;单位是秒&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;deprecated&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;to&lt;/span&gt; &lt;span class="nt"&gt;be&lt;/span&gt; &lt;span class="nt"&gt;removed&lt;/span&gt; &lt;span class="nt"&gt;in&lt;/span&gt; &lt;span class="nt"&gt;MooseFS&lt;/span&gt; &lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="nc"&gt;.7&lt;/span&gt;
 &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;LOCK_FILE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;var&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;run&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;mfs&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;mfsmetalogger&lt;/span&gt;&lt;span class="nc"&gt;.lock&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;changelog_ml.*.mfs文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;changelog_ml.*.mfs是MooseFS文件系统的元数据的changelog日志(备份的Master 的Master的changelog日志)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;metadata.ml.mfs.back文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;metadata.ml.mfs.back是从Master主机上下载的最新的完整metadata.mfs.back的拷贝&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;sessions.ml.mfs文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;sessions.ml.mfs是从master下载的最新的sessions.mfs文件拷贝&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;chunker服务器&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;数据真实存储的位置,实际使用中,对硬件资源消耗不是很大,最终的瓶颈在网卡和磁盘IO.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;chunker主要配置文件&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;mfschunkserver.cfg&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; # WORKING_USER和WORKING_GROUP：是运行mfschunkserver server的用户和组；
 # SYSLOG_IDENT：是mfschunkserver server在syslog中的标识,也就是说明这是由mfschunkserver server产生的；
 # LOCK_MEMORY：是否执行mlockall()以避免mfschunkserver 进程溢出(默认为0，即否)；
 # NICE_LEVE：运行的优先级(如果可以默认是 -19; 注意: 进程必须是用root启动)；
 # DATA_PATH：metadata files and lock file存放路径,此目录下大致有以下文件：metadata，changelog，sessions，stats，lock.
 # MASTER_RECONNECTION_DELAY = 5 在失去连接之后延迟多少秒重新连接master
 # MASTER_HOST: 元数据服务器的名称或地址,可以是主机名，也可以是ip地址.只要数据存储服务器能访问到元数据服务器就行.
 # MASTER_PORT = 9420
 # MASTER_TIMEOUT = 60
 # CSSERV_LISTEN_HOST = *  #允许挂载的客户端连接的IP地址(*允许全部)
 # CSSERV_LISTEN_PORT = 9422
 # CSSERV_TIMEOUT = 5      #客户端挂载连接的超时时间(单位为秒)
 # HDD_CONF_FILENAME = /usr/local/mfs/etc/mfshdd.cfg #分配给MFS使用的磁盘空间配置文件的位置
 # HDD_TEST_FREQ = 10   # 块的测试期(单位为秒)
 # deprecated, to be removed in MooseFS 1.7
 # LOCK_FILE = /var/run/mfs/mfschunkserver.lock
 # BACK_LOGS = 50
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;mfshdd.cfg文件&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;目录列表（指定的）用于moosefs挂载存储&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;*AD&lt;/strong&gt;:当某块磁盘发生故障后可以在前面加*,集群便会在后续冗余中,把相应磁盘或是存储位置的数据转移到其他地方存储&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;mfsclient(mount)服务器&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;客户端,安装相应挂载程序使用mfsmount -H MASTER_MFS_HOST /mnt/mfs,进行磁盘挂载.关于使用嘛,找下man吧.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h2&gt;测试&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;官网手册有详细测试信息&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;零零散散算是把相关配置文件大致介绍一遍,没想成已经有不少内容,不多多半都是配置文件内容,感觉以上介绍离实际用处好远.准备接下来写些MFS使用相关的介绍.此篇准备随时更新.&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="分布式文件系统"></category><category term="Moosefs"></category><category term="分布式存储"></category></entry><entry><title>2014年终总结</title><link href="http://bigbo.github.io/pages/2014/12/31/2014%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/" rel="alternate"></link><updated>2014-12-31T23:22:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2014-12-31:pages/2014/12/31/2014年终总结/</id><summary type="html">&lt;p&gt;在这2014年的结尾,陆陆续续的通过博客\微博\微信看到了好多人在对2014年做的一些总结.赶着2014的末班车,在此我也做些总结.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;工作&lt;/h3&gt;
&lt;p&gt;其实总的来说这一年是不平凡的一年.对于一个职场小白来说,应该从老东家说起.&lt;/p&gt;
&lt;p&gt;那时还是在东三环内的23层,同事还是那么的欢乐,口味依旧那么重.工作环境是那么的轻松欢乐,以至于时间过得那么快,快得都想说句"时间都去哪了".不知不觉公司3月份搬家如期而至;与此同时,项目上遇到的问题比想象中的困难的多的多.最终不得不以结束告终.队伍重组,从而走向了人生的转折.&lt;/p&gt;
&lt;p&gt;4月份来到了@大神的团队,追随一群大神的脚步.开始了一堆高大上的工作.监控\分析\报警,井井有条.让我感到工作的责任还是如此重大.工作内容是如此神圣,虽不能光宗耀祖,但是足可以向身边人吹嘘一番.&lt;/p&gt;
&lt;p&gt;7月犹豫而又慌乱的时代.想想终究算是过去了,就让它淹没在这个时代吧.&lt;/p&gt;
&lt;p&gt;10月没想到该来的还是来了,换了工作,从网到神奇的网站.算是第一次跳槽.想想现在依旧对老东家怀念.也因此终不再犹豫.踏入一个三无地带,从此红旗自己扛,不再有上午茶,中午的安稳觉,下午的集体会;更多的是自己寻找解决方案,尝试处理问题.&lt;/p&gt;
&lt;p&gt;总之找准自己的位置,朝向一个目标前进就是了.要说的是,感谢的人真的是太多了;@大忽悠,感谢把我带上了一条"不归"路;@张姐,感谢合作的那段时间给我指引了好多方向,感觉自己还是不给力,没能坚持到最后,没有给自己一个很好的交代.不过真的学了好多;@会长,感谢那么多的肺腑之言,可惜听了那么多的人生道理,可是依旧没有走好这段路.当然这是后话;@三斗@lantao@SevenShen,有幸跟你们擦肩而过,庆幸自己紧追随你们的步伐,虽然从来没追上过,只能心里默念"他们引擎是V8的".总的来说要感谢的人还是太多了.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;生活&lt;/h3&gt;
&lt;p&gt;改变生活的唯一途径就是自身努力.两年前就应该到手的驾照终于到手了;拥有了比较满意的"大白腿";参与了祖国提供的一次重反校园的考试;虽然与女票有过激烈的争执,但是感情还是一如既往的稳定.生活品质貌似没有提升,后续有待考证.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;主要技术&lt;/h3&gt;
&lt;h5&gt;Python+&lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;历史问题,用自己所学,重构了一个内部系统,至于现在好用就不得而知了.算是对之前的学习总结.中间还用上了&lt;a href="http://gearman.org/"&gt;gearman&lt;/a&gt;,当然对于一向不会前端的我,照猫画虎的拼凑除了一个能看的页面也算是小有所成了.有展示,有监控,有搜索,有规整,有报警.维护的事情就交给@轩了,写的太烂不要骂我.&lt;/p&gt;
&lt;h5&gt;&lt;a href="http://www.moosefs.org/"&gt;MFS&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;分布式文件系统.研究跟大牛比不算深入.后续会在博客中做些总结.倒是在呆过的地方都留下了他的身影.还算是一个容易上手使用的文件系统.虽然被坑过,但还算是不错的(看使用场景).&lt;/p&gt;
&lt;h5&gt;&lt;a href="http://www.elasticsearch.com/"&gt;ELK&lt;/a&gt;框架&lt;/h5&gt;
&lt;p&gt;都不知从何说起了.跟随@三斗的脚步,学习研究整套方案的技术细节,调优方案.目前也正在使用打算推广的一套方案.后续如何,还都是未知.感觉自己慢慢的走向了数据挖掘的深坑.&lt;/p&gt;
&lt;h5&gt;GITHUB+Blog&lt;/h5&gt;
&lt;p&gt;终于动手做了,不知道能坚持多久,共勉.&lt;/p&gt;
&lt;p&gt;犹记得2014年初,当时对一年的期望是读一两本好书,coding坏一个键盘,如今的好书只翻了半本有余,键盘的按键依旧是那么轻快好用,对比一年前,只不过键帽发油发亮了.回想当时的期望,不由得对自己说声好傻好天真.如今展望2015,最大的期望就是能把blog坚持下去.&lt;/p&gt;</summary></entry><entry><title>用Pelican&amp;GitHubPages搭建个人博客</title><link href="http://bigbo.github.io/pages/2014/12/28/create-blog/" rel="alternate"></link><updated>2014-12-28T00:02:00+08:00</updated><author><name>ljingb</name></author><id>tag:bigbo.github.io,2014-12-28:pages/2014/12/28/create-blog/</id><summary type="html">&lt;h3&gt;前言&lt;/h3&gt;
&lt;p&gt;对于github.io早有认识,但是趋于各种懒,至今才动手.想把这几年的一些自己总结的东西做些记录,匆匆那些年,也应该给自己做些积累了.&lt;/p&gt;
&lt;p&gt;那么问题来了,建立github page有各种框架,例如:&lt;a href="http://jekyllrb.com/"&gt;jekyll&lt;/a&gt;,&lt;a href="https://github.com/Shopify/liquid/wiki/Liquid-for-Designers"&gt;liquid&lt;/a&gt;,&lt;a href="http://pelican-docs-zh-cn.readthedocs.org/en/latest/"&gt;Pelican&lt;/a&gt;等等,本文采用后者Pelican,关于Pelican不做过多介绍,想了解的就去连接到的文档看吧.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;搭建基础&lt;/h3&gt;
&lt;p&gt;Pelican基于Python,相比Wordpress等其他框架来说,它比较轻,另外有些自己的&lt;a href="http://docs.getpelican.com/en/3.3.0/#features"&gt;特性&lt;/a&gt;,再配合免费的github pages,非常棒!主要是在linux下进行搭建,过程中会涉及如下技术知识,不过都是很初级的使用,即使新手也可以很容易的上手.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com"&gt;github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pages.github.com"&gt;github pages&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://git-scm.com/blog/2010/06/09/pro-git-zh.html"&gt;git&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.python.org"&gt;python&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://pypi.python.org/pypi/pip"&gt;pip&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://pelican-docs-zh-cn.readthedocs.org/en/latest"&gt;pelican&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://wowubuntu.com/markdown/"&gt;markdown&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr /&gt;
&lt;h3&gt;下载安装&lt;/h3&gt;
&lt;p&gt;由于是linux环境,大部分依赖是有的,没有的话可以通过yum/apt-get去安装.win的话就请参照安装.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;安装python (2.7+,低版本的不支持)&lt;/li&gt;
&lt;li&gt;安装git&lt;/li&gt;
&lt;li&gt;安装pip&lt;/li&gt;
&lt;li&gt;安装pelican&amp;amp;markdown    &lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pip install pelican
pip install markdown
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h3&gt;框架初建&lt;/h3&gt;
&lt;p&gt;创建文件夹,执行以下命令&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mkdir blog //注意命名
cd blog
pelican-quickstart
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;pelican-quickstart执行命令后,可以依照向导,输入相关配置项,怎么填写可以很随意,后续都可以在pelicanconf.py文件中进行更改.&lt;/p&gt;
&lt;p&gt;命令成功执行后,会出现pelican的框架,如下所示:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;blog/
|-- content             # 存放输入的markdown或RST源文件
|-- output              # 存放最终生成的静态博客
|-- pelicanconf.py      # 配置文件
|-- develop_server.sh   # 测试服务器
|-- Makefile            # 管理博客的Makefile
`-- publishconf.py      # 发布文件，可删除
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;以上完成整体大的框架.&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;填写内容&lt;/h4&gt;
&lt;p&gt;至此,我们可以开始使用Markdown创建一个页面,进入content文件夹,创建一个.md文件.大致如:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt text" src="/pictures/pic1.png" /&gt;&lt;/p&gt;
&lt;p&gt;可以通过截图看到我现在这个页面的Markdown版本的源文件,这里要说的是开头部分的&lt;strong&gt;Title,Category&lt;/strong&gt;等重点字段.详情见&lt;a href="http://pelican-docs-zh-cn.readthedocs.org/en/latest/getting_started.html#pelican"&gt;文档&lt;/a&gt;,涵义如下:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Title: 文章标题
Date: 创建日期
Modified: 修改日期
Category: 文章分类，标志本文处于该分类下
Tags: 文章标签，标志本文处于该标签下
Slug: URL中该文章的链接地址
Author: 作者
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以简单的写个内容做测试,然后回到&lt;strong&gt;blog&lt;/strong&gt;目录下.&lt;/p&gt;
&lt;p&gt;执行&lt;strong&gt;make html&lt;/strong&gt;生成html&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;[jingbo.li@zero bigbo-blog]$ make html 
pelican /home/jingbo.li/dev/bigbo-blog/content -o /home/jingbo.li/dev/bigbo-blog/output -s /home/jingbo.li/dev/bigbo-blog/pelicanconf.py 
Done: Processed 1 article(s), 0 draft(s) and 1 page(s) in 0.83 seconds.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;表示已经生成了html页面,可以去&lt;strong&gt;/blog/output&lt;/strong&gt;目录下查看已经生成的html页面.&lt;/p&gt;
&lt;p&gt;接着执行&lt;strong&gt;make server&lt;/strong&gt;开启服务,可以看到相关log&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;[jingbo.li@zero bigbo-blog]$ make serve 
cd /home/jingbo.li/dev/bigbo-blog/output &amp;amp;&amp;amp; python -m pelican.server
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;即可可以用浏览器访问&lt;strong&gt;http://localhost:8000&lt;/strong&gt;看到显示效果.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;*AD:更多便捷命令&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;make regenerate     #修改后自动创建静态界面(make html)
make devserver      #相当于regenerate+serve
make publish        #生成用于发布的html
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;文档中还有其他一些命令,请自行发掘.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;设置相关&lt;/h3&gt;
&lt;hr /&gt;
&lt;h4&gt;主题选择&lt;/h4&gt;
&lt;p&gt;如果你能到这一步,那么恭喜你,你已经搭建完一个属于自己的博客了.以下是对自己博客的包装.
首先打开&lt;a href="http://www.pelicanthemes.com/"&gt;主题官网&lt;/a&gt;挑选自己喜欢的主题,当然我们可以把整个&lt;a href="https://github.com/getpelican/pelican-themes"&gt;主题库&lt;/a&gt;clone到本地.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; git clone https://github.com/getpelican/pelican-themes.git
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;现在可以自由选择不错的主题了.打开&lt;strong&gt;pelicanconf.py&lt;/strong&gt;配置文件,添加或是更改&lt;strong&gt;THEME&lt;/strong&gt;为自己喜欢的主题.更多配置请见&lt;a href="http://pelican-docs-zh-cn.readthedocs.org/en/latest/settings.html#id20"&gt;官方文档&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;例如选择notmyidea-cms-fr主题:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;THEME = &amp;#39;pelican-themes/notmyidea-cms-fr&amp;#39; #相对路径或是绝对路径
&lt;/pre&gt;&lt;/div&gt;


&lt;hr /&gt;
&lt;h5&gt;link的图标不加载&lt;/h5&gt;
&lt;p&gt;主题选择后打开页面一看,擦,有些瑕疵,旁边的一些github等连接没有图片,影响美观不说B格瞬减.
连接上的小图标:&lt;/p&gt;
&lt;p&gt;&lt;img alt="如图上面的小图标" src="/pictures/pic2.png" title="u&amp;quot;如图上面的小图标&amp;quot;" /&gt;&lt;/p&gt;
&lt;p&gt;通过分析查看原因,得知是由于css问题,来到主题文件夹下,尝试修改加载的css文件:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;  &lt;span class="nt"&gt;cd&lt;/span&gt; &lt;span class="nt"&gt;pelican-themes&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;notmyidea-cms-fr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;static&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;css&lt;/span&gt;
  &lt;span class="nt"&gt;vim&lt;/span&gt; &lt;span class="nt"&gt;main&lt;/span&gt;&lt;span class="nc"&gt;.css&lt;/span&gt;
  &lt;span class="err"&gt;#添加如下字段&lt;/span&gt;
  &lt;span class="nc"&gt;.social&lt;/span&gt; &lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;href&lt;/span&gt;&lt;span class="o"&gt;*=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;github.com&amp;#39;&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="nd"&gt;:before&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="k"&gt;content&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="sx"&gt;url(&amp;#39;../images/icons/github.png&amp;#39;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;margin-right&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;2px&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;vertical-align&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;-3px&lt;/span&gt;&lt;span class="p"&gt;;}&lt;/span&gt;
  &lt;span class="err"&gt;#注意在相应位置放上图标&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;久违的图标就会展现在你的眼前了,B格瞬间上升几个百分点.&lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;添加评论系统&lt;/h4&gt;
&lt;p&gt;历经沧桑,终于算是大功告成.等下!貌似还缺一个功能,评论系统.评论可以促进交流,所以这个当然不能少了.目前采用的是国外的评论系统&lt;a href="https://disqus.com/"&gt;Disqus&lt;/a&gt;,安装流程注册填写,会给你博客相关站点分配一个&lt;strong&gt;Shortname&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;回到配置文件&lt;strong&gt;pelicanconf.py&lt;/strong&gt;添加配置&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;DISQUS_SITENAME = Shortname
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;现在大功告成,可以生成页面开始把玩一番吧!&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;编写文章&lt;/h3&gt;
&lt;p&gt;几经转辗,终于可以发篇文章炫耀下了,哈哈哈.本文给予&lt;strong&gt;github pages&lt;/strong&gt;,当然如果你有自己的服务器可以根据&lt;a href="https://help.github.com/articles/creating-pages-with-the-automatic-generator/"&gt;官方教程&lt;/a&gt;设置你自己的站点服务器.这样你就拥有一个二级域名和一个版本库.任性的更新.&lt;/p&gt;
&lt;p&gt;进入&lt;strong&gt;&lt;em&gt;blog&lt;/em&gt;&lt;/strong&gt;目录下的&lt;strong&gt;&lt;em&gt;output&lt;/em&gt;&lt;/strong&gt;文件夹内,依次执行以下命令:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;  git init
  git add .
  git remote add origin https://github.com/bigbo/bigbo.github.io
  git pull origin master
  git commit -m &amp;#39;create blog&amp;#39;
  git push origin master
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当然如果你不会git,没关系,现在先按照&lt;a href="http://www.git-scm.com/book/zh/v1"&gt;官方文档&lt;/a&gt;敲就可以了.熟悉git的同学可以选择使用框架提供的&lt;strong&gt;Makefile&lt;/strong&gt;文件进行一键上传.&lt;/p&gt;
&lt;p&gt;一个完整的博客创建发布流程算是完成了.最后打开浏览器访问github pages的域名即可访问.&lt;/p&gt;
&lt;hr /&gt;
&lt;h3&gt;总结&lt;/h3&gt;
&lt;p&gt;目前博客已经可以满足基本的正常使用了.其实我们还可以对其进行不断完善,让其变得更优雅.后续再写些关于插件\配置等有关的内容.&lt;/p&gt;
&lt;p&gt;第一次建立属于自己的空间,写的过程中参见了网上不少的例子,内容都是参疵不齐.更多的是参照官方文档,或是请教&lt;a href="http://google.com"&gt;google&lt;/a&gt;,这个过程持续了3--4天,终于完成了第一篇,收获还是满满的.当然后续还会有第二第三篇.&lt;/p&gt;
&lt;p&gt;不管怎样,收获远大于付出.也算是为2014画上半个句号.希望 2015 come on!&lt;/p&gt;</summary><category term="github pages"></category><category term="pelican"></category></entry></feed>